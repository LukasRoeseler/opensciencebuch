---
title: "Probleme des Wissenschaftlichen Systems"
editor: visual
format: html
bibliography: references.bib
bibliographystyle: apa
---

## Probleme des Wissenschaftlichen Systems

Neben dem Idealbild davon, was Wissenschaft sein sollte oder wie sie funktionieren sollte, existiert die Wissenschaft, wie sie in unser Gesellschaftssystem integriert ist. Besonderheiten sind dabei, dass Wissenschaftler\*innen ihre Tätigkeit als Beruf ausüben, also Geld dabei verdienen. Wie das Geld, das größtenteils aus Steuergeldern stammt, verteilt werden soll entscheiden Gremien, die wiederum selbst aus Wissenschaftler\*innen bestehen. Durch die hohe Arbeitsbelastung, gleichzeitig Wissenschaft zu betreiben und zu verwalten vereinfachen sich die Entscheider\*innen die Arbeit und verwenden zur Auswahl hochqualifizierter Personen Abkürzungen. So konnte es passieren, dass die Währung in der Wissenschaft die Anzahl an Publikationen und Zitationszahlen sind. Vorbilder wie Charles Darwin oder William James hätten nach dem heutigen Maßstab keine Chance auf eine unbefristete Stelle - sie haben einfach nicht genug Paper geschrieben. Viele der hier diskutierten Problemen, sind beispielsweise in der Psychologie seit mehreren Jahrzehnten bekannt, sodass eine Replikationskrise unabwendbar erschienen haben muss (Cronbach et al., 1991; Greenwald, 1976).

### Wissenschaft versus Academia

Während Wissenschaften in ihrer Anfangszeit oft von Buchveröffentlichungen leben, die eine umfangreiche Basis von meist einzelnen Personen darlegen (e.g., Galileo, James, Darwin) stehen heutzutage wissenschaftliche Fachzeitschriften im Fokus. Diese Zeitschriften sind vergleichbar mit solchen, die es im Kiosk gibt, nur bestehen sie halt aus (meist englischsprachigen) Artikeln, die Wissenschaftler\*innen verfasst und eingereicht haben und sind in vielen Fällen nur noch online oder in Büchereien erhältlich. Forschende laden sich dann einzelne Artikel aus den Zeitschriften herunter und Bibliotheken haben Verträge mit Verlagen und zahlen Geld, damit Universitätsangehörige Zugriff zu den Katalogen haben. Jeder eingereichte Artikel befasst sich mit einer Fragestellung, die von den Forschenden selbst festgelegt wurde. Darin werden meistens Studien mit deren Ergebnissen berichtet. Vor der Veröffentlichung werden die Artikel begutachtet, nicht von Mitarbeitenden der Zeitschrift sondern von Kolleg\*innen. Mit diesem "peer-review" wird die Qualität von Forschung sichergestellt. Üblicherweise wird dabei darauf geachtet, dass die Schlussfolgerungen auf Basis der erhobenen Daten gerechtfertigt sind, die Fragestellung klar beantwortet wird, und die Befunde spannend oder überraschend sind. Zeitschriften unterscheiden sich darin, welche Themen sie abdecken (z.B. Sozialpsychologie, Konsumentenverhalten, Angewandte Sportwissenschaft, usw.) und von wie vielen Forschenden sie gelesen und zitiert werden. Wissenschaften sind also stark integriert in ein System, das Forschenden und Verlagen erlaubt, ein festes Gehalt zu verdienen.

### Prekäre Arbeitsbedingungen

Soweit die Idealbedingungen -- Wer in der Wissenschaft arbeitet, befindet sich jedoch in einem harten Konkurrenzkampf um eine der wenigen unbefristeten Stellen (Rahal et al., 2023). Vom Start der Promotion (Prozess der Erlangung eines Doktorgrades) bis zur Berufung auf eine Professur, also eine der raren unbefristeten Stellen, dauern Verträge meistens nur ein bis drei Jahre [\[LR1\]](#_msocom_1) und haben oft einen Umfang von weniger als 100% [\[LR2\]](#_msocom_2) - während es allerdings unüblich ist, mit weniger als 40 Stunden pro Woche (zumindest wurde das mir zu Beginn meiner Promotion erklärt). Während ein Großteil aller wissenschaftlichen Veröffentlichungen auf Studien beruht, die im Rahmen von Doktorarbeiten durchgeführt wurden, sind Doktorand\*innen gleichzeitig diejenigen Personen im System, die den geringsten Wert haben bzw. deren Arbeitskraft am günstigsten ist. Mentale Probleme wie Burnout oder Depressionen sind unter Promovierenden weit verbreitet (Jaremka et al., 2020; Liu et al., 2019). Den Weg zur Professur schaffen vor allem die Personen erfolgreich, die viele Artikel in prestigeträchtigen Zeitschriften veröffentlichen. Durch die immense Arbeitsbelastung und große Zahl an Artikeln, die bei Fachzeitschriften eingereicht werden, ist keine Zeit mehr, Ergebnisse genau zu prüfen und nachzurechnen (Nuijten et al., 2017) sondern es wird vor allem darauf geachtet, wie eindeutig die Ergebnisse die Fragestellung beantworten - oder genauer gesagt: bestätigen (Mynatt et al., 1977). Mit anderen Worten: Es wird ausgerechnet der Teil der wissenschaftlichen Arbeit belohnt, der nicht in der Hand der Forschenden liegt, nämlich die Ergebnisse von Untersuchungen. Veröffentlichte Artikel und Prestige statt Qualität (Brembs, 2018) sind ab dort die Währung der Wissenschaft: Auf ihrer Basis wird entschieden, wer Forschungsgelder erhält und auf Basis von Forschungsgeldern und Publikationen werden Professuren vergeben. In den darüber entscheidenden Berufungskommissionen lesen die Beteiligten üblicherweise nicht die Artikel der Bewerbenden, sie zählen bloß, wie viele in welchen Zeitschriften aufgelistet werden. Im Folgenden gehe ich auf die einzelnen Probleme näher ein.

Zu diesen verheerenden Problemen kommen außerdem systemische Probleme der sexuellen Belästigung (Hoebel et al., 2022) und des Machtmissbrauches, die in dem aktuell streng hierarchischen Aufbau des Systems nur schwierig zu lösen sind (REF[\[LR3\]](#_msocom_3) , siehe auch <https://www.netzwerk-mawi.de/> und <https://www.jmwiarda.de/2023/11/20/das-stille-leiden-der-betroffenen/>). Wer es in dabei besonders leicht hat, erklären Elsherif et al. (2022) anschaulich an dem „Academic Wheel of Privilege" (S. 85; siehe auch <https://www.psychologicalscience.org/observer/gs-navigating-academia-as-neurodivergent-researchers>). Beispielsweise haben Doktorandinnen [\[LR4\]](#_msocom_4) in den Niederlanden vor allem dann schlechtere Noten als Doktoranden bekommen, wenn der Promotionsausschuss nur aus Männern bestand (REF[\[LR5\]](#_msocom_5) ).

### **Zu viel Forschung**

Im Rahmen von Promotionen müssen Forschende in insgesamt 3-6 Jahren üblicherweise drei wissenschaftliche Artikel veröffentlichen (bzw. in fairen Fällen drei veröffentlichungs-*würdige* Artikel vorweisen). Bei Post Docs, also Personen nach der Promotion und vor dem Wissenschaftsausschluss beziehungsweise in selteneren Fällen der Professur (siehe Kapitel XXX) müssen es noch mehr sein. Für eine Habilitation, für die eine ähnliche Zeit angesetzt ist, sind circa 6 Artikel die Daumenregel. Dabei spielt es eine nachrangige Rolle, wie umfangreich die Artikel sind. Beispielsweise dauert die Durchführung einer Meta-Analyse, in der bisherige Befunde zu einem bestimmten Thema systematisch gesammelt und statistisch zusammengefasst bzw. verglichen werden, oft mehrere Jahre. Eine Querschnittserhebung über einen Online-Fragebogen lässt sich in wenigen Wochen durchführen. Eine Doktorandin, die eine einzige Meta-Analyse durchführt, könnte damit nicht promovieren. Hätte sie stattdessen drei einfache Online-Studien durchgeführt und einzeln veröffentlicht, wäre es kein Problem.[\[1\]](#_ftn1) Diese willkürlichen Vorgaben haben dazu geführt, dass sich Wissenschaftler\*innen alleine durch die Begutachtung der Artikel ihrer Kolleg\*innen einen enormen Arbeitsaufwand auferlegen, der den wissenscchaftlichen Fortschritt behindert (Hanson et al., 2023).

Zur Veranschaulichung des Aufgabenpensums nun ein Gedankenspiel: Angenommen es gäbe 10 Wissenschaftler\*innen, die gemeinsam 10 Artikel im Jahr veröffentlichen würden - manchmal alleine, manchmal in einer Gruppe - und jeder der Artikel würde von zwei Personen begutachtet, so müsste jede\*r zwei Artikel begutachten. Damit das System funktioniert, müsste jede Person die Anzahl der im Schnitt veröffentlichten Artikel mal die Anzahl der benötigten Gutachtenden begutachten. Bei 10 Veröffentlichungen pro Person und drei Gutachtenden wären es 10x3=30 Gutachten. Nun werden aber nicht alle Artikel von der Zeitschrift, bei der sie eingereicht werden, veröffentlicht, noch werden sie sofort veröffentlicht. Wissenschaftler\*innen reichen ihre Artikel oft bei den "hochrangigsten" Zeitschriften ein. Nachdem dort mehrere Gutachter\*innen den Artikel geprüft haben, wird er abgelehnt (Jaremka et al., 2020). Mindestens werden Revisionen angefordert, welche oft eine weitere Runde peer-review auslösen und nicht immer werden Artikel danach veröffentlicht. Unsere Rechnung geht also nicht auf: Nehmen wir *vorsichtshalber* an, ein Artikel würde neun Mal begutachtet (z.B. einmal drei Gutachtende, dann Ablehnung, dann erneut drei Gutachtende, Revision, zweites Gutachten, Akzeptanz). Aus 10x3 wird 10x9, bei etwas Urlaubszeit also etwas mehr als zwei Gutachten pro Woche, idealerweise bis zu zwei Arbeitstage. Bei dieser Rechnung bleibt weniger Zeit für Lehre, Wissenstransfer, Betreuung von Studierenden oder Promovierenden, Einwerbung von Forschungsgeldern, universitäre Selbstverwaltung, usw. Durch die vielen zu publizierenden Artikel und das strenge Review-System bürgt sich die Wissenschaft einen großen Berg Arbeit auf - einen der realistisch nicht machbar ist und unter dem am Ende die Qualität der Forschung leidet. Beispielsweise fiel es weder den Gutachtenden, noch den Herausgebern von Zeitschriften auf, dass in über 30 Artikeln mitten im Text „Regenerate response" stand -- ein Satz, der in OpenAIs ChatGTP Programm auf einem Knopf erlaubt, einen von einer künstlichen Intelligenz erstellten Text umzuformulieren (<https://retractionwatch.com/2023/10/06/signs-of-undeclared-chatgpt-use-in-papers-mounting/>). In manchen Artikeln hieß es sogar „As an AI language model, I ..." ([https://pubpeer.com/search?q="As+an+AI+language+model%2C+I](https://pubpeer.com/search?q=%22As+an+AI+language+model%2C+I)"). In einem Fall wurde der Artikel von dem Verlag Elsevier geändert, und zwar nicht auf dem empfohlenen Weg[\[2\]](#_ftn2) mittels eines transparenten Errandum oder Corrigendum, also einer öffentlichen Mitteilung über die Änderung und ihre Gründe, sondern ohne Erklärung oder Zustimmung der Autor\*innen (<https://predatory-publishing.com/elsevier-changed-a-published-paper-without-any-explanation/>).

### Publish or Perish[\[LR6\]](#_msocom_6) 

Wer in der Wissenschaft arbeitet sollte die wichtigste Spielregel kennen: Wer überleben will, muss Artikel veröffentlichen. Zur Promotion, Habilitation, Einwerbung von Forschungsgeldern, und zur Berufung auf eine Professur sind Veröffentlichungen das oberste Kriterium. Kennzeichen einer Währung ist, dass sich Dingen ein Wert zuweisen lässt. Wie sieht der Wert in der Forschung aus?

Bibliometriker\*innen entwarfen zur Beschreibung (also explizit nicht zur Bewertung) verschiedener Forschungsgebiete verschiedene Kennzahlen, wie den Impact Factor, oder Hirsch-Index. \[ERKLÄRUNGEN\] - impact factor - h index - ccc factor.

IF wird geschönigt (REF[\[LR7\]](#_msocom_7) ), gehört Verlag, der damit Geld verdient, ist inflationiert, selbe Jahre erhalten unterschiedliche Werte: <https://quantixed.org/2016/01/05/the-great-curve-ii-citation-distributions-and-reverse-engineering-the-jif/>

Evidenz, dass methodische Sauberkeit negativ bis gar nicht mit traditionellen Produktivitätsmetriken zusammenhängt (deutlich negativ mit Zitationszahlen und h-index). <https://www.researchgate.net/publication/380433173_Inter-Rater_Reliability_in_Assessing_the_Methodological_Quality_of_Research_Papers_in_Psychology> Table 3

Seit längerem wird für die verantwortungsvolle Verwendung dieser Metriken plädiert [\[LR8\]](#_msocom_8) (Hicks et al., 2015). Wie sich Anreizstrukturen und Karrierestatus auf wissenschaftliches Fehlverhalten auswirken wird mit gemischten Ergebnissen untersucht (REF[\[LR9\]](#_msocom_9) ). Das Problem: Sobald es in einem System ein klares Bewertungskriterium gibt, wird alles darauf ausgerichtet.

Das hat zum Beispiel dazu geführt, dass die meisten in der Psychologie entwickelten Instrumente zur Messung von Persönlichkeitseigenschaften nur wenige Male verwendet werden -- und das auch hauptsächlich von ihren eigenen Entwickler\*innen (Elson et al., 2023). Ein noch extremerer Ausmaß ist bei sogenannten „Paper Mills" zu sehen (van Noorden, 2023): Personen erstellen dabei automatisiert große Mengen von wissenschaftlichen Artikeln, nur ohne die darin beschriebenen Untersuchungen wirklich durchzuführen. Wissenschaftler\*innen können dann Ko-Autor\*innenschaften kaufen. Je nach Zeitschrift werden diese Artikel nicht im Peer-Review aufgedeckt. Es wird befürchtet, dass Käufer\*innen solcher Artikel selbst sehr erfolgreich werden können, selbst Herausgeber von Zeitschriften werden, und sich dadurch vor Entlarvung beschützen. Der genaue Ausmaß des Paper-Mill-Problems ist unklar und weitgehend unerforscht (Byrne & Christopher, 2020). Ein Indiz, mithilfe künstlicher Intelligenz erstellte Artikel zu erkennen sind sogenannte „tortured phrases" (Cabanac et al., 2021).

### Flaschenhals-Hypothese und Innovationsdrang

Namhafte wissenschaftliche Zeitschriften erhalten täglich unzählige Einreichungen, veröffentlichen aber nur eine begrenzte Anzahl an Artikeln. Sie müssen also streng selektieren, was begutachtet und gegebenenfalls veröffentlicht wird. Weil das Ziel einer Zeitschrift ist, viel gelesen zu werden, wählen Herausgeber\*innen von Zeitschriften diejenigen Artikel, welche möglichst großes Potenzial haben, bekannt und viel zitiert zu werden (Giner-Sorolla, 2012). Das betrifft zum Beispiel Beiträge mit besonderen praktischen Implikationen, überraschenden Befunden, oder besonders konsistenten Befunden. Studien, deren Ergebnisse keine eindeutigen Schlüsse zulassen -- oder deren Autor\*innen mit zu großer Vorsicht Schlüsse ziehen -- kommen also nicht infrage. In den Neurowissenschaften kommunizieren manche Zeitschriften beispielsweise öffentlich, dass sie keine Replikationsstudien veröffentlichen und nach Neuheit selektieren, während die meisten keine Stellung dazu nehmen (Yeung, 2017). In der Psychologie nahmen 2017 nur 33 von 1151 Zeitschriften Stellung dazu, dass sie Replikationen akzeptieren (Martin & Clarke, 2017). Zwar werden innovative Befunde dann häufiger zitiert, die Zeitschrift erhält also mehr Leser\*innen, mehr Einreichungen, und damit mehr Geld über Abonnements und Veröffentlichungskosten, vielzitierte Artikel lassen sich jedoch schlechte replizieren als weniger zitiert (Serra-Garcia & Gneezy, 2021) und prestigereiche Zeitschriften sing Magneten für fragwürdige Forschungspraktiken (Kepes et al., 2022) und nachweisbar gleichwertige oder sogar qualitativ schlechtere Forschung (Brembs, 2018).[\[LR10\]](#_msocom_10) 

Wie kommt es dazu? Diese strenge Selektion, die einem Flaschenhals ähnelt (viele Einreichungen aber wenige Veröffentlichungen) führt gemeinsam mit dem Anreiz in eben solchen Zeitschriften zu publizieren dazu, dass Forschende alle möglichen Mittel nutzen, um eine Chance auf eine Publikation zu erhalten. Die Tatsache, dass prestigereiche Zeitschriften wie Nature Human Behavior vor allem Artikel mit klaren Botschaften veröffentlichen[\[LR11\]](#_msocom_11) , spornt also Forschende an, klare Ergebnisse zu berichten. Passt mal ein Befund nicht zu der geprüften Hypothese, wird er nicht veröffentlicht und landet in der Schublade.

### Schubladen-Problem[\[LR12\]](#_msocom_12) 

Seit mehreren Jahrzehnten ist bekannt, dass Wissenschaftler\*innen vor allem diejenigen Studien veröffentlichen, die ihre Theorien stützen (REF; rosenthal; sterling). Im Extremfall hat jemand zum Prüfen einer Theorie fünf Studien durchgeführt, in nur einer davon die Theorie bestätigt, und nur diese veröffentlicht. Andere Forschende, die dann die (veröffentlichte) Literatur durchsuchen, sehen nur die "erfolgreiche" Studie. Es entsteht der Eindruck, dass die Theorie stimmt, während die Mehrheit der Studien diesen Schluss eigentlich nicht nahelegt. Durch dieses Problem konnten sich ganze Forschungsstränge entwickeln, die seit dem Bewusstsein für Replikationsstudien komplett ausgestorben sind (Brockman, 2022).

Für Meta-Analysen, also Studien, die bisherige Befunde zusammenfassen, wurden bereits verschiedene Methoden entwickelt, die Stärke des Schubladen-Problems (engl. File-Drawer-Problem) zu prüfen. Auch Methoden, die dadurch entstandene Verzerrung zu korrigieren existieren bereits vielzählige (REF, PET-PEESE, p-uniform\*, robust bayesian meta-analysis robumeta, hedges vevea selection models). Allerdings funktioniert keine der Methoden in allen möglichen Szenarien (Carter et al., 2019). Um eine Veröffentlichung der fehlgeschlagenen Studien werden wir möglicherweise nicht herumkommen.

In der Medizin gibt es den besonderen Fall, dass alle dort durchgeführten Studien öffentlich registriert [\[LR13\]](#_msocom_13) werden müssen. Bei einer Veröffentlichung muss dann eine Registrierungsnummer angegeben werden. Über öffentliche Angaben zu registrierten Studien lässt sich somit nachverfolgen, welche Personen, Institutionen, oder Länder wie viele ihrer tatsächlich durchgeführten Studien veröffentlichen. Forschende haben dazu ein sogenanntes Dashboard entwickelt [(Franzen et al., 2023; Riedel et al., 2022)](https://www.jclinepi.com/article/S0895-4356(21)00414-5/fulltext) mittels dem nach aktuellem Stand (Herbst 2023, <https://quest-cttd.bihealth.org/>) nachvollziehbar ist, dass unter den registrierten Studien, die auf die Registrierung verweisen, nur 46% innerhalb der folgenden zwei Jahre und 74% innerhalb der folgenden fünf Jahre veröffentlicht wurden. Personen, die sich für die Studien als Versuchspersonen melden oder Drittmittelgeber erhalten somit Aufschluss über die Größe der Schublade, „in der die nicht so spannenden Ergebnisse landen".

### Konzerne

-          <https://stoptrackingscience.eu>

### Zugängigkeit von Wissen

-          Global south

-          Paywalls

-          Soziales Dilemma

-          VG Wort[\[LR14\]](#_msocom_14) ?

[\[1\]](#_ftnref1) Hier ließe sich einwenden, dass einige Zeitschriften nur Artikel veröffentlichen, in denen mehrere Studien durchgeführt wurden. Das Ziel, nämlich die Replikation der eigenen Befunde, verfehlen diese Zeitschriften damit deutlich. Stattdessen reizt es Forschende dazu an, mehrere Studien mit wenigen Versuchspersonen durchzuführen, statt eine Studie mit vielen Befragten.

[\[2\]](#_ftnref2) Ethische Richtlinien im Publikationsprozess sind zum Beispiel verfügbar über das Committee on Publication Ethics (<https://publicationethics.org/guidance/Guidelines>).

 [\[LR1\]](#_msoanchor_1)REF?

 [\[LR2\]](#_msoanchor_2)REF?

 [\[LR3\]](#_msoanchor_3)<https://onlinelibrary.wiley.com/doi/10.1002/joe.21897>

 [\[LR4\]](#_msoanchor_4)<https://www.laborjournal.de/rubric/essays/essays2023/e23_09.php>

Quote schwerbehinderter extrem niedrig (1% unter wiss Mas) und Ignoranz von Quoten in der Wissenschaft

 [\[LR5\]](#_msoanchor_5)https://www.nature.com/articles/s41598-023-46375-7

 [\[LR6\]](#_msoanchor_6)Liste: World's Top 2% most influential scientists à fehlerhaft <https://www.authorea.com/users/571220/articles/620441-a-critical-analysis-of-the-world-s-top-2-most-influential-scientists-examining-the-limitations-and-biases-of-highly-cited-researchers-lists>

 [\[LR7\]](#_msoanchor_7)<https://osf.io/preprints/socarxiv/5t8v7?fbclid=IwZXh0bgNhZW0CMTAAAR0fPKhqCqVY5GIVdZp5TWvlOmBE_m-NdchII9TDpy3Nd5uarSltMcxuEnE_aem_AZ1HBApXlv6zfx2OE42kC-JUhL46lvBK94fnsx2udMBZ7L__WdOVM3iSlXFRgD7MscOgnIZe1y-6Vjlnz7uHAX9W>

 [\[LR8\]](#_msoanchor_8)COARA + SF DORA

 [\[LR9\]](#_msoanchor_9)<https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0255334>

 [\[LR10\]](#_msoanchor_10)+ <https://osf.io/preprints/psyarxiv/4w7rb>

 [\[LR11\]](#_msoanchor_11)<https://www.frontiersin.org/articles/10.3389/fnhum.2018.00037/full>

-          gute Zeitschriften haben schlechtere Qualität\
<https://doi.org/10.1107/S0907444907033847>

-          impact factor ist verhandelbar und inflated:\
<https://quantixed.org/2016/01/05/the-great-curve-ii-citation-distributions-and-reverse-engineering-the-jif/>

-          **noch viele weitere Beispiele im Paper, felderübergreifend entweder kein Zusammenhang oder negativer Zusammenhang**

-          höherer Impact Factor geht mit von Excel zerstörten Gen-Namen einher (Excel denkt, es seien Datumsangaben, konvertiert sie, und man kriegt die eigentlichen Werte nicht wieder): <https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-1044-7#:~:text=Indeed%2C%20the%20number%20of%20papers,(3.8%20%25%20per%20year)>.

Alternative Auswahlkriterien

-          Schauen, mit wem man Kollege sein möchte

-          „Wie gut komplementiert das die Expertise" statt „macht die Person, was ich mache" (nötig für Forschungsgelder)

-          Jemanden, mit dem man eng zusammenarbeit, findet man auch online; interessant wird es, wenn jemand von wo ganz anders kommt; etwas, was man nicht online findet

-          Sehr vorsichtig sein mit quantitativen Maßen, bei vielen Bewerber\*innen aber schwierig; wenn, dann bräuchte man viele, die genau auf den Bedarf zugeschnitten ist

 [\[LR12\]](#_msoanchor_12)Problem von Nullbefunden erklären, 7 Alternativerklärungen

<https://www.cambridge.org/core/journals/journal-of-experimental-political-science/article/more-than-meets-the-itt-a-guide-for-anticipating-and-investigating-nonsignificant-results-in-survey-experiments/C01250EB50598D6328B6065F1DF86BA7?utm_source=hootsuite&utm_medium=twitter&utm_campaign=MNE_campaign>

 [\[LR13\]](#_msoanchor_13)Warum? Ethic-gutachten?

 [\[LR14\]](#_msoanchor_14)https://de.wikipedia.org/wiki/Verwertungsgesellschaft_Wort

### Literatur
