---
title: "Das System"
editor: visual
format: html
bibliography: references.bib
bibliographystyle: apa
---

## Probleme des Wissenschaftlichen Systems

Neben dem Idealbild davon, was Wissenschaft sein sollte oder wie sie funktionieren sollte, existiert die Wissenschaft, wie sie in unser Gesellschaftssystem integriert ist. Besonderheiten sind dabei, dass Wissenschaftler\*innen ihre Tätigkeit als Beruf ausüben, also Geld dabei verdienen. Wie das Geld, das größtenteils aus Steuergeldern stammt, verteilt werden soll entscheiden Gremien, die wiederum selbst aus Wissenschaftler\*innen bestehen (*akademische Selbstverwaltung*). Durch die hohe Arbeitsbelastung, gleichzeitig Wissenschaft zu betreiben und zu verwalten, vereinfachen sich die Entscheider\*innen die Arbeit und verwenden zur Auswahl hochqualifizierter Personen Abkürzungen. So konnte es passieren, dass die Währung in der Wissenschaft zum Großteil die Anzahl der in Fachzeitschriften veröffentlichten Forschungsartikel (*Paper*) ist. Ein weiterer verwendeter Indikator ist die Anzahl, in wie vielen weiteren wissenschaftlichen Artikeln auf die Forschung einer Person verwiesen wird, also die Zitationszahlen. Vorbilder wie Charles Darwin oder William James und selbst aktuelle Nobelpreisträger hätten nach dem heutigen Maßstab keine Chance auf eine unbefristete Stelle in der Wissenschaft - sie haben einfach nicht genug Paper geschrieben. Viele der hier diskutierten Problemen, sind beispielsweise in der Psychologie seit mehreren Jahrzehnten bekannt, sodass eine Replikationskrise unabwendbar erschienen haben muss [@Cronbach.1991; @Greenwald.1976].

### Wissenschaft versus Academia

Während einige Natur- und Sozialwissenschaften in ihrer Anfangszeit oft von Buchveröffentlichungen lebten und darin eine umfangreiche Basis von meist einzelnen Personen erarbeitet wurde (z.B. Galileo Galilei für die Physik oder William James für die Psychologie) stehen heutzutage wissenschaftliche Fachzeitschriften im Fokus. Diese Zeitschriften sind vergleichbar mit solchen, die es im Kiosk und im Supermarkt gibt, nur bestehen sie halt aus (meist englischsprachigen) Artikeln, die Wissenschaftler\*innen verfasst haben und sind in vielen Fällen nur noch online oder in Hochschulbibliotheken erhältlich. Forschende laden sich dann einzelne Artikel aus den Zeitschriften aus dem Internet über das Hochschulnetezwerk herunter und Bibliotheken haben Verträge mit Verlagen und zahlen Geld, damit Universitätsangehörige Zugriff zu den Katalogen haben. Jeder eingereichte Artikel befasst sich mit einer Fragestellung, die von den Forschenden selbst festgelegt wurde (z.B. wie viele psychologische Studien lassen sich im Mittel replizieren?). Darin werden meistens Studien mit deren Ergebnissen berichtet. Vor der Veröffentlichung werden die Artikel begutachtet (*Review*) -- nicht von Mitarbeitenden der Zeitschrift sondern von Kolleg\*innen (*Peers*). Mit diesem *Peer-Review* soll die Qualität von Forschung sichergestellt werden. Üblicherweise wird dabei darauf geachtet, dass die Schlussfolgerungen auf Basis der erhobenen Daten gerechtfertigt sind, die Fragestellung klar beantwortet wird, der Artikel verständlich ist, und die Befunde spannend oder überraschend sind. Zeitschriften unterscheiden sich darin, welche Themen sie abdecken (z.B. Sozialpsychologie, Konsumentenverhalten, Angewandte Sportwissenschaft, usw.), wie streng das Peer-Review ist, und von wie vielen Forschenden sie gelesen und zitiert werden. Wissenschaften sind also stark integriert in ein System, das Forschenden und Verlagen erlaubt, ein festes Gehalt zu verdienen.

### Prekäre Arbeitsbedingungen {#sec-arbeitsbedingungen}

Soweit der Rahmen: Wissenschaftler\*innen forschen und teilen ihre Ergebnisse meist in Form von *Publikationen* wie Zeitschriftenartikel- oder Buch-Veröffentlichungen. Was die Jobs in der Wissenschaft (also vorwiegend an Hochschulen) angeht, so sind sie hierarchisch strukturiert. Es gibt wenige unbefristete Stellen, meist Professuren, und darunter befristete Stellen für Promovierende und bereits promovierte *Post Docs*. Wer in der Wissenschaft arbeitet, befindet sich meistens in einem harten Konkurrenzkampf um eine der wenigen unbefristeten Stellen [@Rahal.2023]. Der Hintergedanke ist dabei, dass Konkurrenz zwischen Forschenden die Produktivität steigern möge. Vom Start der Promotion[^probleme_system-1] bis zur Berufung auf eine Professur, also eine der raren unbefristeten Stellen, dauern Verträge meistens nur ein bis drei Jahre und haben oft einen Umfang von weniger als 100%. Gleichzeitig ist es unüblich ist, mit weniger als 40 Stunden pro Woche innerhalb von den typischen drei Jahren die Promotion erfolgreich abzuschließen. Während ein Großteil aller wissenschaftlichen Veröffentlichungen auf Studien beruht, die im Rahmen von Doktorarbeiten durchgeführt wurden, sind Doktorand\*innen gleichzeitig diejenigen Personen im System, die den geringsten Wert haben bzw. deren Arbeitskraft am günstigsten ist. Forschende auf befristeten Stellen sind also einem enormen Leistungsdruck ausgesetzt. Psychische Probleme wie Burnout oder Depressionen sind unter Promovierenden weit verbreitet [@Jaremka.2020; @Liu.2019]. Den Weg zur Professur schaffen vor allem die Personen erfolgreich, die viele Artikel in prestigeträchtigen Zeitschriften veröffentlichen. Durch die immense Arbeitsbelastung und große Zahl an Artikeln, die bei Fachzeitschriften eingereicht werden, ist keine Zeit mehr, Ergebnisse genau zu prüfen und nachzurechnen [@Nuijten.2017], sondern es wird vor allem darauf geachtet, wie eindeutig die Ergebnisse die Fragestellung beantworten - oder genauer gesagt: bestätigen [@GinerSorolla.2012; @Mynatt.1977]. Mit anderen Worten: Es wird ausgerechnet der Teil der wissenschaftlichen Arbeit belohnt, der nicht in der Hand der Forschenden liegt, nämlich die Ergebnisse von Untersuchungen. Veröffentlichte Artikel und Prestige statt Qualität [@Brembs.2018] sind ab dort die Währung der Wissenschaft: Auf ihrer Basis wird entschieden, wer Forschungsgelder erhält und auf Basis von Forschungsgeldern und Publikationen werden Professuren vergeben. In den darüber entscheidenden Berufungskommissionen lesen die Beteiligten üblicherweise nicht die Artikel der Bewerbenden, sie zählen bloß, wie viele in welchen Zeitschriften aufgelistet werden. Teilweise werden die Bewerber\*innen gebeten, Zitationszahlen anzugeben. Manche dieser Zahlen (z.B. Impact Factor) gehören Unternehmen an und der Zugang muss über die Institution erkauft werden.

[^probleme_system-1]: Prozess der Erlangung eines Doktorgrades/Doktortitles, je nach Disziplin und Hochschule durch das Verfassen eines Buches (Monografie) oder mehrerer Zeitschriftenartikel (kumulative Promotion)

Zu diesen verheerenden Problemen kommen außerdem systemische Probleme der sexuellen Belästigung [@Hoebel.2022] und des Machtmissbrauches, die in dem aktuell streng hierarchischen Aufbau des Systems nur schwierig zu lösen sind (@Forster2018-up, siehe auch <https://www.netzwerk-mawi.de/> und <https://www.jmwiarda.de/2023/11/20/das-stille-leiden-der-betroffenen/>). Berichten des Netzwerkes gegen Machtmissbrauch in der Wissenschaft werden Fälle verschwiegen, und die schuldigen wechseln stillschweigend die Universität, sodass das Problem nicht gelöst wird. Wer es dabei besonders leicht hat, erklären @Elsherif.2022 anschaulich an dem *Academic Wheel of Privilege* ("Akademisches Rad der Privilegierten"; S. 85; siehe auch <https://www.psychologicalscience.org/observer/gs-navigating-academia-as-neurodivergent-researchers>). Beispielsweise haben Doktorandinnen in den Niederlanden vor allem dann schlechtere Noten als Doktoranden bekommen, wenn der Promotionsausschuss, also die Gruppe an Professor\*innen, die die Promotion beurteilt, nur aus Männern bestand [@Bol2023-ij]. Schwerbehindertenquoten weit unter den [Quoten](https://www.laborjournal.de/rubric/essays/essays2023/e23_09.php) anderer Berufe kommen ebenfalls hinzu.

### **Zu viel Forschung**

Im Rahmen von Promotionen müssen Forschende in insgesamt 3-6 Jahren zuzüglich Elternzeiten üblicherweise drei wissenschaftliche Artikel veröffentlichen (bzw. in fairen Fällen drei veröffentlichungs-*würdige* Artikel vorweisen). Bei Post Docs (siehe @sec-arbeitsbedingungen) müssen es noch mehr sein. Dass Personen vor und nach der Promotion jeweils maximal 6 Jahre an Hochschulen angestellt sein dürfen ist gesetzlich festgelegt. Für die weitere Qualifikation *Habilitation*, für die eine ähnliche Zeit angesetzt ist, sind zum Beispiel in der Psychologie circa 6 Artikel die Daumenregel. Dabei spielt es eine nachrangige Rolle, wie umfangreich die Artikel sind. Beispielsweise dauert die Durchführung einer Meta-Analyse, in der bisherige Befunde zu einem bestimmten Thema systematisch gesammelt und statistisch zusammengefasst bzw. verglichen werden, oft mehrere Jahre. Eine Längsschnitterhebung kann je nach Forschungsfrage sogar Jahrzehnte dauern. Im Kontrast dazu lässt sich eine Querschnittserhebung über einen Online-Fragebogen in wenigen Wochen durchführen. Eine Doktorandin, die eine einzige Meta-Analyse durchführt, könnte damit nicht promovieren. Hätte sie stattdessen drei einfache Online-Studien durchgeführt und einzeln veröffentlicht, wäre es kein.[^probleme_system-2] Diese willkürlichen Vorgaben haben dazu geführt, dass sich Wissenschaftler\*innen alleine durch die Begutachtung der Artikel ihrer Kolleg\*innen einen enormen Arbeitsaufwand auferlegen, der den wissenscchaftlichen Fortschritt behindert [@Hanson.2023].

[^probleme_system-2]: Hier ließe sich einwenden, dass einige Zeitschriften nur Artikel veröffentlichen, in denen mehrere Studien durchgeführt wurden. Das Ziel, nämlich die *internale* Replikation der eigenen Befunde, verfehlen diese Zeitschriften damit deutlich. Stattdessen reizt es Forschende dazu an, mehrere Studien mit wenigen Versuchspersonen durchzuführen, statt eine Studie mit vielen Befragten.

Zur Veranschaulichung des Aufgabenpensums nun ein Gedankenspiel: Angenommen es gäbe 10 Wissenschaftler\*innen, die gemeinsam 10 Artikel im Jahr veröffentlichen würden - manchmal alleine, manchmal in einer Gruppe - und jeder der Artikel würde von zwei Personen begutachtet, so müsste jede\*r zwei Artikel begutachten. Damit das System funktioniert, müsste jede Person die Anzahl der im Schnitt veröffentlichten Artikel mal die Anzahl der benötigten Gutachtenden begutachten. Bei 10 Veröffentlichungen pro Person und drei Gutachtenden wären es 10x3=30 Gutachten. Nun werden aber nicht alle Artikel von der Zeitschrift, bei der sie eingereicht werden, veröffentlicht, noch werden sie sofort veröffentlicht. Wissenschaftler\*innen reichen ihre Artikel oft bei den "hochrangigsten" Zeitschriften ein. Nachdem dort mehrere Gutachter\*innen den Artikel geprüft haben, wird er abgelehnt [@Jaremka.2020]. Im Mindestfall werden Revisionen angefordert, welche oft eine weitere Runde Peer Review auslösen und nicht immer werden Artikel danach veröffentlicht. Unsere Rechnung geht also nicht auf: Nehmen wir *vorsichtshalber* an, ein Artikel würde neun Mal begutachtet (z.B. einmal drei Gutachtende, dann Ablehnung, dann erneut drei Gutachtende, Revision, zweites Gutachten, Akzeptanz). Aus 10x3 wird 10x9, bei etwas Urlaubszeit also etwas mehr als zwei Gutachten pro Woche, idealerweise bis zu zwei Arbeitstage. Bei dieser Rechnung bleibt weniger Zeit für Lehre, Wissenstransfer, Betreuung von Studierenden oder Promovierenden, Einwerbung von Forschungsgeldern, universitäre Selbstverwaltung, usw. Durch die vielen zu publizierenden Artikel und das strenge Review-System bürgt sich die Wissenschaft einen großen Berg Arbeit auf -- einen der realistisch nicht machbar ist und unter dem am Ende die Qualität der Forschung leidet. Beispielsweise fiel es weder den Gutachtenden, noch den Herausgebern von Zeitschriften auf, dass in über 30 Artikeln mitten im Text „Regenerate response" stand -- ein Satz, der in OpenAIs ChatGTP Programm auf einem Knopf erlaubt, einen von einer künstlichen Intelligenz erstellten Text umzuformulieren (<https://retractionwatch.com/2023/10/06/signs-of-undeclared-chatgpt-use-in-papers-mounting/>). In manchen Artikeln hieß es sogar „As an AI language model, I ..." ([https://pubpeer.com/search?q="As+an+AI+language+model%2C+I](https://pubpeer.com/search?q=%22As+an+AI+language+model%2C+I)"). In einem Fall wurde der Artikel von dem Verlag Elsevier geändert, und zwar nicht auf dem empfohlenen Weg[^probleme_system-3] mittels eines transparenten *Errandum* oder *Corrigendum*, also einer öffentlichen Mitteilung über die Änderung und ihre Gründe, sondern ohne Erklärung oder Zustimmung der Autor\*innen (<https://predatory-publishing.com/elsevier-changed-a-published-paper-without-any-explanation/>).

[^probleme_system-3]: Ethische Richtlinien im Publikationsprozess sind zum Beispiel verfügbar über das Committee on Publication Ethics (<https://publicationethics.org/guidance/Guidelines>).

### Publish or Perish -- Veröffentlichen oder Verenden

Wer in der Wissenschaft arbeitet sollte die wichtigste Spielregel kennen: Wer überleben will, muss Artikel veröffentlichen. Kurz: Veröffentlichen oder Verenden (engl. *publish or perish*). Zur Promotion, Habilitation, Einwerbung von Forschungsgeldern, und zur Berufung auf eine Professur sind Veröffentlichungen das oberste Kriterium. Kennzeichen einer Währung ist, dass sich Dingen ein Wert zuweisen lässt. Wie sieht der Wert in der Forschung aus? Bibliometriker\*innen entwarfen zur Beschreibung und zur Auswahl von Zeitschriftenabonnements (also explizit *nicht zur Bewertung*) verschiedener Forschungsgebiete verschiedene Kennzahlen, wie den Impact Factor, oder Hirsch-Index. Beide Zahlen bestehen aus Verrechnungen davon, wie oft Artikel je nach Zeitschrift oder je nach Person zitiert wurden. Beispielsweise werden beim Journal Impact Factor die Gesamtzahl der Zitationen in einem bestimmten Jahr durch die Anzahl der zitierbaren Veröffentlichungen in Bezugsjahren (z.B. den 3 vorangegangenen Jahren) geteilt. Zeitschriften werden mit hohen Impact Factors beworben und erlauben teilweise nicht die Zitation von Kommentaren (bzw. veröffentlichen Kommentare unter derselben Referenz wie Originalstudien), um möglichst hohe Impact Factors zu erhalten. Sie können natürlich auch entscheiden, ob sie den 3-Jahres- oder 2-Jahres Impact Factor berichten. Berechnungsweisen unterscheiden sich außerdem darin, auf Basis welcher Daten sie errechnet werden. Die Datenbank des Journal Impact Factors gehört dem Unternehmen Clarivate Analytics und ist nicht öffentlich zugängig. Das heißt, die genauen Zahlen lassen sich nicht einfach nachrechnen und prüfen. Durch die wichtige und intransparente Rolle von Zitationsmetriken ist wenig überraschend, dass sie [manipuliert](https://quantixed.org/2016/01/05/the-great-curve-ii-citation-distributions-and-reverse-engineering-the-jif) werden und dass [3 der Top 10 Zeitschriften in einem Bereich gar keine wissenschaftlichen Zeitschriften sind](https://retractionwatch.com/2024/06/12/how-a-widely-used-ranking-system-ended-up-with-three-fake-journals-in-its-top-10-philosophy-list/). Klar ist auch, dass Zitationsmetriken entweder gar nicht oder negativ mit wissenschaftlicher Qualität zusammenhängen [@Brembs.2018; @etzel2024inter; Table 3]. Zum Beispiel gab es das Problem, dass das Programm Microsoft Excel Genomnamen als Datumsangaben erkannt hat, umformatiert hat, und die eigentlichen Namen nicht mehr erkennbar waren. Somit waren Teile der jeweiligen Ergebnisse nutzlos [@ziemann2016gene]. Dieses Problem kam vor allem bei angesehenen Zeitschriften vor. Sie haben nichts dagegen unternommen, stattdessen wurde Excel nach ein paar Jahren angepasst.

Neben Zeitschriften können auch Ranglisten von Personen erstellt werden. Forschende aus Stanford veröffentlichten eine solche Liste der *20 meistzitierten Forschenden.* Abgesehen davon, dass sie zum Missbrauch verführt, enthält zahlreiche Fehler [@Abduh2023-sj] wie zum Beispiel Forschende, die hunderte Jahre lang Artikel veröffentlicht haben -- vor und nach ihrem Tod. Unternehmen, denen Verlage und andere Werkzeuge für die Wissenschaft (z.B. Programme zur Verwaltung von Literatur) gehören, sammeln darüber hinaus Daten über die Forschenden (z.B. welche Artikel wie lange aufgerufen werden, welche Textpassagen markiert werden). Teilweise werden Bibliotheken aufgefordert, Überwachungsprogramme von Verlagen zu installieren. Die gesammelten Daten verkaufen die Verlage dann zurück an die Forschenden. Diese Praxis gefährdet die Wissenschaftsfreiheit, da Staaten Verlage auffordern können, die Namen von Forschenden zu nennen, die zu politisch brisanten Themen forschen. Die Initiative [Stop Tracking Science](https://stoptrackingscience.eu) setzt sich gegen das Verhalten ein.

Seit längerem wird für die verantwortungsvolle Verwendung dieser Metriken plädiert [@Hicks.2015] und zahlreiche Universitäten und Forschende tun sich zusammen um Bewertung von Forschung sinnvoll zu gestalten (z.B. mittels der [San Francisco Erklärung zur Forschungsbewertung](https://sfdora.org/read/read-the-declaration-deutsch/)). Wie sich Anreizstrukturen und Karrierestatus auf wissenschaftliches Fehlverhalten auswirken, wird mit gemischten Ergebnissen untersucht. Das Problem: Sobald es in einem System ein klares Bewertungskriterium gibt, wird alles darauf ausgerichtet (*gaming the system*). Anreizstrukturen, die schlechte Forschung zur Folge haben herrschen in Bezug auf Bildmanipulationen in der Biologie laut @Fanelli2022-tx vor allem in China, weniger jedoch in USA, Großbritannien, und Kanada.

Ein weiteres Produkt der *Publish or Perish Struktur* ist, dass die meisten in der Psychologie entwickelten Instrumente zur Messung von Persönlichkeitseigenschaften nur wenige Male verwendet werden -- und das auch hauptsächlich von ihren eigenen Entwickler\*innen [@Elson.2023]. @Elson.2023 plädieren: Psychologische Messinstrumente sind keine Zahnbürsten! Ein noch extremeres Ausmaß ist bei sogenannten *Paper Mills* zu sehen [@vanNoorden.2023]: Personen erstellen dabei automatisiert große Mengen von wissenschaftlichen Artikeln, ohne die darin beschriebenen Untersuchungen wirklich durchzuführen. Wissenschaftler\*innen können dann Ko-Autor\*innenschaften kaufen, um ihre Anzahl an veröffentlichten Artikeln zu erhöhen und mehr Zitationen zu bekommen. Je nach Zeitschrift werden diese Artikel nicht im Peer-Review entlarvt. Es wird befürchtet, dass Käufer\*innen solcher Artikel selbst sehr erfolgreich werden können, selbst Herausgeber von Zeitschriften werden, und sich dadurch selbst schützen, ertappt zu werden. Der genaue Ausmaß des Paper-Mill-Problems ist unklar und weitgehend unerforscht [@Byrne.2020]. Ein Indiz, mithilfe künstlicher Intelligenz erstellte Artikel zu erkennen sind sogenannte *tortured phrases* [@Cabanac.2021]*,* welche grammatisch korrekt sind, im üblichen Sprachgebrauch jedoch selten vorkommen oder wenig Sinn machen.

### Flaschenhals-Hypothese und Innovationsdrang

Namhafte wissenschaftliche Zeitschriften erhalten täglich unzählige Einreichungen, veröffentlichen aber nur eine begrenzte Anzahl an Artikeln. Sie müssen also streng selektieren, was begutachtet und gegebenenfalls veröffentlicht wird. Weil das Ziel einer Zeitschrift ist, viel gelesen zu werden, wählen Herausgeber\*innen von Zeitschriften diejenigen Artikel, welche möglichst großes Potenzial haben, bekannt und viel zitiert zu werden [@GinerSorolla.2012]. Das betrifft zum Beispiel Beiträge mit besonderen praktischen Implikationen, überraschenden Befunden, oder besonders konsistenten Befunden. Studien, deren Ergebnisse keine eindeutigen Schlüsse zulassen -- oder deren Autor\*innen mit zu großer Vorsicht Schlüsse ziehen -- kommen also nicht infrage. In den Neurowissenschaften kommunizieren manche Zeitschriften beispielsweise öffentlich, dass sie keine Replikationsstudien veröffentlichen und nach Neuheit selektieren, während die meisten keine Stellung dazu nehmen [@Yeung.2017]. In der Psychologie nahmen 2017 nur 33 von 1151 Zeitschriften Stellung dazu, dass sie Replikationen akzeptieren [@Martin.2017]. Zwar werden innovative Befunde oder Befunde, die als innovativ dargestellt werden [@stavrovascientific] häufiger zitiert, die Zeitschrift erhält also mehr Leser\*innen, mehr Einreichungen, und damit mehr Geld über Abonnements und Veröffentlichungskosten, vielzitierte Artikel lassen sich tendenziell jedoch schlechter replizieren als weniger zitiert [@SerraGarcia.2021] und prestigereiche Zeitschriften sind Magneten für fragwürdige Forschungspraktiken [@Kepes.2022] und nachweisbar gleichwertige oder sogar qualitativ schlechtere Forschung [@Brembs.2018]. 

Wie kommt es dazu? Es ist die Rede von einem Flaschenhals (*Bottleneck*; viele Einreichungen aber wenige Veröffentlichungen). Das führt gemeinsam mit dem Anreiz in eben solchen Zeitschriften zu publizieren dazu, dass Forschende alle möglichen Mittel nutzen, um eine Chance auf eine Publikation zu erhalten. In manchen Instituten gilt, wer in einer bestimmten Zeitschrift veröffentlicht, erhält automatisch die Bestnote auf die Promotion. Andere Institute erklären schon in der Stellenausschreibung für eine Promotionsstelle, in welcher Zeitschrift die Ergebnisse des Forschungsprojektes veröffentlicht werden müssen. Die Tatsache, dass prestigereiche Zeitschriften *Nature* oder *Science* vor allem Artikel mit klaren Botschaften veröffentlichen - also Artikel, die auch häufiger gelesen werden [@Stavrova2024-kk] - spornt also Forschende an, klare Ergebnisse zu erschaffen. Passt mal ein Befund nicht zu der geprüften Hypothese, wird er entweder manipuliert oder gar nicht veröffentlicht und landet in der Schublade.

### Schubladen-Problem

Seit mehreren Jahrzehnten ist bekannt, dass Wissenschaftler\*innen vor allem diejenigen Studien veröffentlichen, die ihre Theorien stützen [@Rosenthal.1979; @Sterling.1959]. Im Extremfall hat jemand zum Prüfen einer Theorie fünf Studien durchgeführt, in nur einer davon die Theorie bestätigt, und nur diese veröffentlicht. Andere Forschende, die dann die (veröffentlichte) Literatur durchsuchen, sehen nur die "erfolgreiche" Studie. Es entsteht der Eindruck, dass die Theorie stimmt, während die Mehrheit der Studien diesen Schluss eigentlich nicht nahelegt. Dass Studienergebnisse natürlichen, statistischen Schwankungen unterliegen führt dazu, dass bei vielen Studien auch eine dabei sein kann, die das gewünschte Ergebnis zeit. Durch das Schubladen-Problem konnten sich ganze Forschungsstränge entwickeln, die seit dem Bewusstsein für Replikationsstudien komplett ausgestorben sind (Brockman, 2022).

Für *Meta-Analysen*, also Studien, die bisherige Befunde zusammenfassen, wurden bereits verschiedene Methoden entwickelt, die Stärke des Schubladen-Problems (engl. *File-Drawer-Problem*) zu prüfen. Auch Methoden, diese Verzerrung zu korrigieren, existieren bereits vielzählige [@Fisher.2017; @Hedges.1996; @Schimmack.2020; @Simonsohn.2014; @vanAert.2018b]. Allerdings funktioniert keine der Methoden in allen möglichen Szenarien [@Carter.2019]. Um eine Veröffentlichung der fehlgeschlagenen Studien kommen Forschende also nicht herum.

In der Medizin gibt es den besonderen Fall, dass alle dort durchgeführten Studien öffentlich registriert werden müssen. Bei einer Veröffentlichung muss dann eine Registrierungsnummer angegeben werden. Über öffentliche Angaben zu registrierten Studien lässt sich somit nachverfolgen, welche Personen, Institutionen, oder Länder wie viele ihrer tatsächlich durchgeführten Studien veröffentlichen. Forschende in Berlin haben dazu eine Website mit einem sogenannten interaktiven *Dashboard* entwickelt, um die darüber gesammelten Daten durchsuchen und abbilden zu können [@Franzen.2023; @Riedel.2022]. Auf <https://quest-cttd.bihealth.org/> ist nach aktuellem Stand (Juli 2024) sichtbar, dass von allen registrierten Studien nur 46% innerhalb der folgenden zwei Jahre und 74% innerhalb der folgenden fünf Jahre veröffentlicht wurden. Personen, die sich für die Studien als Versuchspersonen melden oder Drittmittelgeber erhalten somit Aufschluss über die Größe der Schublade, in der die fehlgeschlagenen Studien und die "nicht so spannenden Ergebnisse landen".

### Zugängigkeit von Wissen

Durch die Einbindung von Forschung in das kommerzielle Verlagssystem befindet sich ein Großteil der Wissenschaften in einem sozialen Dilemma, das einen massiv eingeschränkten Zugang zum Wissen zur Folge hat. Das vorherrschende Modell bei wissenschaftlichen Zeitschriften, die zum Großteil Verlagen wie Springer, Elsevier, Sage, oder Taylor and Francis angehören, ist ein Abonnement-Modell. Hochschul-Bibliotheken zahlen Regelmäßig Geld an die Verlage, damit die Hochschul-Angehörigen (also Studierende und Mitarbeitende) Zugriff auf die darin veröffentlichten Arbeiten haben. Wer kein Abonnement hat, kann Artikel einzeln kaufen. Versucht man, einen Artikel online herunterzuladen, ohne dass man sich in einem Hochschulnetzwerk befindet, geht das nicht kostenlos: Der Artikel befindet sich hinter einer Bezahlschranke (*Paywall*). Soll ein Artikel für alle frei zugänglich veröffentlicht werden (*Open Access*,öffentlicher Zugang), kostet das extra, nämlich je Artikel zwischen 2000€ und 9000€. Um Forschung also lesen zu können, müssen Hochschulen Abonnements oder Artikel kaufen. Infolge dessen sind finanziell schlechter ausgestattete Institutionen, Länder, oder sogar gesamte Regionen wie der globale Süden in ihrer Teilnahme am internationalen Wissenschaftsdiskurs systematisch benachteiligt.

Das soziale Dilemma besteht nun in der Schwierigkeit, dieses System zu verändern. @Brembs.2023 beschreiben es wie folgt: Bibliotheken schließen die Abos mit Verlagen ab, um Forschung an ihren Hochschulen zu ermöglichen. Würden sie die Verträge kündigen, könnte das die Forschung verlangsamen und die Stellung einer Hochschule verschlechtern. Forschende können die namhaften Zeitschriften der kommerziellen Verlage nicht boykottieren, da sie sonst ihre Karriere gefährden würden. Sie sind darauf angewiesen, in prestigereichen Zeitschriften zu publizieren. Zudem ist es extrem schwierig, das Verhalten von Millionen von Forschenden, von denen die meisten viele Jahre lang mit dem aktuellen System gelebt haben, schlagartig zu verändern. Die Zeitschriften, als dritter Akteur in diesem Dilemma, profitieren von der Abhängigkeit und können Preise beliebig steigen lassen. Abgesehen vom Markenwert der Zeitschriften, also dem Ansehen und dem Vertrauen, das ihnen fälschlicherweise [@Brembs.2018] entgegengebracht wird, tragen sie zu diesem System fast nichts bei. Universitäten und Länder haben bereits jetzt die Möglichkeit, Forschungsartikel online zu verwalten; die Begutachtung und Qualitätssicherung geschieht durch freiwillige Forschende und nicht durch Angestellte der Zeitschrift; und die Formatierung der Artikel können Forschende wie an bestehenden [^probleme_system-4] ersichtlich ist [@Carlsson.2017], mit geringem Aufwand selbst übernehmen. Entsprechende Lösungen werden in [@sec-openaccess] erläutert.

[^probleme_system-4]: Damit sind Zeitschriften gemeint, die Artikel ohne Abonnement-Zugang und ohne Paywall veröffentlichen, und zwar ohne Kosten für die Autor\*innen.

### Wissenschaftliche Qualitätskontrolle

Durch die Probleme des wissenschaftlichen Systems zieht sich das Problem der Qualitätskontrolle. Im Begutachtungsprozess vor der Veröffentlichung werden viele Fehler nicht erkannt und nach der Veröffentlichung sind Berichte so intransparent, dass es oft nicht einmal möglich ist, gefälschte Daten zu entlarven. Gutachten wissenschaftlicher Artikel bleiben meistens unter Verschluss und wenn eine Zeitschrift einen Artikel ablehnt, wird er bei einer anderen eingereicht. Die bereits herausgestellten Kritikpunkt gehen dabei verloren [@aczel2021billion].

Wissenschaftliche Artikel haben am Ende einen Absatz zu möglichen Interessenkonflikten. Dort müssen Forschende angeben, wenn sie Leistungen von Unternehmen für die Forschung bekommen haben, oder in irgendeiner Weise von der Forschung profitieren (z.B. Aktien des Unternehmens besitzen, dessen Medikament sie positiv gestetet haben). In der Glücksspiel-Forschung fehlen diese Angaben oft [@Heirene.2021]. Einige große Unternehmen untergraben systematisch den wissenschaftlichen Konsens, indem sie falsche Informationen streuen: Dazu gehört beispielsweise die Tabakindustrie und der sichere negative Effekt vom Rauchen auf die Gesundheit [@reed2021disinformation].

Zeitschriften machen sich die Lage zu Nutzen, indem sie gegen eine schwache oder gar keine Qualitätskontrolle und hohe Publikationskosten (z.B. 4500€ pro Artikel) Forschung veröffentlichen. Diese Praxis wird *Predatory Publishing* genannt und meint, dass Forschende sich Publikationen erkaufen und Verlage dadurch Profit schöpfen. Teilweise ist aufgrund des anonymen und unter Verschluss gehaltenen Peer Review Prozesses unklar, ob es sich bei einer Zeitschrift um eine mit oder ohne vorliegende Qualitätskontrolle handelt. Einen Schritt weiter gehen Paper-Mills. Dabei können Personen Ko-Autor\*innenschaften bei Artikeln kaufen. Die Artikel sind häufig von einzelnen Personen oder mittels Algorithmen generiert. Fälle, in denen Unsinn-Artikel entlarvt werden, gibt es häufig, allerdings werden die Artikel nur selten zurückgezogen oder öffentlich mit einer Notiz, die den Fehler erklärt versehen [@cabanac2021prevalence]. Neben Publikationen können Forschende auch Zitationen kaufen oder selbst künstlich erhöhen, so wurde laut Angaben von Google Scholar beispielsweise kurzzeitig die [Katze Larry](#0) 132 Mal zitiert. Durch die Gutachten, die unter Verschluss bleiben, konnten sich auch "Review-Mills" bilden: Dort werden Autor\*innen dazu genötigt, bestimmte Forschungsartikel zu zitieren, um den Gutachtenden höhere Zitationszahlen zu verschaffen. Die Gutachten bestehen dabei aus vagen Textbausteinen [@oviedo2024review].

## Vertiefende Informationen

-   Der kostenlose Film "Paywall: The Business of Scholarship" behandelt das Thema Paywalls sowie den öffentlichem Zugang von wissenschaftlichem Wissen: https://paywallthemovie.com/paywall

-   Das Thema der Neurodiversität in der Forschung diskutieren @Elsherif.2022. Via [FORRT.org](https://forrt.org/neurodiversity/) verwaltet die Gruppe darüber hinaus eine Datenbank neurodivergenter Forschender und weitere Projekte.

-   Thériault und Forscher haben kürzlich das [*Missing Majority Dashbaord*](https://remi-theriault.com/dashboards/missing_majority#home) veröffentlicht [@theriault2024missing], das automatisch mittels der OpenAlex Literaturdatenbank darstellt, von welchen Kontinenten Autor\*innen stammen. Nordamerika und Europa sind dabei deutlich überrepräsentiert.

## Literatur
