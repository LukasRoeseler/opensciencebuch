---
title: "Die Geschichte der Open Science Bewegung"
format: html
---

## Geschichte

Im Rahmen dieses Buches wird die Open Science Bewegung also als eine Reaktion auf identifizierte Probleme und damit als Selbstkorrektur-Prozess der Wissenschaft verstanden. In im Zentrum steht ein mangelndes Vertrauen in Befunde, die in wissenschaftlichen Fachzeitschriften veröffentlicht wurden. Einige Probleme sind schon seit Jahrzehnten in ähnlicher Form bekannt. Bis sie allerdings öffentlich diskutiert wurden und Lösungsvorschläge erarbeiteten, benötigte es einschneidende Ereignisse.

## 1.   Anfänge einer Revolution

Um das Jahr 2010 herum häuften sich in der Psychologie Ereignisse, die für sich genommen als Einzelfälle abgetan werden konnten, gemeinsam aber ein negatives Bild der Wissenschaft zeichneten.

### Stapel

Durch einen Zufall entdeckte XXX im Jahr 20XX, dass die Daten einer Studie seines Kollegen, Diederik Stapel, von niemandem jemals erhoben wurden. Sie waren ausgedacht, bzw. fabriziert. Daraufhin wurden XXX Fachartikel identifiziert und zurückgezogen, deren Daten fabriziert oder geschönt wurden. Wissenschaftliche Institutionen wie der Begutachtungsprozess von Artikeln durch Fachkolleg\*inen, deren Zweck die Qualitätssicherung war, hatten versagt. Seit dem Vorfall sind einige weitere Fälle bekannt geworden, teilweise durch erneute Analyse von Daten der jeweiligen Studien (REF datacolada ariely) und oft durch Whistleblower, also durch Personen, die zu ihrem Schutz anonym bleiben wollen. Umfragen in den Niederlanden unter Forschenden haben ergeben, dass Fälschung oder Schönigung von Daten von bis zu 10% aller Personen durchgeführt wird (REF niederländische Studie scientific malpractice). Dabei ist zu beachten, dass Studien durch gefälschte Daten besonders innovativ, überraschend, oder klar werden - Eigenschaften, die die Veröffentlichung in einer Fachzeitschrift wahrscheinlicher machen.

### Bem

Kurze Zeit später veröffentliche Daryl Bem, bekannt durch grundlegende psychologisch-philosophische Theorien wie der Self-Perception-Theory (REF), den Befund, dass Personen die Zukunft vorhersagen können (REF feeling the future). Genauer gesagt, können manche Personen unter bestimmten Dingen, die Zukunft vorhersagen. In 8 Studien fand die Forschendengruppe, dass Männer (XXX) vorhersagen konnten, ob XXX Paradigma genau beschreiben XXX. Die Ergebnisse wurden in der hoch angesehenen Fachzeitschrift XXX veröffentlicht. Vielen Psycholog\*innen war sofort klar: Entweder, Grundlegende Annahmen ihres Weltbildes waren falsch ("Personen können nicht die Zukunft vorhersagen") oder es stimmte etwas mit den Ergebnissen nicht. Mehrere Forschende versuchten sich daran, zu erklären, wie es zu den Ergebnissen kam. Analysen mit alternativen statistischen Methoden führten zur selben Schlussfolgerung (wagenmakers cf schimmack), Replikationen durch unabhängige Forschende schlugen jedoch fehl (REF feeling future meta analysis).

### Bargh

Seine Studien wurden im Marketing gefeiert und als Neurowissenschaftliche Erkenntnisse verkauft: Wer sich einsam fühlt, versucht die fehlende soziale Wärme durch physische Wärme zu kompensieren, indem er wärmer duscht (REF einsamkeit duschen). Wenn man das Verhalten seines Gegenübers imitiert (z.B. gleichzeitig am Kopf kratzen), wirkt man der Person sympathischer (Chamäleon Effekt, REF). Wer Anagramme löst, die etwas mit hohem Alter zu tun haben (z.B. PFLEGEHEIM, GRAU, oder zum selbst probieren GHOSTECK), geht danach in langsamerem Tempo. Die letzte Studie wurde repliziert: Forschenden fiel auf, dass Bargh und Kolleg\*innen die Zeit mit Stoppuhren gemessen hatten und dabei wussten, welche Person die "Alt"-Wörter und welche die neutralen Anagramme gelöst hatten - dabei lernt jede\*r Psychologie-Studierende im ersten Jahr, dass das nicht der Fall sein sollten und Versuchsleiter\*innen "blind" gegenüber dem Untersuchungszweck und der Zuordnung der Personen zu den Gruppen sein sollte. In ihrer Replikation (REF, doyen?) ließen Doyen (?) und Kolleg\*innen die Zeit mit Lichtschranken erfassen und maßen selbst wie Bargh et al. in der Originalstudie. Bei der problematischen Messung kam dasselbe raus, die Lichtschranken, denen vorher nicht verraten wurde, welche Hypothese mit ihnen untersucht werden sollten und welche Personen welche Anagramme lösen mussten, konnten den Effekt jedoch nicht replizieren.

## 2.   Bestandsaufnahme der Replizierbarkeit

Eine ähnliche Vertrauenskrise gab es in der Sozialpsychologie in den 1960er Jahren (REF[\[LR1\]](#_msocom_1) ). Ein entscheidender Unterschied war diesmal die Bestandsaufnahme: Parallel zu diesen eigenartigen Befunden oder *Anomalien* vernetzten sich Psycholog\*innen um Brian Nosek international und untersuchten die Replizierbarkeit von 100 Studien aus namhaften psychologischen Fachzeitschriften (REF[\[LR2\]](#_msocom_2) )[\[1\]](#_ftn1). Sie fanden heraus, dass sich nur 39 der 100 Originalbefunde replizieren ließen. Bei allen anderen Studien, waren die Replikationsergebnisse anders als die ursprünglichen Ergebnisse. Viele weitere Großprojekte folgten, alle mit ähnlichen Ergebnissen: Die Replikationsraten lagen weit unter den Gewünschten.

Zahlreiche Verbündnisse folgten. Einige Projekte konzentrierten sich auf einzelne Phänomene. Beispielsweise wurde \[RRR von XXX einfügen und beschreiben, wie viele Laboratorien und Forschende mit wie vielen Versuchspersonen nachgemacht haben\]. \[Ergebnisse\]. Andere konzentrierten sich auf Bereiche wie Forschung mit Babys (REF ManyBabies) oder Zeitschriften (REF Camerer).

Liste von groß angelegten Replikationsprojekten

+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     |                                         |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     | Projekt                                 |     | Internetadresse               |     | Zentrale Publikationen |     | Fokus |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     |                                         |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     | Many Labs                               |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     |                                         |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     | Many Primates                           |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     |                                         |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     | ManyBabies                              |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     |                                         |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     | I4R                                     |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     |                                         |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     | ManyLanguages                           |     | <https://many-languages.com>  |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     |                                         |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     | Social Science Replication Project      |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     |                                         |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     | CORE                                    |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     |                                         |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     | SCORE                                   |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     |                                         |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     | \[siehe FReD Einträge und irise liste\] |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+
|     |                                         |     |                               |     |                        |     |       |    |
+-----+-----------------------------------------+-----+-------------------------------+-----+------------------------+-----+-------+----+

### Definition von Replizierbarkeit

Zu sagen, was repliziert werden konnte und was nicht[\[LR3\]](#_msocom_3) , ist erst nach einer Definition möglich. Im Sprachgebrauch von Forschenden wird mit „wurde repliziert\" gemeint, dass ein Replikationsversuch zu gleichen Ergebnissen wie eine Originalstudie gekommen ist. Zu Replikationsfehlschläge wird „konnte nicht repliziert werden\" gesagt, subtil davon abweichend kann „wurde nicht repliziert\" meinen, dass keine Replikationsversuche existieren oder sie fehlschlugen. Für eine Wissenschaft, die über 100 Jahre alt ist, scheint es überraschend, dass noch immer keine klare Definition wichtiger Konzepte rund um das Thema Replikation vorliegt, geschweige denn es zur Routine gehört, Studien zu replizieren. Während sich in verschiedenen Feldern abweichende Taxonomien durchgesetzt haben, sieht die Verwendung in diesem Buch wie in **Tabelle 1** beschrieben aus.

[\[LR4\]](#_msocom_4) 

-          <https://dl.acm.org/doi/pdf/10.1145/3457143> (auch siehe Helga Wolf BA)

-          Induktion und Deduktion <https://www.frontiersin.org/articles/10.3389/fpsyg.2021.605191/full>

-          <https://www.acm.org/publications/policies/artifact-review-and-badging-current>

-          Nicht in allen Disziplinen sinnvoll: Archäologie „zerstört\" Daten bei der Erhebung indem sie sie aus ihrem Originalen Kontext herausreißt, etwas kann nicht 2x ausgegraben werden

-          Diskussionen zum Verhältnis zwischen Entdecken, Replizieren, und Verallgemeinern <https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/science-with-or-without-statistics-discovergeneralizereplicate-discoverreplicategeneralize/FADF4916A14C3C9B1D1EF8949D8F893A#related-commentaries>

### Weiterführende Literatur

Für eine systematischere, in den Informationswissenschaften verankerte Taxonomie zur Art der Replikation siehe: <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5778115/> REF). Eine an den statistischen Methoden angelehnte Taxonomie für die Ergebnisse von Replikationsstudien haben LeBel et al., (REF) vorgeschlagen. Philosophisch diskutiert wird Replikationsnähe zum Beispiel von REF (<https://psycnet.apa.org/record/2024-20853-001>).[\[LR5\]](#_msocom_5) 

**Tabelle 1**

*Replikationstaxonomie*

+-----+--------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------------------------------------+----+
|     |                                                                                                        |     |                                                                                                                               |    |
+-----+--------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------------------------------------+----+
|     | **Unterscheidungskriterium**                                                                           |     | **Ausprägungen**                                                                                                              |    |
+-----+--------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------------------------------------+----+
|     |                                                                                                        |     |                                                                                                                               |    |
+-----+--------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------------------------------------+----+
|     | Ergebnisse einer Replikationsstudie                                                                    |     | -          Erfolgreich                                                                                                        |    |
|     |                                                                                                        |     |                                                                                                                               |    |
|     |                                                                                                        |     | -          Fehlgeschlagen                                                                                                     |    |
|     |                                                                                                        |     |                                                                                                                               |    |
|     |                                                                                                        |     | -          Unklar oder gemischt                                                                                               |    |
+-----+--------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------------------------------------+----+
|     |                                                                                                        |     |                                                                                                                               |    |
+-----+--------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------------------------------------+----+
|     | Nähe einer Replikationsstudie zur Originalstudie (in Anlehnung an Lebel REF und Hüffmeier et al REF)   |     | -          Direkte Replikation \                                                                                              |    |
|     |                                                                                                        |     | (selbe Versuchsleiter\*innen, \                                                                                               |    |
|     |                                                                                                        |     | selbe Versuchsmaterialien, \                                                                                                  |    |
|     |                                                                                                        |     | neue Versuchspersonen)                                                                                                        |    |
|     |                                                                                                        |     |                                                                                                                               |    |
|     |                                                                                                        |     | -          Nahe Replikation \                                                                                                 |    |
|     |                                                                                                        |     | (andere Versuchsleiter\*innen, \                                                                                              |    |
|     |                                                                                                        |     | möglichst ähnliche Versuchsmaterialien, \                                                                                     |    |
|     |                                                                                                        |     | neue Versuchspersonen)                                                                                                        |    |
|     |                                                                                                        |     |                                                                                                                               |    |
|     |                                                                                                        |     | -          Konzeptuelle oder konstruktive Replikation\                                                                        |    |
|     |                                                                                                        |     | (andere Versuchsleiter\*innen, \                                                                                              |    |
|     |                                                                                                        |     | andere Versuchsmaterialien, \                                                                                                 |    |
|     |                                                                                                        |     | neue Versuchspersonen)                                                                                                        |    |
+-----+--------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------------------------------------+----+
|     |                                                                                                        |     |                                                                                                                               |    |
+-----+--------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------------------------------------+----+
|     | Ziel der Replikation                                                                                   |     | -          Mit selben Daten und selbem Programmiercode zu denselben Ergebnissen gelangen: (komputationale) Reproduktion       |    |
|     |                                                                                                        |     |                                                                                                                               |    |
|     |                                                                                                        |     | -          Mit anderen Daten zu denselben Ergebnissen gelangen: Replikation                                                   |    |
+-----+--------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------------------------------------+----+
|     |                                                                                                        |     |                                                                                                                               |    |
+-----+--------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------------------------------------+----+

###  „Eine Schwalbe macht noch keinen Sommer\"

Ob an einem wissenschaftlichen Befund „etwas dran ist\", er also einen Wahrheitsanspruch hat, hängt -- neben seiner eigentlichen Art der Etablierung -- bei der Replikationsforschung von vielen Faktoren ab. Was waren die Ergebnisse der Replikationsstudie? Wie viele und wie unterschiedliche Studien wurden durchgeführt? Wie sahen die genauen Methoden aus? Was waren die Unterschiede zwischen Replikationen und Originalstudie? Während Einzelstudien immer einen Erkenntnisgewinn liefern (mindestens, ob eine bestimmte Methode praktikabel ist, REF <https://www.researchgate.net/publication/368641396_Epistemic_Functions_of_Replicability_in_Experimental_Sciences_Defending_the_Orthodox_View>), können sie je nach Forschungsgebiet stark variieren (REF <https://www.researchgate.net/publication/359332892_Variation_and_Covariation_in_Large-scale_Replication_Projects_An_Evaluation_of_Replicability> , REF crowdsourcing hypothesis test). Für das Gesamtbild braucht es mehr, wie zum Beispiel eine statistische Aggregation aller Einzelbefunde im Rahmen einer Meta-Analyse. Ein Beispiel mit Fantasiedaten befindet sich dazu in Abbildung X.

ABBILDUNG X: Forest plot mit simulierten Ergebnissen von Original + vielen Einzelstudien; in den Notes dann ausführliche Erklärung.

### Disziplin-zentrierte Replikationsprojekte

Ungefähr die Hälfte aller psychologischen Befunde ist also nicht replizierbar. Heißt das, alle Sozialwissenschaftlichen Lehrbücher aus allen Disziplinen sind zur Hälfte falsch? Die wohl wissenschaftlichste Antwort bei fast allen Fragen lautet "kommt darauf an".

#### Psychologie 

Inwiefern es auf die Disziplin innerhalb der Sozialwissenschaften ankommt wurde bisher vor allem in der Psychologie untersucht. Aktuelle Tendenzen weisen darauf hin, dass Replikationsraten in der Persönlichkeitspsychologie und kognitiven Psychologie (REF, REF) höher liegen als die in der Sozialpsychologie (REF) oder im Marketing (REF charlton). Während schon hunderte Replikationsversuche für sozialpsychologische Studien veröffentlicht sind, sind es in anderen Bereichen wie dem Marketing aktuell weniger - Stand Oktober 2022 sogar nur 9. Bereiche außerhalb der Psychologie sind von Replikationsproblemen ebenfalls betroffen.

-   

-   Infant cognition <http://philsci-archive.pitt.edu/22679/1/PoS_final_Oct_2023-2.pdf>

-   

-   Animal Cognition <https://www.animalbehaviorandcognition.org/article.php?id=1197>

-   

-   System Justification Theory estimate: <https://onlinelibrary.wiley.com/doi/full/10.1002/ejsp.2858>

-   

-   Persönlichkeitspsychologie:

    -   

    -   <https://doi.org/10.1016/j.jrp.2023.104435>

    -   

    -   Soto

    -   

-   

```{=html}
<!-- -->
```
-   

-   Sportpsychologie

    -   

    -   <https://econtent.hogrefe.com/doi/full/10.1026/1612-5010/a000406> \[special issue\]

    -   

    -   <https://econtent.hogrefe.com/doi/full/10.1026/1612-5010/a000404>

    -   

    -   <https://epub.ub.uni-muenchen.de/37148/1/Geukes_Schoenbrodt_F_Utesch_Geukes_Back_Wege_aus_der_Vertrauenskrise.pdf>

    -   

-   

-   Spracherwerb <https://osf.io/zk5qg/>

-   

-   Entwicklungspsychologie: <https://onlinelibrary.wiley.com/doi/10.1002/icd.2495>

-   

-   Unterschiede zwischen Feldern

    -   

    -   Bei Psychological Science Artikeln Social -- Cognition -- Development (und andere) [https://onlinelibrary.wiley.com/doi/10.1002/icd.2361 Figure 1](https://onlinelibrary.wiley.com/doi/10.1002/icd.2361%20Figure%201)

    -   

-   

-   Suizidforschung: <https://osf.io/preprints/osf/fwsr3>

-   

#### Medizin

-   

-   Krise in **Medizin**: Milliarden 28 USD \$ Kosten <https://journals.plos.org/plosbiology/article/info:doi/10.1371/journal.pbio.1002165> UND <https://www.nature.com/articles/483531a> UND <https://www.nature.com/articles/nrd3439-c1>

-   

-   Krise in Krebsforschung: <https://www.nature.com/articles/483531a?error=cookies_not_supported&code=1c1d343e-b688-4ecc-b62c-891bc2bd1017> <https://www.nature.com/articles/nrd3439-c1?error=cookies_not_supported&code=ed06429a-e279-4b03-9270-c9c8a33aecba> <https://jamanetwork.com/journals/jama/fullarticle/201218#note-joc50060-1>

    -   

    -   Die hälfte kann man nicht mal replizieren, weil im Originalartikel nicht genug beschrieben ist

    -   

    -   Von denen, die repliziert werden konnten, haben wenige geklappt

    -   

-   

-   Krise in Medizin: <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7817176/>

-   

-   Schätzung der Kosten: <https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002165>

-   

-   <https://link.springer.com/article/10.1007/s00103-023-03797-y>

-   

-   Präklinische Forschung: Effekte korrelieren nur schwach mit denen in klinischen Studien

    -   

    -   <https://link.springer.com/article/10.1007/s11060-022-04092-7>

    -   

    -   <https://www.science.org/doi/full/10.1126/scitranslmed.adg8656>

    -   

    -   overview: <https://www.jci.org/articles/view/177383>

    -   

-   

-   Präregistrierungen in Toxikologie (<https://www.tandfonline.com/doi/full/10.1080/2833373X.2024.2314303>)

-   

#### Physik

-          Reproduzierbarkeitsprobleme in Condensed Matter Physics <https://www.technologyreview.com/2024/05/15/1092535/a-wave-of-retractions-is-shaking-physics/>, dazu Konferenz: <https://www.pqi.org/international-conference-reproducibility-condensed-matter-physics>

#### Sportwissenschaften

-          Auswahl von Replikationsstudien: <https://link.springer.com/article/10.1007/s40279-022-01749-1> (z.B. Publikationsjahr, Zitationen, Disziplin, Studientyp, Frage, Variablen, Machbarkeit)

-          <https://ssreplicationcentre.com/about/>

-          <https://www.bmj.com/content/345/bmj.e4797> kaum Studien mit Poweranalysen zwischen 1971 und 2012

-          <https://ssreplicationcentre.com/publication/publication_bias/>

-          <https://ssreplicationcentre.com/publication/survey/>

-          <https://storkinesiology.org>

#### Wirtschaftswissenschaften

-   

-   Camerer replication studies

-   

-   Ökonomie Bestandsaufnahe (reproduce): <https://www.econstor.eu/handle/10419/250076>

-   

-   P-hacking in organizational research: <https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0281938>

-   

§  Management Science (Reproducibility): <https://osf.io/mydzv/>

-   

-   Preisgekrönte Kollaboration zur Durchführung von Replikationsstudien: <https://wzb.eu/en/news/new-research-hub-lab2> \
    <https://wzb.eu/en/jobs/post-doctoral-research-fellow-fmx-id-nr-243-282-243>

-   

-   Inventur, wie viel Replikationen es in Ökonomie gibt: <https://doi.org/10.1016/j.jebo.2023.05.009>

-   

-   Open Economics Guide vom ZBW <https://www.b-i-t-online.de/heft/2024-01-fachbeitrag-fingerle.pdf>

-   

-   Inventur, wie viele Replikationen in welchen Zeitschriften veröffentlicht werden: <https://ideas.repec.org/p/stg/wpaper/2020_01.html>

-   

#### Marketing und Konsumentenverhalten

-          P-curve analyse zu menu design [10.1016/j.ijhm.2022.103378](http://dx.doi.org/10.1016/j.ijhm.2022.103378)

-           Charlton <https://openmkt.org/research/replications-of-marketing-studies/>

-          Adler, Röseler, & Schöniger, 2023

-          Management Science: einige Replikationsversuche und grober Leitfaden <https://journals.sagepub.com/doi/full/10.1177/27550311241232661>

-          Toward Open Science in Marketing Research: <https://osf.io/f7a8c/>

-          Wird trotzdem als positiv ausgelegt, indem internal replications mitgezählt werden <https://academic.oup.com/jcr/article/51/1/157/7672979>

#### Biologie

-          Human Genome Project: große Gruppe an Wissenschaftler\*innen, Sequenzierung des menschlichen Gens, Konflikte wegen Bestrebungen, das Gen zu patentieren <https://www.science.org/doi/10.1126/science.287.5462.2396>

o   <https://www.yourgenome.org/theme/how-did-patenting-cause-conflicts-within-the-human-genome-project/>

#### Sportwissenschaften

-   

-   In Sportwissenschaft wird Krise vermutet: <https://royalsocietypublishing.org/doi/full/10.1098/rsos.220946>

-   

§  technology education research: <https://link.springer.com/article/10.1007/s10798-022-09787-6>

#### Kriminologie

-          Diskussion: <https://www.annualreviews.org/doi/abs/10.1146/annurev-criminol-032317-091849>

#### Geowissenschaften

-          Beispiele für Replikationen <https://www.sciencedirect.com/science/article/pii/S1674987124000458>

-          Reproduzierbarkeit in GeoInformatik <https://o2r.info/publications/>

#### Medienwissenschaften

#### Kommunikationswissenschaften und Medienwissenschaften

-          Need for Replication <https://www.cogitatiopress.com/mediaandcommunication/article/viewFile/7935/3695>

-          Are we replicating yet? <https://doi.org/10.17645/mac.i429>

-          Wie Replikationen aussehen müssten: <https://www.cogitatiopress.com/mediaandcommunication/article/viewFile/7971/3812> (Special Issue bei Media and Communication)

-          Offenheit für Replikationen und Kommentare bei Zeitschrift „Sexuality & Culture\" <https://link.springer.com/article/10.1007/s12119-023-10164-1>

-          Liste mit Zeitschriften, die Open Science Fokus haben: <https://docs.google.com/spreadsheets/d/1WDTBIop2Eg9CKsvQ1BUgMXJdmrh1TAreyS02SiWEJDY/edit?gid=0#gid=0>

-          Replikationsstudie (erfolgreich) <https://www.tandfonline.com/doi/abs/10.1080/00224499.2021.1999893>

-          OS Primer für CommSci: <https://doi.org/10.1080/19312458.2019.1685660>

-          Große Gruppe an Kommunikationswissenschaftler\*innen positioniert sich für OS: <https://academic.oup.com/joc/article/71/1/1/5803422>

-          Konkrete Umsetzungsvorschläge: <https://academic.oup.com/joc/article/71/5/855/6339986>

-          In Diskussion noch z.B.: unklare Definition von Open Science, Mangel an Aufmerksamkeit für Replikationsprobleme mit Social Media Daten <https://academic.oup.com/joc/article/71/5/686/6363639>

-          OS Praktiken hängen nicht mit Impact zusammen: <https://doi.org/10.1080/23808985.2023.2201601>

-          Replikationen in ComSci 2007-2016 gibt es, sind aber vor allem konzeptuell: <https://doi.org/10.1080/23808985.2019.1632218>

-          Reproduzierbarkeit von Ergebnissen: <https://www.cogitatiopress.com/mediaandcommunication/article/viewFile/7789/3726>

#### Soziologie

In Anlehnung an Breznau, 2021

-          Von großen Diskussionen weitgehend abwesend <https://www.annualreviews.org/doi/10.1146/annurev-soc-060116-053450>

-          Bekannte Soziologen wie Robert Merton haben Probleme, die in Open Science Bewegung diskutiert werden, schon in der ersten Hälfte des 20. Jahrhundert angesprochen (z.B. Mertonsche Normen von Wissenschaft); umgekehrt wird Open Science als soziale Bewegung verstanden (REF[\[LR6\]](#_msocom_6) )

-          Habermas hat vor Kontrolle der „public sphere\" durch „private Interest\" gewarnt, wie es aktuell durch wissenschaftliche Zeitschriften geschieht (<https://books.google.de/books?hl=de&lr=&id=e799caakIWoC&oi=fnd&pg=PR11&ots=5SCCe_SYy1&sig=hS4ZXlACeY-BH4eFJqjJCfCJSIo&redir_esc=y#v=onepage&q&f=false>, p. 94-101)

-          Bekanntes Open Access Journal „Sociological Science\" (<https://sociologicalscience.com/articles-v3-6-109/>) erlaubt direkte Reaktion und schnellen wissenschaftlichen Austausch

-          Breznau, 2021 (<https://www.mdpi.com/2075-4698/11/1/9>): „If you are using quantitative methods, immediately stop hiding your work. If you ran 100 models and 99 did not support your hypothesis, then this is your finding. If a journal does not want to publish this, point the editors and reviewers to the importance of null results and the problems of publication bias. If they still refuse, consider boycotting this journal and sharing your negative experience in public.\"

-          Probleme mit Publikationssystem auch schon seit 50 Jahren bekannt: <https://doi.org/10.2307/2064432>

-          Diskussionen um Replikationsstandards seit 2007: <https://doi.org/10.1177/0049124107306659>

-          Vereinzelte Replikationen, z.B. <https://sociologicalscience.com/articles-v2-20-420/?utm_content=buffer9ff03&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer>

-          Retractions aufgrund von Fehlern nur sehr schwer und nur durch Druck des Originalautors möglich, dieselben Hinweise durch unabhängige Wissenschaftler\*innen wurden vorher ignoriert: <https://www.science.org/doi/10.1126/sciadv.aba5491>

-          Transparenz auch verankert in großen nationalen soziologischen Vereinigungen: American Sociological Association, German Sociological Society, Japanese Sociological Society (Breznau, 2021, Table 1)

-          Leipziger Replikationsstudien: <https://home.uni-leipzig.de/lerep/>

-          Widerstände gegen Open Science groß, v.a. in qualitativer Soziologie\
z.T. nur 15% bereit, Daten öffentlich zu teilen (<https://www.konsortswd.de/wp-content/uploads/forschungsinfrastrukturen_qualitative_sozialforschung.pdf#page=98>, <https://books.google.de/books?hl=de&lr=&id=KPWpCgAAQBAJ&oi=fnd&pg=PA75&ots=aAz18pO-A-&sig=MHbvPzJeYcnJt150NWEIPWTthXA&redir_esc=y#v=onepage&q&f=false>)

#### Politikwissenschaften

-          Probleme mit gefälschten Daten (<https://www.science.org/content/article/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour>)

-          Replication Blog: <https://politicalsciencereplication.wordpress.com>

-          Vorschlag für Replikationen-Policy für Journals und viele andere Arbeiten von Gary King (<https://gking.harvard.edu/pages/data-sharing-and-replication>)

-          Qualitative Data Repository: <https://qdr.syr.edu> erlaubt abspeichern von Reden, Pressekonferenzen, Interview-Protokolle/-Aufnahmen, Offiziellen Dokumenten, Broschüren, Fernsehaufnahmen, Radiosendungen, Büchern, Fotos, usw.

-          Diskussion zur Erweiterung von Reviewer Guidelines (Daten prüfen, Codesheet reviewen): <https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Alfd3g8AAAAJ&citation_for_view=Alfd3g8AAAAJ:d1gkVwhDpl0C>

-          Auch bereits Special Issues, also Zeitschriftenausgaben, bei denen viele Artikel zu einem Thema sind, zu Open Science: <https://www.cambridge.org/core/journals/ps-political-science-and-politics/issue/FDA7996E28CFB6DD9A2052575DBABBB6>

-          Reproduzierbarkeit: <https://doi.org/10.1017/S1049096520001717> fast 80% nicht erfolgreich

-          Qualitative Forschung hier auch hoher Stellenwert: <https://doi.org/10.1017/S1049096520000955> Beispiel für Präregistrierung einer qualitativen Studie: <https://doi.org/10.1017/S1049096520000955>

#### Erziehungswissenschaften / Bildungswissenschaften / Pädagogik

-          Frage der Zeit, bis die Diskussion in das Fach übergeht, v.a. Präregistrierung, Open Materials, Open Data; Vorschläge: <https://link.springer.com/article/10.1007/s35834-020-00286-z>

-          Call for Papers in Zeitschrift für Erziehungswissenschaften: <https://zfe-online.de/wp-content/uploads/2024/06/CfP_ZfE_Themenschwerpunkt_Open-Science-in-der-Bildungsforschung_final.pdf>

#### Technology Education Research

-          [10.1007/s10798-023-09827-9](http://dx.doi.org/10.1007/s10798-023-09827-9)

-           

#### Künstliche Intelligenz

-          <https://www.technologyreview.com/2020/11/12/1011944/artificial-intelligence-replication-crisis-science-big-tech-google-deepmind-facebook-openai/>

#### Accounting

Viele Replikationen und hohe Erfolgsrate im Accounting <https://doi.org/10.2308/HORIZONS-2022-152>

#### Homöopathie

-          Datenbank für Replikationsbefunde wurde vorgeschalgen: <https://www.highdilution.org/index.php/ijhdr/article/view/1354>

#### Chemie

-          Orientiert an Vortrag von Egon Willighagen (Jülich Open Science Speaker Series, 30.01.2024

-          Open standards (SMILES, chemical markup language \"Jmol, JChemPaint\")

-          Chemistry Development Kit, Blue Obelisk Movement (2006, 2011 papers,O\'Boyle Guha Willighagen et al, Journal of Cheminformatics)

-         

#### Epidemiologie

-          <https://www.researchgate.net/publication/367025586_Toward_open_and_reproducible_epidemiology>

#### Geisteswissenschaften

-          V.a. digital Humanities, die quantitativ arbeiten

-          Konzeptualisierung von „repetitiver Forschung\" <https://link.springer.com/article/10.1007/s42803-023-00073-y#Sec5>

-          Geschichte:

o   <https://research.vu.nl/en/publications/brooke-on-the-merton-thesis-a-direct-replication-of-john-hedley-b>

o   <https://research.vu.nl/en/publications/jewish-responses-to-copernican-thought-a-conceptual-replication-o>

o   <https://research.vu.nl/en/publications/introduction-to-thematic-part-replicating-john-hedley-brookes-wor>

### Phänomen-zentrierte Replikationsprojekte

Im Gegensatz zu dem breit gefächerten RPP und anderen Versuchen, die Replikationsrate zu schätzen, haben sich andere Versuche auf grundlegende Phänomene fokussiert. Dutzende Gruppen auf der ganzen Welt haben sich in solchen Fällen zusammengeschlossen, auf ein Versuchsdesign geeinigt, und führen die Studien mit einer enormen Anzahl an Versuchspersonen durch. Während die dabei gefundenen Effektstärken, also sozusagen die Deutlichkeit eines Zusammenhanges oder Befundes, in fast allen Fällen weit unter denen bisheriger Studien lagen (REF compraing registered report meta-analysis; meta analysis inflation), waren sie zudem beim Großteil der Studien null, die Phänomene waren also „nicht da\". So konnte beispielsweise mit einer enormen Präzision gezeigt werden, dass eine Geschichte über einen Professor Versuchspersonen in einem anschließenden Leistungstest \*nicht\* schlauer macht, oder XXX EGO DEPLETION BEIPSIEL EINFÜGEN XXX.

XXX- Dissonanztheorie / force compliance paradigm

## 3.   Wandel im System

Seit dem Bekanntwerden der geringen Replizierbarkeit psychologischer Studien wurde das wissenschaftliche System in vielen Aspekten hinsichtlich seiner Offenheit und Transparenz verändert. Einige Zeitschriften setzen für die Veröffentlichung wissenschaftlicher Artikel voraus, dass die Daten öffentlich zugängig sind beziehungsweise erklärt ist, weshalb das nicht der Fall ist (z.B. bei Daten, die sich schwierig anonymisieren lassen). In seltenen Fällen wie bei der Zeitschrift Meta-Psychology rechnen Wissenschaftler\*innen alle Ergebnisse nach. Als Antithese zum "Impact Factor", einer Kennzahl, die angibt wie oft eine Zeitschrift zitiert wird und nachweislich nichts mit der Qualität der darin enthaltenen Forschung zu tun hat (REF), wurde der TOP-Factor eingeführt (TOP: Transparency and Openness Promotion). Dieser gibt für eine Liste von [\[LR7\]](#_msocom_7) Kriterien an, in welchem Maße sie von verschiedenen Zeitschriften erfüllt werden. In anderen Feldern wie Betriebswirtschaftslehre oder Marketing werden Zeitschriften sogar von wenigen ausgewählten Forschenden über Ratingskalen bewertet, die jährlich als Rankings veröffentlicht werden. TOP-Factors hingegen sind objektiv, werden stetig aktualisiert, und sind öffentlich einsehbar und nachvollziehbar.[\[2\]](#_ftn2)

Am Wandel beteiligt sind vor allem Jungwissenschaftler\*innen oder Forschende im frühen Karrierestadium (*Early Career Researchers*). An vielen Universitäten haben sich in den letzten Jahren Open Science Initiativen oder regelmäßige Treffen („Reproducibili-Tea\") herausgebildet, die fast ausschließlich aus "Post Docs" (Personen nach der Promotion ohne Professur), Promovierenden (Doktoranden), und Studierenden bestehen. In Deutschland haben sie sich zum NOSI (Netzwerk der Open Science Initiativen Deutschland) vernetzt (REF OSF Link). ~~Besonders hervorzuheben ist das Journal of European Psychology Students (REF LINK), das vollständig von Studierenden geführt wird, ausschließlich Artikel mit studentischen Erstautor\*innen veröffentlicht, und dessen TOP-Factor den zahlreicher prestigereicher Zeitschriften übersteigt (XXX Beispiel, Stand: 24.10.22).~~

### Hat sich die Replizierbarkeitsrate erhöht?

Die Replikationskrise dauert nun schon ungefähr ein Jahrzehnt an und einiges hat sich geändert. Ist dadurch auch das Problem der Replizierbarkeit gelöst? Zum einen ist für viele Bereiche noch gar nicht klar, was sich replizieren lässt. Im Marketing führte eine Zeitschrift kurzzeitig eine Replikationsecke ein (JOURNAL NAME XXX siehe Susi paper p-values p-bullshit). Diese wurde dann in eine andere, weniger bekannte Zeitschrift verlagert. Die andere Zeitschrift wurde dann XXX. Aktuell sind Projekte in Arbeit, die die Replizierbarkeit schätzen, die Ergebnisse sind größtenteils noch vorläufig und unklar. In einem eigenen Projekt, sammeln wir Replikationsergebnisse, um langfristig je Disziplin und über die Zeit zu schauen, wie sich Replikationsraten verändert haben. Tagesaktuelle Werte sind online verfügbar (<https://metaanalyses.shinyapps.io/replicationdatabase/>). Eine Evaluation über mehrere Disziplinen und Jahre erfordert noch hunderte weitere Replikationsstudien.

### Die Open Science Revolution als Paradigmenwechsel[\[LR8\]](#_msocom_8) 

Wissenschaftshistoriker oder -theoretiker beschreiben die Entwicklung der Wissenschaft als nicht-stetig. Lehrbücher werden nicht immer dicker, stattdessen werden manche Kapitel kürzer, weil das darin beschriebene Wissen verworfen wird, andere werden dicker, weil neue Erkenntnisse hinzukommen. Zeitweise verschwinden Kapitel sogar vollständig. Eines der bekanntesten Wissenschaftsmodelle stammt von Thomas Kuhn (REF), der selbst Psychologe war und große Teile vom Mediziner und Soziologen Ludwik Fleck (REF) übernommen hat (siehe Abbildung X). Darin wird angenommen, dass zeitweise das Wissen wächst, sich jedoch dabei Befunde anhäufen, die mit allem anderen Wissen nicht vereinbar sind. Diese sogenannten Anomalien lassen sich ab einem bestimmten Punkt nicht mehr ignorieren. Ab dort kippt das wissenschaftliche Weltbild: Neue Theorien werden entworfen, die die Anomalien erklären können und altes Wissen wird verworfen oder in die neuen Theorien integriert. Dieses Kippen wird als Paradigmenwechsel oder wissenschaftliche Revolution bezeichnet[\[3\]](#_ftn3). Paradebeispiel für so einen Paradigmenwechsel ist der Übergang vom geozentrischen zum heliozentrischen Weltbild in der Astronomie, die Prospect Theory in den Wirtschaftswissenschaften, oder, so die Behauptung hier im Buch: Die Replikationskrise in der Psychologie. Anomalien sind in diesem Fall die Befunde von Bem oder Bargh oder vereinzelte Replikationsfehlschläge. Sie waren mit bisherigem Wissen nicht vereinbar und nachdem sich viele solcher Befunde häuften, ließen sie sich nicht mehr ignorieren oder abtun. Dass die Replikationsforscher\*innen etwas falsch gemacht hatten, nicht qualifiziert waren, oder Pech hatten, war keine gute Erklärung mehr. Im Gegensatz zu klassischen Revolution steht bei der Open Science Revolution keine bestimmte Theorie oder Forschungsdisziplin die verworfen wird im Fokus, sondern die wissenschaftliche Methode und das Wissenschaftssystem der Sozialwissenschaften. In Anlehnung an die wissenschaftstheoretische Terminologie von Kuhn wird neben Replikationskrise auch Glaubwürdigkeits-Revolution (Credibility Revolution; REF <https://www.nature.com/articles/s44271-023-00003-2>) verwendet. Für [\[LR9\]](#_msocom_9) philosophische Betrachtungen siehe auch REF <https://osf.io/preprints/metaarxiv/2dz9s/> .

ABBILDUNG X: PARADIGMENWECHSEL

## "Beim ersten Versuch kommen die Ergebnisse nie so raus, wie sie sollten": Der Paradigmenwechsel in der Psychologie

Ein Paradigmenwechsel ist vergleichbar mit einem Kippbild die dem Hase-Ente-Bild (**Abbildung 1**) wie es zum Beispiel Wittgenstein (Tractatus logico-philosophicus, 1984) gezeichnet hat. Bis zu einem gewissen Punkt sind sich alle einig, dass es ein Hase ist. Doch nach und nach kommen Erkenntnisse und Perspektiven hinzu. Der Punkt wird überschritten, die Ente ist anerkannt, und niemand würde es mehr für einen Hasen halten. Beim Hase-Ente-Bild lässt sich natürlich beliebig hin und her springen. Beim wissenschaftlichen Fortschritt kommt neues Wissen hinzu und eine Rückkehr ist nur noch schwer möglich.

**Abbildung 1\
** *Hase-Ente-Kippbild frei nach Wittgenstein: Die Quader auf der linken Seite können entweder als Schnabel einer nach links blickenden Ente oder Ohren eines nach rechts blickenden Hasen interpretiert werden.*

Tatsächlich wurde ich von Beginn meiner Methodenausbildung an darin geschult, entsprechend des amtierenden psychologischen Paradigmas mit fehlgeschlagenen Replikationen umzugehen. Ich begann mein Studium bevor die Replikationskrise sich herauskristallisierte. Bei der ersten Studie, an der ich beteiligt war, replizierten wir den Befund, dass bunte Mengen in ihrer Anzahl weniger aussahen als einfarbige Mengen. Im Rahmen der Konsumentenpsychologie ist das hinsichtlich Slogans wie "viele viele bunte Smarties" etwas kontraintuitiv, es lässt sich aber gestaltpsychologisch plausibel darlegen. Nachdem eine Vorgruppe das Gegenteil herausfand, nämlich das bunte Smarties tatsächlich nach mehr aussahen als einfarbige Smarties, konnten wir in zwei eigenen Studien nichts vom beiden nachweisen. Egal ob die Teller, Tassen, oder Schalen, die wir den Leuten gaben, aus blauen, roten, gelben, oder bunten Schokolinsen bestanden: Unsere Versuchspersonen schätzten immer unabhängig von der Farbe. In den folgenden Jahren durfte ich als Tutor dann weitere Replikationsversuche durchführen. Der betreuende Professor erklärte: Ich habe es eigentlich noch nie erlebt, dass die Hypothese gleich beim ersten Versuch bestätigt wird. Nach jedem Experiment ist man schlauer und weiß, was man nächstes Mal besser machen muss. Es ist ganz natürlich, dass es ein paar Versuche dauert, bis man weiß, wie sich die Hypothese bestätigen lässt. Nachdem wir 5 (?XXX) Studien mit insgesamt über XXX Versuchspersonen durchgeführt hatten, die Autoren der Originalstudie um Rat gebeten haten, haufenweise Schokolinsen verzehrt hatten, und die Hypothese über alle Studien hinweg nicht bestätigt wurde, hatte ich das Vertrauen in den Befund verloren.

Ungefähr sechs Jahre später dachte ich während meiner Promotionszeit an die Studien zurück und diskutierte mit dem Professor. Im Rahmen der Replikationskrise war klar: Wenn man mehrere Experimente durchführt und die Hypothese eigentlich falsch ist, wird alleine durch den Zufall ab und zu trotzdem die Hypothese bestätigt. Das ist vergleichbar damit, dass selbst eine faire Münze sechs Mal hintereinander auf derselben Seite landen kann. Es passiert nicht oft, wenn man jedoch 10 Münzen gleichzeitig sechs Mal wirft, ist es nicht selten, dass eine davon sechs Mal auf derselben Seite landet. Aus dieser Perspektive hat das Zitat, dass die Ergebnisse beim ersten Versuch eigentlich nie so rauskommen, wie man es sich wünscht, einen bitteren Beigeschmack. Wenn die Hypothese falsch ist, ist es tatsächlich unwahrscheinlich, dass sie dennoch bestätigt wird. Nicht aber, wenn man mehrere Studien hintereinander durchführt. Dann ist es sogar zu erwarten, dass irgendwann eine Studie die Hypothese - auch wenn sie eigentlich falsch ist (!) - bestätigt.

# Struktur der Vertrauenskrise

Im Gespräch über Präregistrierungen -- eine Methode zur Erhöhung der Replizierbarkeit eines Befundes -- entgegnete ein Kollege: \"Schön und gut, aber solange sich das System nicht ändert, wird sich an Replikationsraten nichts ändern.\" Wie lässt sich dieser Einwand verstehen? Zäumen wir dazu das Pferd von hinten auf: Spätestens seit dem Reproducibility Project Psychology (Open Science Collaboration, 2015) ist den meisten Psycholog\*innen klar, dass wir massive Probleme bei der Replizierbarkeit von Befunden haben. Woher kommen diese genau? Ein wichtiges Problem ist hierbei der *Publikationsbias*, womit gemeint ist, dass bei der Veröffentlichung von wissenschaftlichen Berichten eine Auswahl getroffen werden muss und dadurch nur bestimmte Ergebnisse publiziert werden (z.B. Ergebnisse, die eine bestimmte Theorie stützen). Dadurch steht ein verzerrtes Bild der Realität. Oft schreiben Wissenschaftler\*innen sogar nur bestimmte Befunde zu Berichten zusammen. \"Fehlgeschlagene Experimente\", also solche, bei denen eine Hypothese nicht bestätigt oder eine Theorie nicht gestützt werden konnte, landen in der Schublade (engl. *File-Drawer-Problem*; Rosenthal, 1979; Sterling, 1959). In extremeren Fällen bedienen sich Wissenschaftler\*innen verschiedener größtenteils anerkannter Methoden, die Daten so darzustellen, dass sie die Hypothese stützen oder tun so, als ob das, was sich aus den Daten lesen lässt, von Beginn an die Hypothese gewesen wäre (HARKing, REF). Aber was treibt Personen, die sich vor allem für den Beruf wegen ihres Interesse an der Funktionsweise der Welt (oder im Falle der Psychologie der Funktionsweise des Menschen) und wegen Ihrer Suche nach Wahrheit entschieden haben dazu, die Wahrheit zu schönen? Am Anfang des komplexen Prozesses, welcher zur Replikationskrise geführt hat, steht das aktuelle wissenschaftliche System: Ein Großteil der in der Wissenschaft beschäftigten arbeitet unter extremem Druck und prekären Arbeitsbedingungen. Um nach ein bis zwei Jahren eine Vertragsverlängerung zu erhalten, müssen Publikationen von Artikeln in möglichst angesehenen Fachzeitschriften nachgewiesen werden. Diese kriegt man durch besonders aussagekräftige und spannende Ergebnisse. Das Anreizsystem der Wissenschaft belohnt also nicht Wahrheit, Genauigkeit, Bescheidenheit, oder Transparenz, sondern vor allem diejenigen Dinge, die nicht in der Hand eine\*r Wissenschaftler\*in liegen: Spannende und eindeutige Ergebnisse.

Der Prozess von prekären Arbeitsbedingungen bis zur niedrigen Replikationsrate ist in Abbildung 1 veranschaulicht. In den folgenden Kapiteln werden die Probleme und Lösungsansätze im Detail diskutiert.

**Abbildung 2**

*Das Anreizsystem der Wissenschaft als Ursache für Replikationsfehlschläge*

[\[LR10\]](#_msocom_10) 

[\[1\]](#_ftnref1)Obgleich dieses „Reproducibility Project Psychology\" die gesamte Fachgemeinschaft zutiefst erschütterte und den Weg für einen Paradigmenwechsel ebnete, bemängeln manche Forschende auch negative Auswirkungen auf nachfolgende Replikationsforschung. Indem 100 Studien gleichzeitig von einer Gruppe aus über 100 Forschenden veröffentlicht wurden, setzte das Projekt unrealistische Maßstäbe für Replikationsforschung (REF Gilad Feldman twitter siehe eine Mail Sommer 2022). Gleichzeitig war die Qualitätskontrolle dabei weniger streng, da die Einzelstudien nicht alle in dem Maße begutachtet werden konnten, wie es bei einer traditionellen Veröffentlichung der Fall gewesen wäre (z.B. Röseler 2022 OSF Replications). Einige gleichermaßen ambitionierte Vorhaben wurden veröffentlicht, wie zum Beispiel die ManyLabs Studien (REF) oder Versuche, bei denen unabhängige Gruppen dieselben Hypothesen testeten und replizierten (REF crowdsourcing hypothesis test). Oft beschränken sich diese Vorhaben auf Studien, die sich im Rahmen einer Online-Befragung replizieren lassen. Verhaltensbeobachtungen sind dabei unterrepräsentiert.

[\[2\]](#_ftnref2) Analog dazu gibt es für Universitätsrankings das transparente Leiden Ranking (<https://open.leidenranking.com>).

[\[3\]](#_ftnref3) Für eine ausführliche Diskussion über die Replikationskrise als Paradigmenwechsel siehe REF <https://www.degruyter.com/document/doi/10.1515/ling-2019-0045/html>

 [\[LR1\]](#_msoanchor_1)https://osf.io/preprints/psyarxiv/dtvs7/

 [\[LR2\]](#_msoanchor_2)Open science collab 2015

 [\[LR3\]](#_msoanchor_3)Einarbeiten: <https://www.dfg.de/resource/blob/172844/d25fe7c0dea8a229c682d64b1efe4f1a/170425-stellungnahme-replizierbarkeit-forschungsergebnisse-de-data.pdf>

 [\[LR4\]](#_msoanchor_4)Aus <https://publiscologne.th-koeln.de/frontdoor/deliver/index/docId/2302/file/BA_Wolf_Helga.pdf> p. 21/239

 [\[LR5\]](#_msoanchor_5)Hinzufügen

<https://link.springer.com/article/10.1007/s42803-023-00073-y>

allgemeine auslegung und auf andere Felder anwendbar (ingenieurswissenschaften):

<https://www.tandfonline.com/doi/abs/10.1080/0020174X.2023.2278032>

<https://the-turing-way.netlify.app/reproducible-research/overview/overview-definitions.html>

<https://languagelog.ldc.upenn.edu/nll/?p=21956>

 [\[LR6\]](#_msoanchor_6)<https://osf.io/preprints/socarxiv/4dsqa>

 [\[LR7\]](#_msoanchor_7)Hier auch n-pact factor

<https://www.researchgate.net/publication/364520526_Journal_N-Pact_Factors_From_2011_to_2019_Evaluating_the_Quality_of_SocialPersonality_Journals_With_Respect_to_Sample_Size_and_Statistical_Power>

 [\[LR8\]](#_msoanchor_8)einarbeiten: [https://www.researchgate.net/profile/Mark-Rubin-9/publication/373353747_The_Replication_Crisis_is_Less_of_a_Crisis_in_Lakatos'\_Philosophy_of_Science/links/658575ef0bb2c7472b014f7a/The-Replication-Crisis-is-Less-of-a-Crisis-in-Lakatos-Philosophy-of-Science.pdf](https://www.researchgate.net/profile/Mark-Rubin-9/publication/373353747_The_Replication_Crisis_is_Less_of_a_Crisis_in_Lakatos'_Philosophy_of_Science/links/658575ef0bb2c7472b014f7a/The-Replication-Crisis-is-Less-of-a-Crisis-in-Lakatos-Philosophy-of-Science.pdf)

 [\[LR9\]](#_msoanchor_9)mehrere parallele paradigmen: <https://www.tandfonline.com/doi/10.1080/1350178X.2023.2192231>

 [\[LR10\]](#_msoanchor_10)Terminologie vereinfachen oder Erklärungen ergänzen
