<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.53">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Lukas Röseler">
<meta name="description" content="Vertrauenskrise, Replikationsrevolution, und Open Science einfach und umfangreich erklärt">

<title>Das System – Open Science: Wie sich die Wissenschaft öffnet</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./lösungen_methoden.html" rel="next">
<link href="./lösungen.html" rel="prev">
<link href="./images/favicon_os.jpg" rel="icon" type="image/jpeg">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./lösungen.html">Lösungen</a></li><li class="breadcrumb-item"><a href="./lösungen_system.html"><span class="chapter-title">Das System</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Open Science: Wie sich die Wissenschaft öffnet</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/LukasRoeseler/opensciencebuch" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Open-Science--Wie-sich-die-Wissenschaft-öffnet.pdf">
              <i class="bi bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Open-Science--Wie-sich-die-Wissenschaft-öffnet.epub">
              <i class="bi bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Willkommen</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./about.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Über das Buch</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./einleitung.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Einleitung</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wasistopenscience.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Was ist Open Science?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./umgehenmitopenscience.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Wie ist mit Open Science umzugehen?</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./geschichte.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Die Geschichte der Open Science Bewegung</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./anfänge.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Anfänge einer Revolution</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bestandsaufnahme.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Bestandsaufnahme</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wandel.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Wandel im System</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./struktur.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Struktur der Vertrauenskrise</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./probleme.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probleme</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probleme_system.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Das System</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probleme_karriere.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Karriere in der Wissenschaft</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probleme_methoden.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Methoden</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probleme_theorien.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Theorien</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probleme_epistemische.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Epistemische Probleme</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./lösungen.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lösungen</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lösungen_system.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Das System</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lösungen_methoden.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Methoden</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lösungen_theorien.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Theorien</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lösungen_welt.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Die Welt</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Fazit und Ausblick</span></span>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#politik" id="toc-politik" class="nav-link active" data-scroll-target="#politik">Politik</a></li>
  <li><a href="#universitäten" id="toc-universitäten" class="nav-link" data-scroll-target="#universitäten">Universitäten</a></li>
  <li><a href="#institute-und-vereinigungen" id="toc-institute-und-vereinigungen" class="nav-link" data-scroll-target="#institute-und-vereinigungen">Institute und Vereinigungen</a></li>
  <li><a href="#zeitschriften" id="toc-zeitschriften" class="nav-link" data-scroll-target="#zeitschriften">Zeitschriften</a></li>
  <li><a href="#forschende" id="toc-forschende" class="nav-link" data-scroll-target="#forschende">Forschende</a></li>
  <li><a href="#bewertungskriterien" id="toc-bewertungskriterien" class="nav-link" data-scroll-target="#bewertungskriterien">Bewertungskriterien</a></li>
  <li><a href="#infrastruktur-open-infrastructure" id="toc-infrastruktur-open-infrastructure" class="nav-link" data-scroll-target="#infrastruktur-open-infrastructure">Infrastruktur (Open Infrastructure)</a></li>
  <li><a href="#sec-openaccess" id="toc-sec-openaccess" class="nav-link" data-scroll-target="#sec-openaccess">Open Access Publikationen</a></li>
  <li><a href="#pre-prints" id="toc-pre-prints" class="nav-link" data-scroll-target="#pre-prints">Pre-Prints</a></li>
  <li><a href="#ansätze-gegen-die-selektion-spannender-ergebnisse" id="toc-ansätze-gegen-die-selektion-spannender-ergebnisse" class="nav-link" data-scroll-target="#ansätze-gegen-die-selektion-spannender-ergebnisse">Ansätze gegen die Selektion spannender Ergebnisse</a></li>
  <li><a href="#replikationsforschung" id="toc-replikationsforschung" class="nav-link" data-scroll-target="#replikationsforschung">Replikationsforschung</a></li>
  <li><a href="#modellierung-von-replizierbarkeit" id="toc-modellierung-von-replizierbarkeit" class="nav-link" data-scroll-target="#modellierung-von-replizierbarkeit">Modellierung von Replizierbarkeit</a></li>
  <li><a href="#veröffentlichung-aller-ergebnisse" id="toc-veröffentlichung-aller-ergebnisse" class="nav-link" data-scroll-target="#veröffentlichung-aller-ergebnisse">Veröffentlichung aller Ergebnisse</a></li>
  <li><a href="#umgang-mit-fehlern" id="toc-umgang-mit-fehlern" class="nav-link" data-scroll-target="#umgang-mit-fehlern">Umgang mit Fehlern</a></li>
  <li><a href="#offene-lehre-open-teaching-open-educational-resources" id="toc-offene-lehre-open-teaching-open-educational-resources" class="nav-link" data-scroll-target="#offene-lehre-open-teaching-open-educational-resources">Offene Lehre / Open Teaching / Open Educational Resources</a></li>
  <li><a href="#literatur" id="toc-literatur" class="nav-link" data-scroll-target="#literatur">Literatur</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/LukasRoeseler/opensciencebuch/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./lösungen.html">Lösungen</a></li><li class="breadcrumb-item"><a href="./lösungen_system.html"><span class="chapter-title">Das System</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Das System</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Ansätze, die darauf abzielen, das System zu verändern, bergen am meisten Potenzial, denn um im System Geld verdienen zu können, müssen Forschende sich an die Regeln halten. Und solange Publikationen die Währung sind und Paper mit knackigen Titeln und eindeutigen Ergebnissen als qualitativ hochwertiger befunden werden, sind Forschende darin motiviert, nach knackigen Titeln und eindeutigen Ergebnissen und nicht nach der Wahrheit zu suchen.</p>
<p>Insgesamt ist eine positive Entwicklung sichtbar <span class="citation" data-cites="Korbmacher.2023">(<a href="#ref-Korbmacher.2023" role="doc-biblioref">Korbmacher et al. 2023</a>)</span> und eine Veränderung der Anreizstruktur wird anvisiert. Sie lässt sich als Angleichung des wissenschaftlichen Systems an die <em>Mertonschen Normen</em> (nach Robert Merton) auffassen <span class="citation" data-cites="merton1973sociology">(<a href="#ref-merton1973sociology" role="doc-biblioref">Merton 1973</a>)</span>: (1) Kommunismus: Das wissenschaftliche Wissen sollte allen Wissenschaftler*innen gleichermaßen gehören, um die Zusammenarbeit zu fördern. (2) Universalismus: Wissenschaftliche Güte ist unabhängig vom soziopolitischen Status und persönlichen Attributen der Teilhabenden. (3) Desinteresse: Wissenschaftliche Institutionen handeln im Interesse der Wissenschaft und nicht für persönlichen Gewinn. (4) Organisierter Skeptizismus: Wissenschaftliche Behauptungen sollten einer kritischen Prüfung unterzogen werden bevor sie akzeptiert werden.</p>
<p>Nosek empfiehlt in einem <a href="https://www.cos.io/blog/strategy-for-culture-change">Blogpost</a> eine Maßnahmenstruktur, nach welcher die gewünschten Veränderung nacheinander …</p>
<ol type="1">
<li>möglich (z.B. durch Infrastruktur wie online Repositorien, in denen Forschungsmaterialien öffentlich und gratis hochgeladen werden können),</li>
<li>einfach (z.B. durch barrierearme Angebote, mehrsprachige Anleitungen),</li>
<li>normativ (z.B. durch Wissenschaftliche Communities, die gemeinsam hinter Forderungen der Verbesserung stehen),</li>
<li>belohnend (z.B. durch designierte Preise), und</li>
<li>notwendig (z.B. durch Mindeststandards, die von Zeitschriften oder Drittmittelgebern gefordert werden)</li>
</ol>
<p>gemacht werden sollen. Wie die verschiedenen Ansätze bei den verschiedenen Akteuren, also Politik, Universitäten, oder Zeitschriften konkret aussehen, wird im Folgenden diskutiert.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pyramide.jpg" class="img-fluid figure-img"></p>
<figcaption>Kulturwandel in der Wissenschaft nach Nosek (https://www.cos.io/blog/strategy-for-culture-change)</figcaption>
</figure>
</div>
<section id="politik" class="level3">
<h3 class="anchored" data-anchor-id="politik">Politik</h3>
<p>International stehen politische Parteien und Vereinigungen deutlich hinter Open Science und Open Access. Beispielsweise empfiehlt die UNESCO einen universellen Zugang zu wissenschaftlichen Wissen ungeachtet von Herkunftsland, Geschlechterrolle, politischen Grenzen, ethnischer Zugehörigkeit, oder ökonomischen oder technologischen Hürden [<span class="citation" data-cites="unesco2020first">UNESCO (<a href="#ref-unesco2020first" role="doc-biblioref">2020</a>)</span>; p.&nbsp;3]. <a href="https://opusproject.eu/openscience-news/open-science-horizon-unescos-recommendation/">Arbeitsgruppen</a> für politische Instrumente, Förderung, und Infrastruktur wurden entsprechend gegründet. Die <a href="G7 BEST PRACTICES FOR SECURE &amp; OPEN RESEARCH Security and Integrity of the Global Research Ecosystem (SIGRE) Working Group">G7</a> setzen sich für wissenschaftliche Integrität, akademische Freiheit, und Open Science ein. <a href="https://www.consilium.europa.eu/en/press/press-releases/2023/05/23/council-calls-for-transparent-equitable-and-open-access-to-scholarly-publications/">Offener Zugang</a> aber auch <a href="Triggers for audits of good laboratory practice (GLP) studies">Transparenz</a> des wissenschaftlichen Vorgehens wird auch seitens der Europäischen Union gefordert. Infrastruktur (z.B. die <a href="https://eosc-portal.eu">European Open Science Cloud</a>) und diverse Open Science Forschungsprojekte werden gezielt gefördert. Für alle durch die EU geförderten Forschungsprojekte steht zudem die kostenlose Publikations- und Begutachtungs-Plattform <a href="https://open-research-europe.ec.europa.eu">Open Research Europe</a> zur Verfügung.</p>
<p>In Deutschland hat sich die Regierung der Periode 2021-2025 im Rahmen des Koalitionsvertrages vorgenommen, „Open Access … als gemeinsamen Standard [zu] etablieren.” Einzelne Bundesländer wie Nordrhein-Westfalen haben in Zusammenschlüssen aus den jeweiligen Universitäten darüber hinaus Open <em>Access</em> Strategien entwickelt <span class="citation" data-cites="Openness2023-ga">(<a href="#ref-Openness2023-ga" role="doc-biblioref">Openness 2023a</a>)</span> und arbeiten aktuell an Open <em>Science</em> Strategien. Andere Länder, wie zum Beispiel Schweden, haben bereits <a href="https://www.kb.se/samverkan-och-utveckling/nytt-fran-kb/nyheter-samverkan-och-utveckling/2024-01-15-national-guidelines-for-promoting-open-science-in-sweden.html">nationale Richtlinien zu Open Science</a> entwickelt. Hinsichtlich der Problematik von Machtmissbrauch wird das Problem beispielsweise in einem Eckpunkte-Papier des Landes NRW anerkannt, doch als <a href="https://opal.landtag.nrw.de/portal/WWW/dokumentenarchiv/Dokument/MMV18-2422.pdf">Einzelfall</a>- statt System-Problem verstanden (<a href="https://www.jmwiarda.de/https-www.jmwiarda.de-2024-05-28-bitte-nachschaerfen/">Kommentar dazu</a>).</p>
</section>
<section id="universitäten" class="level3">
<h3 class="anchored" data-anchor-id="universitäten">Universitäten</h3>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Welche Universitäten tun etwas? (Beispiele)
</div>
</div>
<div class="callout-body-container callout-body">
<p>Das Thema Open Science hat bei vielen Universitäten bereits Anklang gefunden. Während die meisten deutschen Universitäten (zeitlich begrenzte) Mittel für Open Access Publikationen haben, existieren an einigen darüber hinaus Open Science Policys (z.B. <a href="https://oa-info.sh/2022/01/open-science-policy-der-uni-erlangen-nuernberg/">FAU Erlangen</a>), Open Science Centers (z.B. <a href="https://www.osc.uni-muenchen.de/index.html">LMU Open Science Center</a>; <a href="https://oscc.uni-koeln.de/home">Köln Open Science Center</a>; <a href="https://www.uni-muenster.de/MueCOS/">Münster Center for Open Science</a>; <a href="https://www.uni-mannheim.de/open-science/open-science-office/">Mannheim Open Science Office</a>). Darüber hinaus unterstützen das Leibniz-Informationszentrum Wirtschaft in Kiel und das Leibniz-Institut für Psychologie Replikationsforschung beispielsweise mit einer Replikationszeitschrift (<a href="https://www.jcr-econ.org" class="uri">https://www.jcr-econ.org</a>) oder im Rahmen einer Juniorprofessur für Psychologische Metawissenschaft. An der TU Dortmund wurde eine Bedarfserhebung zum Thema Forschungsdatenmanagement durchgeführt <span class="citation" data-cites="kletke2024bestands">(<a href="#ref-kletke2024bestands" role="doc-biblioref">Kletke et al. 2024</a>)</span>. Eines der größten Zentren für Metawissenschaft n Europas hat sich in den Niederlanden in Tilburg gebildet. Die Berliner Universitäten haben eine gemeinsame Open Access Erklärung entwickelt (<a href="https://openaccess.mpg.de/Berliner-Erklaerung" class="uri">https://openaccess.mpg.de/Berliner-Erklaerung</a>) und in Frankreich ist die Universität Sorbonne ein Pionier: Gemeinsam mit der Universität Amsterdam und dem Universitätscollege London wurde eine Erklärung über die die Veröffentlichung von Forschungsdaten unterzeichnet. Seit 2024 hat die Universität Sorbonne darüber hinaus den Vertrag mit Clarivate für die Nutzung der Forschungsdatenbank „Web of Science” gekündigt und arbeitet seitdem mit der Open Source Software „OpenAlex” <span class="citation" data-cites="Priem2022-mb">(<a href="#ref-Priem2022-mb" role="doc-biblioref">Priem, Piwowar, and Orr 2022</a>)</span>.</p>
</div>
</div>
<p>Für die langfristige Entwicklung der Wissenschaften haben Universitäten dadurch eine besondere Verantwortung, dass sie Wissenschaftler*innen beschäftigen und an ihnen die Auswahl für die wenigen unbefristeten Arbeitsplätze in der Wissenschaft fallen. Wenn jahrzehntelang Professuren auf Basis subjektiver, nicht-reproduzierbarer, und für gute Wissenschaft nachrangigen Kriterien gewählt werden (z.B. Anzahl an Publikationen in Fachzeitschriften), kann sich das negativ auf die Entwicklung von Wissenschaften auswirken. Diesem Problem entgegenwirkend wurde ein Forschungspreis des Berlin Institute of Health (BIH), der jährlich für Projekte zur Förderung von wissenschaftlicher Integrität verliehen wird, an ein Projekt, das objektive und sinnvolle Auswahlkriterien für Professor*innen entwickelt vergeben <span class="citation" data-cites="schonbrodt2022responsible gartner2022responsible">(<a href="#ref-schonbrodt2022responsible" role="doc-biblioref">Schönbrodt, Gärtner, Frank, Gollwitzer, Ihle, Mischkowski, Phan, Schmitt, Scheel, Schubert, and others 2022</a>; <a href="#ref-gartner2022responsible" role="doc-biblioref">Gärtner, Leising, and Schönbrodt 2022a</a>)</span>. Um die Rolle quantiativer Indikatoren zu schwächen wird bereits an einigen Universitäten und bei DFG-Anträgen die “N-best” bzw. häufig “5-best” Regel angewandt <span class="citation" data-cites="Frank2019-ro">(<a href="#ref-Frank2019-ro" role="doc-biblioref">Frank 2019</a>)</span>: Dabei dürfen nur die 5 besten Forschungsartikel in der Bewerbung genannt werden und die Evaluation darf nur auf Basis von ihnen geschehen.</p>
<p>Innerhalb von Universitäten spielen außerdem die Bibliotheken eine aufklärerische Rolle hinsichtlich Forschungsdatenmanagement und Publikationskultur <span class="citation" data-cites="Schmidt2024-uv">(<a href="#ref-Schmidt2024-uv" role="doc-biblioref">Schmidt et al. 2024</a>)</span>. Über sie kann der Forschungsprozess mit entsprechender Infrastruktur (z.B. zum Lagern und Veröffentlichen von Forschungsmaterialien und -ergebnissen) unterstützt werden <span class="citation" data-cites="Quan2021-hw">(<a href="#ref-Quan2021-hw" role="doc-biblioref">Quan 2021</a>)</span> und verhindert werden, dass sich eine „Abhängigkeit von wenigen kommerziellen Anbietern” ergibt, die „begrenzen, was [bei] der Forschung an Arbeitsmöglichkeiten und Fragestellungen erreichbar ist” <span class="citation" data-cites="Siems2024-vv">(<a href="#ref-Siems2024-vv" role="doc-biblioref">Siems 2024</a>)</span>. Eine Pflicht, Mitglieder eine Universität zur Einhaltung von Open Science Strategien zu bewegen, gibt es an Universitäten durch den hohen Stellenwert der „Freiheit der Forschung” kaum. Damit könnten sie Gefahr laufen, für Forschende weniger attraktiv zu werden: Wenn beispielsweise auf namhafte Zeitschriften nicht mehr über die Universität zugegriffen werden kann, weil Verträge mit closed-access Zeitschriften gekündigt wurden, erschwert das den Forschenden die Arbeit. Beispielsweise klagte die juristische Fakultät der Universität Konstanz gegen eine Zweitveröffentlichungs<em>pflicht</em>: Forschende in Deutschland haben das <a href="https://de.wikipedia.org/wiki/Zweitveröffentlichung">Recht zur Zweitveröffentlichung</a>, das heißt, dass sie ihre Forschung, wenn sie in einer Fachzeitschrift veröffentlicht wurde, auch selbst (z.B. über eigene Websites) veröffentlichen dürfen. In Konstanz konnten die Forschenden nicht dazu verpflichtet werden, davon Gebrauch zu machen.</p>
<p>Ein weiteres Stellrad von Universitäten ist die Bezuschussung von Publikationskosten bei Zeitschriften. Wird beispielsweise die wissenschaftliche Qualität einer Zeitschrift angezweifelt, kann eine Universität diese <a href="https://www.suub.uni-bremen.de/ueber-uns/neues-aus-der-suub/unter-kritischer-beobachtung-open-access-publikationen-im-mdpi-verlag">Bezuschussung stoppen</a>.</p>
<p>Eine oft vernachlässigte Rolle kommt außerdem der universitären Lehre hinzu. Durch die Freiheit von Forschung und Lehre und bereits durchgeplanten Studiengängen gestaltet sich die Integration neuer Themen wie Open Science schwierig. Forschende, in deren Lehre die Thematik eine Rolle spielt, teilen proaktiv ihre Materialien, erstellen gemeinsam Curricula, und sind beispielsweise in großen internationalen Initiativen wie dem Framework for Open and Reproducible Research Training (<a href="https://forrt.org">FORRT.org</a>) vernetzt (konkrete Vorschläge zur Integration von Open Science in die Lehre hat zum Beispiel <span class="citation" data-cites="Pennington2024-mp">Pennington and Pownall (<a href="#ref-Pennington2024-mp" role="doc-biblioref">2024</a>)</span> veröffentlicht.</p>
</section>
<section id="institute-und-vereinigungen" class="level3">
<h3 class="anchored" data-anchor-id="institute-und-vereinigungen">Institute und Vereinigungen</h3>
<p>Wissenschaftliche Gebiete leben vor allem durch Communities, also alle in dem Bereich forschenden Personen. Sie organisieren sich in Vereinen (z.B. Deutsche Gesellschaft für Psychologie), Interessensverbunden, oder ähnlichen Gemeinschaften. Eine besondere Stellung hat in Deutschland die Deutsche Forschungsgemeinschaft, welche staatlich und über die Bundesländer mit mehreren Milliarden Euro ausgestattet Forschungsgelder vergibt. Als eine der wichtigsten nationalen Institution hat ihre Open Science Positionierung einen hohen Stellenwert <span class="citation" data-cites="Deutsche_Forschungsgemeinschaft2022-qx">(<a href="#ref-Deutsche_Forschungsgemeinschaft2022-qx" role="doc-biblioref">Deutsche Forschungsgemeinschaft 2022</a>)</span>. Erfahrungsgemäß gehen Veränderungen jedoch nicht von der DFG aus, sondern die DFG wartet auf Anstöße aus den Fächern. In der Psychologie fördert darüber hinaus das <a href="https://leibniz-psychology.org/das-institut">ZPID</a> die Infrastruktur durch Zeitschriften, Pre-Print Server, und weitere Methoden und in den Wirtschaftswissenschaften verwaltet das ZBW wichtige Informationen oder Zeitschriften (REF). Auch interdisziplinäre Vereinigungen wie das <a href="https://openscience.cern">CERN</a> oder internationale Akteure wie die <a href="https://www.apa.org/pubs/journals/resources/publishing-tips/transparency-openness-promotion-guidelines?utm_campaign=apa_publishing&amp;utm_medium=direct_email&amp;utm_source=businessdevelopment&amp;utm_content=openscience_promo_11302023&amp;utm_term=text_middle_learnmore">American Psychological Association</a> verpflichten sich zu Offenheit und Transparenz.</p>
<p>Im Rahmen der Open Science Reform entstanden außerdem viele neue Vereinigungen. Das interdisziplinäre und besonders von Wissenschaftler*innen in der frühen Karrierephase geleitete FORRT <span class="citation" data-cites="Azevedo2019-df">(<a href="#ref-Azevedo2019-df" role="doc-biblioref">Azevedo et al. 2019</a>)</span> setzt sich für eine Verankerung von Open Science in der Lehre ein. Der Verbesserung psychologischer Forschung hat sich die Society for the Improvement of Psychological Science (SIPS) verschrieben. Sogenannte „grassroot”-Initiativen (also von jungen Wissenschaftler*innen ausgehende Bewegungen) haben sich an zahlreichen Universitäten herausgebildet und zu Netzwerken wie dem <a href="https://osf.io/tbkzh/">Netzwerk der Open Science Initiativen (NOSI)</a> und „Reproducibility Networks” wie dem deutschen Netzwerk <em>GRN</em> (<a href="https://reproducibilitynetwork.de" class="uri">https://reproducibilitynetwork.de</a>), dem im Vereinigten Königreich <em>UKRN</em> (<a href="https://www.ukrn.org" class="uri">https://www.ukrn.org</a>) und weiteren zusammengeschlossen. Aber auch Zusammenschlüsse von Professor*innen zur Änderung von Kurzzeitverträgen existieren (z.B. Netzwerk Nachhaltige Wissenschaft, <a href="https://netzwerk-nachhaltige-wissenschaft.de" class="uri">https://netzwerk-nachhaltige-wissenschaft.de</a>).</p>
</section>
<section id="zeitschriften" class="level3">
<h3 class="anchored" data-anchor-id="zeitschriften">Zeitschriften</h3>
<p>Wissenschaftliche Zeitschriften gelten als Bühne des wissenschaftlichen Diskurses und bestimmen maßgeblich, welche Elemente des Forschungsprozesses zum „scientific record” gehören und damit relevant sind. Sie sind darüber hinaus als Organisatorinnen des Begutachtungsprozesses für die Qualitätssicherung in der Wissenschaft verantwortlich. Dem Mangel an Qualität entgegnend existieren bereits ausführliche Empfehlungen zur Gestaltung von Zeitschriften, es bilden sich neue Zeitschriften, und vollständige neue Begutachtungs- und Publikationsmodelle werden vorgeschlagen und vielseitig implementiert. Das Journal of <a href="https://joss.theoj.org">Open Source Software</a> basiert beispielsweise auf einem öffentlich einsehbaren Programmiercode und seine Infrastruktur lässt sich für weitere Zeitschriften einfach kopieren und anpassen.</p>
<section id="empfehlungen" class="level4">
<h4 class="anchored" data-anchor-id="empfehlungen">Empfehlungen</h4>
<p>Herausgeber*innen, die sich in Bezug auf die von ihnen verwaltete Zeitschrift mit Open Science Praktiken auseinandersetzen möchten, können inzwischen auf einen umfangreichen Leitfaden zurückgreifen <span class="citation" data-cites="Silverstein2023-ek">(<a href="#ref-Silverstein2023-ek" role="doc-biblioref">Silverstein et al. 2023</a>)</span>. Über eine Diskussionsplattform (Journal Editors Discussion Interface, JEDI) wurden Vorschläge gesammelt und es wird erklärt, worum es sich bei Dingen wie Registered Reports, Open Peer Review, Diversifizierung, und Open Access handelt und wie diese in eine Zeitschrift implementiert werden können. Eventuelle Sorgen und Ängste werden angesprochen und beantwortet. Das Committee on Publication Ethics (COPE) setzt sich ebenfalls für Aufklärung und Lehre ein, die Herausgeber, Universitäten, und Forschungsinstitute im Umgang mit Problemen im Publikationssystem helfen soll. Es bietet beispielsweise <a href="https://publicationethics.org/retraction-guidelines">Richtlinien</a> unter welchen Umständen Publikationen zurückgezogen oder korrigiert werden sollten, oder welche ethischen Standards ein <a href="https://publicationethics.org/resources/guidelines/cope-ethical-guidelines-peer-reviewers">Begutachtungsprozess</a> erfüllen sollte. Herausgeber*innen, die Zeitschriften für kommerzielle Verlage verwalten und auf Systeme umsteigen möchten, die vollständig in der Hand der Forschenden liegen, können über Universitätsbibliotheken Hilfe bei der Migration von den kommerziellen zu offenen und kostenfreien Systemen erhalten und Zeitschriften beispielsweise mit dem Open Journal System verwalten (siehe z.B. <a href="https://ojs-de.net/start">OJS Netzwerk</a>). Eine Datenbank mit bereits über 20,000 offen zugänglichen Zeitschriften verwaltet das Directory of Open Access Journals (<a href="https://doaj.org">DOAJ</a>). Gutachter*innen von Forschungsartikeln können über die Reviewer Zero Initiative (<a href="https://www.reviewerzero.net" class="uri">https://www.reviewerzero.net</a>) auf Lehrmaterialien und Leitfäden zugreifen (<a href="https://osf.io/e7z5k/wiki/Resources/" class="uri">https://osf.io/e7z5k/wiki/Resources/</a>).</p>
</section>
<section id="open-science-praktiken-hervorheben" class="level4">
<h4 class="anchored" data-anchor-id="open-science-praktiken-hervorheben">Open Science Praktiken hervorheben</h4>
<p>Aus der Psychologie ist lange bekannt, dass Motivation über Belohnung besser funktioniert als über Bestrafung (REF). Im Straßenverkehr, in dem es bis vor einiger Zeit nur Bestrafungen für Verletzen von Regeln gab, äußert sich die Erkenntnis beispielsweise an Geschwindigkeitstafeln, die den Autofahrer*innen beim Einhalten des Tempolimits einen fröhlichen Smiley zurückmelden. Wissenschaftliche Zeitschriften heben Einhaltung von Empfehlungen (z.B. öffentlich verfügbare Datensätze) mit Plaketten (<em>Badges</em>) hervor. Die Zeitschrift <em>Psychological Science</em> geht dabei seit 2024 so weit, dass Badges schon wieder abgeschafft werden und Open Science dort der Standard für alle Artikel ist. Auf der Website topfactor.org sind Zeitschriften und deren Einhaltung verschiedener Standards aufgelistet und in einer Rangliste abgebildet. Zuletzt besteht in jedem System mit Belohnungen das Problem, dass die Akteure ihr Verhalten auf die Belohnungen hin ausrichten und dabei versuchen, Abkürzungen zu gehen <span class="citation" data-cites="Klonsky2024-pl">(<a href="#ref-Klonsky2024-pl" role="doc-biblioref">Klonsky 2024</a>)</span>.</p>
</section>
<section id="review-systeme" class="level4">
<h4 class="anchored" data-anchor-id="review-systeme">Review Systeme</h4>
<p>Wissenschaft zeichnet sich durch Systematik aus <span class="citation" data-cites="HoyningenHuene.2013">(<a href="#ref-HoyningenHuene.2013" role="doc-biblioref">Hoyningen-Huene 2013</a>)</span>. Der wohl systematischste Weg, die wissenschaftliche Qualitätssicherung zu garantieren, wäre eine Studie, die verschiedene Systeme vergleicht. Während aktuelle Forschung ähnliches unternimmt <span class="citation" data-cites="Soderberg.2021">(<a href="#ref-Soderberg.2021" role="doc-biblioref">Soderberg et al. 2021</a>)</span>, werden alternative Begutachtungssysteme aktuell ausprobiert. Zur Erinnerung: Wissenschaftler*innen verfassen Artikel, die sie bei Zeitschriften einreichen. Dort ist eine Person (Editor) dafür zuständig, dass der Artikel, sofern er zur Zeitschrift passt, an Gutachtende gesendet wird.</p>
<p>Um zu prüfen, ob die Urteile im Begutachtungsprozess zwischen den Urteilenden übereinstimmen, haben <span class="citation" data-cites="etzel2024inter">Etzel et al. (<a href="#ref-etzel2024inter" role="doc-biblioref">2024</a>)</span> verschiedene Gutachtende hinsichtlich klassischer Kriterien befragt. Sie fanden heraus, dass das nicht der Fall ist und schlagen Kriterien vor, die einen klaren Wert haben, und sich gut erfassen lassen (z.B. ob Daten öffentlich verfügbar sind).</p>
</section>
<section id="open-peer-review" class="level4">
<h4 class="anchored" data-anchor-id="open-peer-review">Open Peer Review</h4>
<p>Seit der Auseinandersetzung Forschender mit dem Begutachtungssystem wird darüber hinaus diskutiert, was mit Gutachten passiert: Traditionell bleiben sie unter Verschluss. In der Fachzeitschrift erscheint der finale Artikel und alle vorherigen Versionen sind nur Autor<em>innen,</em> Herausgeber<em>in,</em> und Gutachter*innen bekannt. Diese bleiben zudem meistens anonym, das heißt, wenn sie sich keine Mühe gegeben haben, wird es wahrscheinlich nie auffallen. Außerdem haben Forschende keinen Anreiz, Gutachten zu verfassen - höchstens erhalten sie einen Nachweis, dass sie ein Manuskript bei einer Zeitschrift begutachtet haben. Einige Zeitschriften haben inzwischen das <em>Open Peer Review</em> eingeführt. Der Name passt nur halb, denn veröffentlicht werden Gutachten nur dann, wenn der Artikel bei der Zeitschrift akzeptiert wird. Das birgt die Gefahr, dass schwerwiegende Probleme, welche für eine Ablehnung üblicherweise nötig sind, nicht ans Licht kommen. Forschende können den Artikel dann ohne Überarbeitung bei einer anderen Zeitschrift einreichen, wo die Probleme vielleicht nicht entdeckt werden. Dieses Vorgehen führt zu Doppelarbeit und enormen Kosten <span class="citation" data-cites="aczel2021billion">(<a href="#ref-aczel2021billion" role="doc-biblioref">Aczel, Szaszi, and Holcombe 2021</a>)</span>. Zoltan Kekecs merkte dazu bei einer Diskussion im Rahmen einer Konferenz an, dass selbst Kasinos, die in Konkurrenz zueinander stehen, Listen von Betrüger<em>innen miteinander austauschen. Herausgeber</em>innen von Zeitschriften tun das noch nicht.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 48%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>Gutachten bleiben unter Verschluss</th>
<th>Gutachten werden bei Publikation veröffentlicht</th>
<th>Gutachten werden bei Publikation und Ablehnung veröffentlicht</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Es ist kein Nachweis der Qualitätskontrolle möglich.</td>
<td>Abgelehnte Artikel können bei anderen Zeitschriften ohne Überarbeitung eingereicht werden und führen zu Mehraufwand.</td>
<td>Qualitätskontrolle ist nachvollziehbar und transparent.</td>
</tr>
</tbody>
</table>
<p>Umstrittener als die Veröffentlichung von Gutachten ist die Anonymität der Gutachter<em>innen: Der Standard ist, dass Gutachten anonym sind, aber bei Wunsch unterzeichnet werden können. Promovierende, die einen Artikel eines potenziellen zukünftigen Chefs oder einer zukünftigen Chefin schlecht beurteilen, werden dadurch geschützt. Selbst Professor</em>innen können bei negativen Beurteilungen riskieren, dass der oder die Kollegin später einen Forschungsgelderantrag von ihnen begutachtet und sich für die Kritik rächt. Auf der anderen Seite kann Anonymität zur Folge haben, dass Kritik gegen die Person gerichtet ist und nicht konstruktiv ist.</p>
<p>Eine weitere Art, wie Peer-Review offen sein kann, ist, dass sich jede Person daran beteiligen kann. Das ist zum Beispiel bei Meta-Psychology möglich. Problematisch ist dabei jedoch die relativ geringe Beteiligung. Bei den Zeitschriften Zeitschrift Synlett und ASAPbio werden Gruppe dazu koordiniert, wie es sie zur Diskussion spannender Artikel schon in Form von <em>Journal Clubs</em> gibt - nur eben als “<a href="https://asapbio.org/crowd-preprint-review">Pre-Print Review Club</a>”.</p>
</section>
<section id="begutachtung-von-pre-prints" class="level4">
<h4 class="anchored" data-anchor-id="begutachtung-von-pre-prints">Begutachtung von Pre-Prints</h4>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Was ist ein Pre-Print?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Ein Pre-Print nennt man ein Manuskript <em>in dem</em> oder <em>vor dem</em> Stadium der Einreichung bei einer Zeitschrift. Es wurde möglicherweise noch nicht begutachtet oder nach Begutachtung abgelehnt, auf einer Internetseite veröffentlicht, ist zitierbar, und kostenlos zugängig. In manchen Fällen mag es sinnvoll sein, ein wissenschaftlichen Beitrag <em>nicht</em> der Begutachtung zu unterziehen (z.B. bei Kommentaren, Positions-Artikel, oder öffentlichem Austausch). Typischerweise zählen begutachtete Beiträge für die wissenschaftliche Karriere mehr. Der Zweck von Pre-Prints ist vielfältig: Sie erhöhen die Verfügbarkeit von Wissen, erlauben eine schnellere Veröffentlichung (Beweise in der Mathematik müssen aufwändig im Laufe von bis zu mehreren Jahren nachgeprüft werden), und verhindern, dass einem andere Forschende mit einer innovativen Idee zuvorkommen. In der Medizin und den Sozialwissenschaften wurden sie aufgrund des schnelleren Austausches im Zuge der Corona-Pandemie ausgiebig verwendet <span class="citation" data-cites="Fraser2020-fn">(<a href="#ref-Fraser2020-fn" role="doc-biblioref">Fraser et al. 2020</a>)</span>. In der Epidemilogie konnte nicht nachgewiesen werden, dass Pre-Prints qualitativ schlechter sind <span class="citation" data-cites="Nelson2022-yn">(<a href="#ref-Nelson2022-yn" role="doc-biblioref">Nelson et al. 2022</a>)</span>.</p>
</div>
</div>
<p>Über Plattformen und Gemeinschaften wie <em>PCI</em> oder <em>f1000research</em> oder zukünftig auch MetaROR (https://researchonresearch.org/project/metaror/) werden Pre-Prints begutachtet. Sie werden dann nicht bei einer Zeitschrift sondern bei dem der jeweiligen Einrichtung eingereicht und dort begutachtet. Das Modell nennt sich <em>publish-review-curate</em>, es werden also zuerst Pre-Prints hochgeladen, diese dann begutachtet, und schließlich zu Themenbereichen zusammengefasst. Die Qualitätssicherung wird dabei von Forschenden selbst organisiert und ist unabhängig von kommerziellen Verlagen. Dabei wird empfohlen, Studierende aktiv mit in den Prozess einzubeziehen <span class="citation" data-cites="holford2024engaging">(<a href="#ref-holford2024engaging" role="doc-biblioref">Holford et al. 2024</a>)</span>. Das Modell bei PCI ist, dass Artikel, die dort ein positives Gutachten erhalten haben, ohne weiteres Gutachten bei einer der teilnehmenden (<em>PCI-friendly</em>) Zeitschriften veröffentlicht werden können. Auf F1000research.com fungiert wie eine Zeitschrift, bei der Artikel direkt zugängig sind, sich über die Zeit durch Peer Review verändern. Auf ähnliche Weise gibt es bei der Zeitschrift für digitale Geisteswissenschaften eine Peer-Review-Ampel: Nach Einreichung sind Artikel dort direkt verfügbar und eine Ampel gibt an, ob sie unter Begutachtung sind, und falls sie begutachtet wurden, ob es (noch) schwerwiegende Probleme gibt oder nicht.</p>
</section>
<section id="gedächtnis-von-gutachten" class="level4">
<h4 class="anchored" data-anchor-id="gedächtnis-von-gutachten">Gedächtnis von Gutachten</h4>
<p>Eine weitere Möglichkeit, Gutachten fest an Forschungsartikel “dranzuheften”, besteht über Plattformen, die eine schnelle Kommentierung ermöglichen. Zum Beispiel lassen sich über Pubpeer.com oder hypothes.is alle wissenschaftlichen Beiträge (z.B. auch Daten) öffentlich und wenn gewünscht anonym kommentieren. Das ist für Pre-Prints möglich, sodass diese Kommentare dann dauerhaft damit verknüpft sind. Mittels Plug-Ins für Internetbrowser werden dann Artikel, zu denen es bei Pubpeer Diskussionen gibt, markiert. Weitere Plattformen sind alphaxiv.org, Disqus, oder scirev.org.</p>
</section>
<section id="aufmerksamkeit-zum-thema-in-bestehenden-zeitschriften" class="level4">
<h4 class="anchored" data-anchor-id="aufmerksamkeit-zum-thema-in-bestehenden-zeitschriften">Aufmerksamkeit zum Thema in bestehenden Zeitschriften</h4>
<p>Anforderungen an wissenschaftliche Artikel seitens der Zeitschriften sind 2010 maßgeblichen Änderungen untergangen. In den Sozialwissenschaften orientieren sich zahlreiche Zeitschriften an den Richtlinien zur „Transparency and Openness Promotion” (TOP) und erhalten entsprechende TOP-Faktoren (<a href="https://topfactor.org/summary" class="uri">https://topfactor.org/summary</a>). Dabei wird festgehalten, welcher Grad an Offenheit und Transparenz von Forschungsdaten und -materialien gefordert wird und ob Replikationen bei der jeweiligen Zeitschrift veröffentlicht werden. Neue Herausgeber*innen bei existierenden Zeitschriften haben große Änderungen vorgenommen. Beispielsweise haben <span class="citation" data-cites="Hardwicke2023-fo">Hardwicke and Vazire (<a href="#ref-Hardwicke2023-fo" role="doc-biblioref">2023</a>)</span> für die Zeitschrift <em>Psychological Science</em> ein standardmäßiges Nachrechnen aller berichteten Ergebnisse ab 2024 angekündigt, indem sie mit dem Institute for Replication zusammenarbeiten (<a href="https://i4replication.org" class="uri">https://i4replication.org</a>). Vereinzelt haben Zeitschriften Spezialausgaben herausgegeben, bei denen der Fokus auf Replikationsstudien oder der Reproduzierbarkeit von Ergebnissen lag <span class="citation" data-cites="Carriquiry2023-en">(<a href="#ref-Carriquiry2023-en" role="doc-biblioref">Carriquiry, Daniels, and Reid 2023</a>)</span>.</p>
</section>
<section id="zeitschriften-für-nicht-innovatives" class="level4">
<h4 class="anchored" data-anchor-id="zeitschriften-für-nicht-innovatives">Zeitschriften für “nicht Innovatives”</h4>
<p>Durch die Selektion spannender Ergebnisse gibt es für Forschung, die nicht bahnbrechend und dennoch höchst relevant ist, keine Plattform. Schätzungen zufolge werden bis zu 40% aller durchgeführten Studien innerhalb von 4 Jahren nach Durchführung nicht veröffentlicht <span class="citation" data-cites="Ensinck2023-hf">(<a href="#ref-Ensinck2023-hf" role="doc-biblioref">Ensinck and Lakens 2023</a>)</span>. Andere Forschende können nicht davon lernen und Ressourcen, die in die Sammlung und Auswertung der Daten geflossen sind, Zeit von Versuchspersonen, und lange Vorbereitungen der Forschung werden schließlich verschwendet. Zur Lösung dieses Problems haben sich neue Zeitschriften und Formate gebildet. In der Ökonomie hat sich auf Forderungen <span class="citation" data-cites="Zimmermann2015-jw">(<a href="#ref-Zimmermann2015-jw" role="doc-biblioref">Zimmermann 2015</a>)</span> hin beispielsweise eine <a href="jcr-econ.org">Zeitschrift</a> für Replikationen und Kommentare gebildet. Die Zeitschrift Meta-Psychology bietet ein Format für Replikationen und eines für „Schubladenberichte” an. Letzteres ist für Studien vorgesehen, die wegen wenig überraschenden Ergebnissen oder Fehlern in der Durchführung anderweitig in der Schublade landen würden aber dennoch wichtige Informationen beinhalten. Ebenfalls zur Abbildung des für den Forschungsprozess typischen Fehlschlagens wurde das <a href="https://journal.trialanderror.org">Journal of Trial and Error</a> gegründet, und bei <a href="https://rescience.github.io/board/">ReScience C</a> und <a href="rescience.org/x">Rescience X</a> können Berichte über Reproduzierbarkeit und Replikationen veröffentlicht werden.</p>
</section>
<section id="publikationsmodelle" class="level4">
<h4 class="anchored" data-anchor-id="publikationsmodelle">Publikationsmodelle</h4>
<p>Noch radikalere Vorschläge als die Anpassung bisheriger Zeitschriften ist der Vorschlag, das bisherige System durch ein neues zu ersetzen. Dabei handelt es sich um ein soziales Dilemma, bei dem Millionen von Forschenden sich plötzlich anders verhalten müssen und dabei entgegen der Spielregeln des wissenschaftlichen Systems handeln müssen <span class="citation" data-cites="Brembs.2023">(<a href="#ref-Brembs.2023" role="doc-biblioref">Brembs et al. 2023</a>)</span>. Das Dilemma wurde von kommerziellen Verlagen gestaltet, welche daraus Geld verdienen. <span class="citation" data-cites="Brembs.2023">Brembs et al. (<a href="#ref-Brembs.2023" role="doc-biblioref">2023</a>)</span> haben einen präzisen Vorschlag erarbeitet, bei welchem ein dezentrales System aufgebaut wird, das soziale Netzwerke wie Mastodon als Vorbild hat, von Wissenschaftler*innen organisiert wird, und Forschungsprodukte wie Daten oder Programme ebenso wie die traditionellen Forschungsberichte wertschätzt. Plattformen, die ein solches Mikro-Publishing-System bereits implementieren sind <a href="https://www.researchequals.com/">Research-Equals</a> oder Octopus.ac <span class="citation" data-cites="Hsing">(<a href="#ref-Hsing" role="doc-biblioref"><strong>Hsing?</strong></a>)</span>. Dem System, bei dem alle Produkte begutachtet werden, der Begutachtungsprozess aber nicht die Qualität sicherstellt, stehen hier Ampel-Systeme und öffentliche Kommentierung entgegen, die signalisieren, was und ob begutachtet wurde, welche Kritikpunkte vorlagen, und wie damit umgegangen wurde.</p>
</section>
</section>
<section id="forschende" class="level3">
<h3 class="anchored" data-anchor-id="forschende">Forschende</h3>
<p>Unabhängig von Nationalität, Wissenschaftsgebiet, und Universität haben viele Forschende ihre Arbeitsweisen im Zuge von Open Science überdacht und angepasst. <a href="http://www.researchtransparency.org">Hunderte</a> haben öffentliche Erklärungen zur Forschungstransparenz und der Forderung von Open Science Praktiken in der Rolle von <a href="https://www.opennessinitiative.org">Gutachter*innen</a> unterzeichnet. Einzelne Forschende führen im Rahmen von Lehre Replikationsstudien durch <span class="citation" data-cites="Boyce.2023 Jekel.2020 Korell.2023">(<a href="#ref-Boyce.2023" role="doc-biblioref">Boyce, Mathur, and Frank 2023</a>; <a href="#ref-Jekel.2020" role="doc-biblioref">Jekel et al. 2020</a>; <a href="#ref-Korell.2023" role="doc-biblioref">Korell, Reinecke, and Lott 2023a</a>)</span>, schließen sich weltweit zusammen um gemeinsam Projekte durchzuführen, die einzelne nicht stemmen könnten (z.B. Psychological Science Accelerator, <a href="https://psysciacc.org" class="uri">https://psysciacc.org</a>), und entwickeln <a href="https://docs.google.com/spreadsheets/d/1KUMSeq_Pzp4KveZ7pb5rddcssk1XBTiLHniD0d3nDqo/edit#gid=0">Informations-Sammlungen</a> (Open Scholarship Knowledge Base, https://oercommons.org/hubs/OSKB), <a href="https://osf.io/jfh3t/">Leitfäden</a> und Glossare <span class="citation" data-cites="Parsons.2022">(<a href="#ref-Parsons.2022" role="doc-biblioref">Parsons et al. 2022</a>)</span>, um den Zugang zu Open Science zu erleichtern. Eine noch unerfüllte Forderung ist die, Forschende das System über Zusammenschlüsse im Rahmen von Gewerkschaften zu reformieren <span class="citation" data-cites="rahal2023quality">(<a href="#ref-rahal2023quality" role="doc-biblioref">Rahal et al. 2023</a>)</span>.</p>
</section>
<section id="bewertungskriterien" class="level3">
<h3 class="anchored" data-anchor-id="bewertungskriterien">Bewertungskriterien</h3>
<p>Mit der San Francisco Erklärung zur Forschungsbewertung (Declaration on Research Assessment, <a href="https://sfdora.org/read/read-the-declaration-deutsch/">SF DORA</a>) begannen 2012 viele Institutionen und Forschende, sich öffentlich und klar dagegen zu positionieren, Forschung ausschließlich auf Basis von Zitationsmetriken (z.B. Impact Factor) zu bewerten. Im Jahr 2024 gab es bereits über 25.000 Signaturen aus 165 Ländern. Die Erklärung besteht aus einer allgemeinen und anschließend spezifischen Empfehlungen (für Föderorganisationen, Instutionen, Verlage, …). Die allgemeine Empfehlung lautet. “Verwenden Sie keine Kennzahlen auf der Ebene von Fachzeitschriften, wie den Journal Impact Factor, als Ersatz, um die Qualität einzelner Fachartikel zu bewerten, um die Beiträge einzelner Wissenschaftler zu bewerten, oder um Entscheidungen über Einstellung, Beförderung oder Finanzierung zu treffen.” (https://sfdora.org/read/read-the-declaration-deutsch/).</p>
<p>In der Psychologie werden Bewertungskriterien für Forschende systematisch und mit Methoden der Persönlichkeitspsychologie und Diagnostik entwickelt <span class="citation" data-cites="Schönbrodt_Gärtner_Frank_Gollwitzer_Ihle_Mischkowski_Phan_Schmitt_Scheel_Schubert_Steinberg_Leising_2022 Gartner2022-uh">(<a href="#ref-Schönbrodt_Gärtner_Frank_Gollwitzer_Ihle_Mischkowski_Phan_Schmitt_Scheel_Schubert_Steinberg_Leising_2022" role="doc-biblioref">Schönbrodt, Gärtner, Frank, Gollwitzer, Ihle, Mischkowski, Phan, Schmitt, Scheel, Schubert, Steinberg, et al. 2022</a>; <a href="#ref-Gartner2022-uh" role="doc-biblioref">Gärtner, Leising, and Schönbrodt 2022b</a>)</span>. Ein Problem ist dabei, dass sich Forschende in Gruppen die Arbeit aufteilen und manche Personen davon eher profitieren als andere (z.B. weil sie sich auf Methoden spezialisieren und in der Autor*innenliste seltener an erster Stelle stehen). Analog tritt das Problem im Fußball auf: Würde man Spieler und Spielerinnen nur nach geschossenen Toren bewerten, wären Leute in der Abwehr und im Mittelfeld und sogar diejenigen, die für die Vorlage verantwortlich sind, benachteiligt. <span class="citation" data-cites="Tiokhin2023-ne">Tiokhin et al. (<a href="#ref-Tiokhin2023-ne" role="doc-biblioref">2023</a>)</span> schlagen vor diesem Hintergrund eine schrittweise Bewertung vor: Zuerst sollten die Gruppen, in denen Forschende arbeiten, bewertet werden, und anschließend die einzelnen Mitglieder.</p>
<p>Auch bei der Bewertung von einzelnen Forschungsartikeln, also vor allem im Peer Review, werden Bewertungskriterien weiterentwickelt. <span class="citation" data-cites="Elsherif2023-by">Elsherif, Feldman, and Yeung (<a href="#ref-Elsherif2023-by" role="doc-biblioref">2023</a>)</span> haben eine Vorlage zur Begutachtung quantiativer, psychologischer Studien und Replikationen entwickelt. Im Rahmen der “Peer Reviewer Openness Initiative” (PRO, https://www.opennessinitiative.org) haben sich Forschende öffentlich dazu positioniert, Forschungsartikel nur dann positiv zu beurteilen, wenn sie Zugang zu allen nötigen Materialien und Daten haben (außer, es gibt gute ethische Gründe, weshalb das nicht möglich ist).</p>
<p>Ein grundlegendes Problem bei der Entwicklung von Bewertungskriterien ist, dass sie oft Dinge jenseits der Normalfälle benachteiligen <span class="citation" data-cites="Hostler2024-to">(<a href="#ref-Hostler2024-to" role="doc-biblioref">Hostler 2024</a>)</span>. Mittels Kriterien wird ein gleichförmiger Maßstab über viele verschiedene Forschenden und Forschungsdisziplinen gehalten. Wirtschaftswissenschaftler*innen, die nach dem Impact Factor bewertet werden, veröffentlichen gerne Artikel in Zeitschriften, die sich mit anderen Disziplinen überschneiden, weil dort die Zitationszahlen höher sind. Werden methodische Kriterien zur Bewertung herangezogen (z.B. ob eine zentrale Studie präregistriert ist), werden diejenigen benachteiligt, die qualitativ forschen und für die eine klassische Präregistrierung gar nicht hilfreich ist.</p>
<section id="alternativen-zum-impact-factor" class="level4">
<h4 class="anchored" data-anchor-id="alternativen-zum-impact-factor">Alternativen zum Impact Factor</h4>
<p>Während die San Francisco Erklärung “DORA” klar den Journal Impact Factor verurteilt, lässt sie offen, welche Alternativen gewählt werden sollten. Aufbauend empfiehlt die Coalition for Advancing Research Assessment (<a href="https://coara.eu/">coara.eu</a>) die Verwendung qualitativer Merkmale. <span class="citation" data-cites="Nosek2015-at">Nosek et al. (<a href="#ref-Nosek2015-at" role="doc-biblioref">2015</a>)</span> entwickelten die Transparency and Openness Promotion Guidelines (TOP Guidelines), die Zeitschriften auf Basis von zehn Kriterien bewerten und nach denen sich Zeitschriften einordnen lassen (<a href="topfactor.org">topfactor.org</a>).</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TOP Faktor versus Hirsch Index
</div>
</div>
<div class="callout-body-container callout-body">
<p>Um den TOP Faktor für eine Zeitschrift zu berechnen, muss zuerst für alle Facetten notiert werden, wie offen und transparent eine Zeitschrift ist. Beispielsweise muss bezüglich der Transparenz von Materialien geprüft werden, ob in den Richtlinien der Zeitschrift überhaupt etwas steht (0 Punkte), ob in Zeitschriften bloß notiert werden muss, ob Materialien verfügbar sind (1 Punkt), ob Materialien in einer Datenbank hochgeladen werden müssen (2 Punkte), oder ob darüber hinaus eine Person die Analysen reproduzieren (also nachrechnen) wird (3 Punkte). Die Punkte über alle Facetten werden aufsummiert - es ist also streng genommen eine TOP “Summe” und kein Faktor (so wie der Impact Factor eigentlich ein Quotient ist). Psychometrisch ist dabei bedenklich, dass die Summe der verschiedenen Facetten gebildet wird, so als würden 3 Punkte bei einer Facette einen fehlenden Punkt bei einer anderen Facette problemlos ersetzen können.</p>
<p>Der Hirsch Index (oder h-index) gibt an, dass von allen Publikationen mindestens so viele davon so oft zitiert wurden. Ein Index von 4 hieße, dass mindestens 4 Artikel mindestens 4 mal zitiert wurden.</p>
<p>H Indizes und TOP Faktoren sind für viele Zeitschriften öffentlich einsehbar. Die Daten lassen sich leicht herunterladen und miteinander in Zusammenhang setzen (Materialien dafür sind online verfügbar: https://osf.io/utzfs/). Die meisten Zeitschriften haben einen sehr kleinen H Index, weshalb die Daten für bessere Lesbarkeit logarithmiert wurden. Während für Zeitschriften in Nordamerika ein leichter Zusammenhang zwischen H Index und TOP Faktor sichtbar ist, liegt für westeuropäische Zeitschriften kein Zusammenhang vor. Offenheit und Transparenz als objektive Gütekriterien für Wissenschaft haben also nachweislich nichts oder nur wenig mit Zitationszahlen zu tun.</p>
<p><img src="images/tophindex.png" class="img-fluid"></p>
</div>
</div>
<p>Um aus Zitationszahlen Qualität schließen zu können, wurde von <span class="citation" data-cites="Peroni2012-ko">Peroni and Shotton (<a href="#ref-Peroni2012-ko" role="doc-biblioref">2012</a>)</span> ein System entwickelt, wie festgelegt werden kann, um was für eine Art Zitation es sich handelt (Citation Typing Ontology, <a href="https://sparontologies.github.io/cito/current/cito.html">CiTO</a>) und das bereits von Zeitschriften implementiert wurde <span class="citation" data-cites="Willighagen2023-gp">(<a href="#ref-Willighagen2023-gp" role="doc-biblioref">Willighagen 2023</a>)</span>. Inwiefern es die Bewertung von Forschung verbessert, bleibt abzuwarten. Nicht ganz ernstgemeint wurde für die Medizin außerdem der Free Lunch Index vorgeschlagen, der die Summe der Geschenke aus der Industrie abbildet <span class="citation" data-cites="Scanff2023-sz">(<a href="#ref-Scanff2023-sz" role="doc-biblioref">Scanff et al. 2023</a>)</span>.</p>
</section>
</section>
<section id="infrastruktur-open-infrastructure" class="level3">
<h3 class="anchored" data-anchor-id="infrastruktur-open-infrastructure">Infrastruktur (Open Infrastructure)</h3>
<p>In der Pyramide zum Kulturwandel bildet Infrastruktur das Fundament. Sie ermöglicht, dass verschiedene Open Science Praktiken umgesetzt werden können. Beispielsweise lassen sich Forschungsdaten nicht einfach veröffentlichen, wenn es dafür keinen Ort oder keine Internetseite gibt. Diesbezüglich gab es massive Fortschritte und Forschungsmaterialien, Daten, oder Publikationen zu teilen war nie einfacher. Mittels der Richtlinien für Infrastruktur in der Forschung <span class="citation" data-cites="Bilder2020-pm">(<a href="#ref-Bilder2020-pm" role="doc-biblioref">Bilder, Lin, and Neylon 2020</a>)</span> ist festgelegt, wie Infrastruktur im Idealfall aufgebaut sein sollte: Beispielsweise sollte sie nachhaltig gestaltet und langfristig finanziert sein und über Disziplinen, Institutionen, und Orte hinaus verwendet werden. In Deutschland setzt sich zudem der Verein “Nationale Forschingsdaten Infrastruktur (NFDI) dafür ein, dass Daten als gemeinsames Gut organisiert werden. In fachspezifischen Konsortien werden Strukturen geschaffen, mittels derer sich Forschungsdaten teilen lassen. Eine <a href="https://access2perspectives.org/mapping-open-science-resources/">interaktive Karte offener Infrastruktur</a> ist online verfügbar (https://kumu.io/access2perspectives/open-science#disciplines/by-os-principle/open-infrastructure).</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Die Kosten eines “Offenen Buches”
</div>
</div>
<div class="callout-body-container callout-body">
<p>Dieses Buch wurde vollständig mittels kostenloser Software verfasst (GNU R, RStudio, Quarto) und wird kostenlos bei Github gehostet. Ein weitere Schritt wäre die ausschließliche Verwendung von Open Source Software, also von Programemn, deren Code öffentlich gemacht wurde und welcher für eigene Zwecke verwendet werden kann. Aktuell ist die Verfügbarkeit dieses Buches davon abhängig, dass Github kostenlos bleibt.</p>
</div>
</div>
<table class="caption-top table">
<caption>Beispiele für Open Science Infrastrukturen</caption>
<colgroup>
<col style="width: 24%">
<col style="width: 34%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Service</th>
<th>Zweck</th>
<th>Anbieter</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Literaturdatenbank</td>
<td>Verwalten und Durchsuchen von Literatur</td>
<td>OpenAlex</td>
</tr>
<tr class="even">
<td>Datenrepositorium</td>
<td>Veröffentlichung von Forschungsdaten</td>
<td>re3data.org, osf.io, researchbox.org, zenodo.org</td>
</tr>
<tr class="odd">
<td>Pre-Print Server</td>
<td>Veröffentlichung von Forschungsartikeln</td>
<td>arXiv.org</td>
</tr>
<tr class="even">
<td>Zeitschriftensystem (Editorial Manager)</td>
<td>Verwaltung von wissenschaftlichen Fachzeitschriften (Einreichung, Begutachtung, Publikation, Indizierung)</td>
<td>Open Journal System</td>
</tr>
<tr class="odd">
<td>Post-Publication Peer Review</td>
<td>Begutachtung und Kommentierung von Forschung nach Veröffentlichung</td>
<td>Pubpeer.com</td>
</tr>
<tr class="even">
<td>Identifizierung von Forschenden, Institutionen, und Forschung</td>
<td></td>
<td>Open Researcher and Contributor ID (ORCID.org), Research Organization Registry (ROR.org), Digital Object Identifier (DOI.org)</td>
</tr>
</tbody>
</table>
</section>
<section id="sec-openaccess" class="level3">
<h3 class="anchored" data-anchor-id="sec-openaccess">Open Access Publikationen</h3>
<p>Um den Zugang zu wissenschaftlichem Wissen zu erhöhen, wird mehr und mehr Forschung als “Open Access” (offener Zugang) veröffentlicht. Spezifisch kann das auf vielen verschiedenen Wegen geschehen: Personen können Artikel in nicht-kommerziellen Zeitschriften veröffentlichen (für eine Sammlung an über 20.000 Zeitschriften siehe z.B. https://doaj.org), manche kommerzielle Zeitschriften machen Artikel nach Ablauf einer bestimmten Zeit frei verfügbar, oder sie können Geld bezahlen, damit der Artikel öffentlich zugänglich in einer traditionellen Fachzeitschrift erscheint. Dabei können sich die Kosten auf Werte zwischen ein paar hunderten Euro bis zu 9.000€ bei “angesehenen Zeitschriften” belaufen. Die Gelder dafür stammen meistens aus den Mitteln von Universitäten (z.B. Open Access Funds) oder aus Projektmitteln, das heißt, dass bei der Beantragung von Geldern für das Projekt auch Gelder mit beantragt wurden, um die Kosten für Open Access Publikationen zu bezahlen. Während Open Access ursprünglich explizit nicht dieses Bezahlmodell meint, haben es Zeitschriften inzwischen “rekommerzialisiert”, sich also zu Nutzen gemacht. In der Open-Access-Strategie der Hochschulen des Landes Nordrhein-Westfalen <span class="citation" data-cites="Openness2023-yk">(<a href="#ref-Openness2023-yk" role="doc-biblioref">Openness 2023b</a>)</span> werden die Typen übersichtlich aufgelistet. Neben Open Access bei der Erstveröffentlichung haben Forschende im Sinne von “Green Open Access” üblicherweise das Recht, die von ihnen verfassten Artikeln auf ihrer eigenen Website, denen ihrer Institution, oder auf fachlichen Repositorien hochzuladen. <span class="citation" data-cites="Zumstein2023-kn">Zumstein (<a href="#ref-Zumstein2023-kn" role="doc-biblioref">2023</a>)</span> empfiehlt beispielsweise, bei Zeitschriften mit Abo-Modell (“Subskriptionsmodell”) nicht die Open Access Option dazuzukaufen, da es nicht nachhaltig ist und stattdessen die Zweitveröffentlichung offen zu machen.</p>
<table class="caption-top table">
<caption>Typen von Open Access bei der Erstveröffentlichung</caption>
<colgroup>
<col style="width: 20%">
<col style="width: 79%">
</colgroup>
<thead>
<tr class="header">
<th>Typ</th>
<th>Regelung</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Gold / Diamond</td>
<td>Alle Publikationen sind sofort und kostenlos verfügbar</td>
</tr>
<tr class="even">
<td>Hybrid</td>
<td>Die Zeitschrift hat ein Abo-Modell. Einzelne Artikel werden gegen eine Gebühr öffentlich gemacht.</td>
</tr>
<tr class="odd">
<td>Moving Wall</td>
<td>Die Zeitschrift hat ein Abo-Modell. Nach Ablauf einer Frist (6-48 Monate) sind Artikel frei zugänglich.</td>
</tr>
<tr class="even">
<td>Promotional</td>
<td>Zur Bewerbung der Zeitschrift sind einzelne Artikel frei verfügbar.</td>
</tr>
</tbody>
</table>
<p>Typen von Open Access (siehe zenodo NRW AG Open Science Auflistung)</p>
<div class="callout callout-style-simple callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Wie Prestige für Offenheit blind machen kann
</div>
</div>
<div class="callout-body-container callout-body">
<p>An manchen Orten gibt es ungeschriebene Gesetze wie “wenn du während deiner Promotion in einer hochrangigen Zeitschrift publizierst, wirst du die Bestnote kriegen”. Damit wird den prestigereichen Zeitschriften immer mehr Macht zugeschoben. Leuten wird außerordentlich dafür gratuliert, dass sie etwas in Psychological Bulletin oder sogar Nature Human Behavior veröffentlicht haben. Dass niemand, der nicht mit einer Universität affiliiert ist (also an einer arbeitet oder studiert), den Artikel im Psychological Bulletin lesen kann, oder dass für die Veröffentlichung in Nature bis zu 9.000 Euro (meistens aus Steuergeldern) bezahlt wurden, spielt dabei keine Rolle.</p>
</div>
</div>
<p>Neben kommerziellen und Open Access Zeitschriften existiert noch ein weiterer Akteur bei der Zugänglichkeit von wissenschaftlichem Wissen: Mittels <em>Schattenbibliotheken</em> wie Sci-Hub können Personen auf Artikel, die sonst hinter einer Bezahlschranke liegen, zugreifen (“Guerilla Open Access”). Sci-Hub (<a href="https://de.wikipedia.org/wiki/Sci-Hub" class="uri">https://de.wikipedia.org/wiki/Sci-Hub</a>) als bekannteste Schattenbibliothek beinhaltet fast 70% aller 81.6 Millionen wissenschaftlichen Artikeln bis zum Jahr 2018 <span class="citation" data-cites="Himmelstein2018-ys">(<a href="#ref-Himmelstein2018-ys" role="doc-biblioref">Himmelstein et al. 2018</a>)</span>. Nutzungsstatistiken aus Deutschland hat <span class="citation" data-cites="strecker2019nutzung">Strecker (<a href="#ref-strecker2019nutzung" role="doc-biblioref">2019</a>)</span> analysiert. Die Verbreitung und das Herunterladen sind rechtlich umstritten. Andere Möglichkeiten, kostenlos an Forschungsartikel zu kommen sind 12ft.io, der Hashtag #canihazpaper in sozialen Netzwerken, oder das persönliche Anschreiben von Autor*innen per Mail oder über soziale Netzwerke für Forschende (Researchgate.net, Academia.edu).</p>
<section id="wahl-der-fachzeitschrift" class="level4">
<h4 class="anchored" data-anchor-id="wahl-der-fachzeitschrift">Wahl der Fachzeitschrift</h4>
<p>Abgesehen von Prestige oder Journal Impact Factors können Forschende bei der Wahl der Zeitschrift, in der sie ihre Forschung veröffentlichen möchten, auf Gold Open Access achten (z.B. via <a href="https://doaj.org" class="uri">https://doaj.org</a> oder <a href="https://freejournals.org/current-member-journals/" class="uri">https://freejournals.org/current-member-journals/</a>) und den TOP Faktor berücksichtigen (topfactor.org). Zudem sollten sie bei ihren Bibliotheken nachhaken: Bei Zeitschriften mit Abo-Modell (hybrid Open Access) hat sich nämlich ein Markt für bezahlte Open Access Publikationen entwickelt. Zeitschriften und Verlage veröffentlichen dabei extrem viele Artikel ohne strenge Begutachtung und verdienen Geld durch die Open Access Gebühren. In dem Fall sind die Zeitschriften als “Open Access Zeitschriften” vermarktet und die Kosten heißen “Author Processing Charges (APCs)”. Mittels des von der Universität Bielefeld betriebenen Dashboards wird aufgeschlüsselt, welche Zeitschriften und welche Verlage wie viel Geld von deutschen Universitäten bekommen haben (https://treemaps.openapc.net/apcdata/openapc/#publisher/). Der Verlag MDPI, mit über 2000 Artikeln auf Platz 1 bei der Artikelanzahl und mit Einnahmen von über 4 Millionen Euro auf Platz 2 hinsichtlich Profit, ist dabei besonders umstritten: Forschende (https://predatoryjournals.org/news/f/is-mdpi-a-predatory-publisher) konnten Nachweisen, dass die Bearbeitungszeiten (Dauer der Begutachtung, Revision, Veröffentlichung) unrealistisch gleichförmig sind und es pro Tag mehrere Spezialausgaben gibt (für gewöhnlich hat eine Zeitschrift 1-2 Spezialausgaben pro Jahr). Beall hat auf seiner Website (https://beallslist.net) eine umstrittene Liste veröffentlicht, die Zeitschriften als unwissenschaftlich kennzeichnet und beschreibt seine Erfahrungen in einem Artikel <span class="citation" data-cites="Beall2017-hw">(<a href="#ref-Beall2017-hw" role="doc-biblioref">Beall 2017</a>)</span>. Ebenfalls helfen Tools zur Identifikation unseriöser Zeitschriften und Konferenzen (<a href="#0" class="uri">https://thinkchecksubmit.org</a>, <a href="#0" class="uri">https://thinkcheckattend.org</a>).</p>
</section>
<section id="monitoring" class="level4">
<h4 class="anchored" data-anchor-id="monitoring">Monitoring</h4>
<p>Wie viel Forschung als Open Access veröffentlicht wird oder wie viel das Kostet, lässt sich mithilfe verschiedener Werkzeuge beobachten. <em>OpenAPCs</em> listet Open Access Kosten je nach Verlag, Zeitschrift, und Universität auf (https://treemaps.openapc.net/apcdata/openapc/) und der Open Access Monitor schlüsselt auf, wie viele Publikationen in Deutschland unter welchen Open Access Modellen veröffentlicht werden (<a href="https://open-access-monitor.de" class="uri">https://open-access-monitor.de</a>).</p>
<p>Aktuell (Stand Sommer 2024) haben 54,4% aller indizierten Fachzeitschriften kein offenes Modell und der Großteil aller Forschung wird darüber veröffentlicht. 19,2% der Fachzeitschriften laufen außerdem unter einem Transformationsvertrag. Dabei soll ein Übergang vom Abo-Modell zu einem Open Access Modell geschafft werden und alle bisher veröffentlichten Artikel sollen ebenfalls öffentlich zugänglich gemacht werden. Die wohl größte Rolle spielt dabei das DEAL Konsortium (<a href="https://deal-konsortium.de/publizierende" class="uri">https://deal-konsortium.de/publizierende</a>): Dabei haben sich deutsche Wissenschaftsorganisationen zusammengeschlossen, um mit Verlagen einen bundesweiten Vertrag auszuhandeln, das allen deutschen Forschenden ermöglicht, Open Access ohne zusätzliche Kosten zu publizieren.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Offene Lehrbücher
</div>
</div>
<div class="callout-body-container callout-body">
<p>Während Artikel in Fachzeitschriften primär für den Austausch unter Forschenden genutzt werden, spielen Lehrbücher die besondere Rolle, dass sie die Kommunikation zwischen Expert*innen und Interessierten (z.B. Studierenden) bilden. Das Verhältnis zwischen Lehrbuch-Autor*innen und Verlagen ist weniger angespannt als das zwischen Forschenden und Zeitschriften - auch, wenn es größtenteils dieselben Verlage sind. Zwei besondere Unterschiede könnten die Ursache dafür sein: 1. Verfasser*innen von Lehrbüchern verdienen von Verkäufen und 2. können sie ihre eigenen Werke für Prüfungen relevant erklären. In der Folge müssen Studierende die Kosten tragen und nicht sie selbst. Im Vereinigten Königreich existieren bereits Pilotprojekte, die das Ziel haben, die Lehre möglichst vollständig auf offene Lehrbücher umzustellen <span class="citation" data-cites="Farrow2020-jc">(<a href="#ref-Farrow2020-jc" role="doc-biblioref">Farrow, Pitt, and Weller 2020</a>)</span>.</p>
</div>
</div>
</section>
<section id="massenrücktritte-von-herausgeberinnen" class="level4">
<h4 class="anchored" data-anchor-id="massenrücktritte-von-herausgeberinnen">Massenrücktritte von Herausgeber*innen</h4>
<p>Immer häufiger kommt es vor, dass die Herausgeberschaft einer Zeitschrift zurücktritt. Grund dafür, dass Verlage die Publikationskosten oder die Anzahl veröffentlichter Artikel erhöhen möchte. Eine Liste solcher Rücktritte verwaltet Retractionwatch.org (“Editorial Mass Resignations”, https://retractionwatch.com/the-retraction-watch-mass-resignations-list/). Dabei hat eine Community aus Forschenden jahrelang hart gearbeitet, um die Zeitschrift zu verwalten und bekannt zu machen und wird dann damit bestraft, dass sie noch mehr Geld dafür zahlen muss, ihre Forschung miteinander auszutauschen.</p>
<p>In vielen solcher Fälle gründen die Forschenden im Anschluss an ihren Rücktritt eine neue, üblicherweise Open Access Zeitschrift. Während Universitätsbibliotheken Gründungen neuer Zeitschriften unterstützen und der Prozess technisch unproblematisch ist, gibt es legale und soziale Hürden: Verlage wie Taylor &amp; Francis vereinbaren mit den Forschenden häufig “Non-comepete Klauseln”, verbieten ihnen also, im Anschluss an ihre Herausgebertätigkeit innerhalb eines oder mehrerer Jahre bei einer anderen Zeitschrift zu arbeiten. Eine wissenschaftliche Community, die der <a href="https://blogs.lse.ac.uk/impactofsocialsciences/2019/03/29/the-value-of-a-journal-is-the-community-it-creates-not-the-papers-it-publishes/">Kern</a> einer Zeitschrift ist, muss außerdem einstimmig hinter der Veränderung stehen. In einem Fall hat die Herausgeberschaft klar kommuniziert, dass es sozial völlig inakzeptabel ist, die alte Zeitschrift zu unterstützen. Neu gegründete Zeitschriften haben außerdem noch keinen Impact Factor, weil noch keine zitierfähigen Artikel erschienen sind und Artikel noch nicht zitiert werden konnten. Verlage arbeiten gegen Massenrücktritte, indem sie die Zugehörigen der Herausgeberschaft häufig rotieren, sodass sie sich schlechter absprechen können. Treffen in Person sind durch die Internationalität der Forschung ebenfalls erschwert.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Offenheit durch Klemmbausteine
</div>
</div>
<div class="callout-body-container callout-body">
<p>Offenheit der Wissenschaft kann viele Gesichter haben: Eine besondere Form des öffentlichen Zugangs verbreitet sich aktuell in der biotechnologischen Forschung aus. Damit Wissenschaftler*innen, Ingenieur*innen, aber auch die allgemeine Bevölkerung Zugang zu Konstruktionen hat, wird dort zu Klemmbausteinen wie beispielsweise solchen von dem Unternehmen LEGO® gegriffen <span class="citation" data-cites="Boulter2022-xu">(<a href="#ref-Boulter2022-xu" role="doc-biblioref">Boulter et al. 2022</a>)</span>. Das Patent für “den Lego-Stein” ist bereits ausgelaufen, sodass verschiedene Unternehmen oder Personen mit 3D-Drucker eigene Klemmbausteine herstellen können. Die Dateien für 3D-Drucker sind im Internet frei verfügbar. So konnte der Forscher David Aguilar beispielsweise einen prosthetischen Arm mit Klemmbausteinen entwerfen.</p>
</div>
</div>
</section>
</section>
<section id="pre-prints" class="level3">
<h3 class="anchored" data-anchor-id="pre-prints">Pre-Prints</h3>
<p>Wie bereits im Kapitel zur Begutachtung von Pre-Prints erläutert, sind Pre-Prints immer öffentlich und kostenlos verfügbar. Forschende können verschiedene Lizenzen vergeben, die beispielsweise eine kommerzielle Verwendung verbietet, sind dabei jedoch fast immer sehr liberal. Neben den bereits diskutierten Vorteilen von Pre-Prints, sind Änderungen bei ihnen um ein vielfaches schneller: Forschende können jederzeit auf Kritik reagieren und Fehler korrigieren. In einem <a href="https://www.statnews.com/2020/02/03/retraction-faulty-coronavirus-paper-good-moment-for-science/">Artikel zum Coronavirus</a> fiel ein Fehler kurz nach der Veröffentlichung auf und wurde innerhalb von zwei Tagen korrigiert. Bei einem Zeitschriftenartikel kann sich dieser Prozess über viele Jahre ziehen. Gerade bei ernsthaften Problemen, die eine Retraction zur Folge haben, sind Verlage vergleichsweise langsam. Einen Pre-Print können Autor*innen jederzeit vom Netz nehmen - wobei er über Suchmaschinen dabei sicherlich noch auffindbar bleibt.</p>
<p>Pre-Prints können außerdem dazu beitragen, dass Ressourcen effizienter benutzt werden: Durch die <a href="https://asapbio.org/what-do-researchers-think-about-scholarly-publishing-five-key-takeaways-from-a-new-survey-by-coalition-s">beschleunigte Kommunikation</a> zwischen Forschenden fällt schneller auf, wenn verschiedene Gruppen an derselben Fragestellung arbeiten. So können sich Kooperationen bilden oder Gruppen verlagern ihre Schwerpunkte.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Unberechtigte Sorge vor Ideenklau
</div>
</div>
<div class="callout-body-container callout-body">
<p>In manchen wissenschaftlichen Disziplinen sind Forschende Pre-Prints gegenüber zögerlich. Sie haben Angst, dass jemand ihre Idee klaut und schneller als sie einen Artikel bei einer Fachzeitschrift dazu veröffentlicht. Während diese Angst beim klassischen System z.B. durch böswillige Gutachtende oder Zuhörer*innen bei einer Konferenz ebenfalls besteht und selbst bei veröffentlichten Fachzeitschriftenartikeln passiert, ist der Vorteil von Pre-Prints, dass sie mit einem Datum versehen sind und für alle klar nachvollziehbar ist, wann was veröffentlicht wurde.</p>
</div>
</div>
</section>
<section id="ansätze-gegen-die-selektion-spannender-ergebnisse" class="level3">
<h3 class="anchored" data-anchor-id="ansätze-gegen-die-selektion-spannender-ergebnisse">Ansätze gegen die Selektion spannender Ergebnisse</h3>
<p>Die Ergebnisse einer Untersuchung sind das, was am wenigsten in der Hand der forschenden Person liegt (bzw. liegen sollte - immerhin interessiert uns ja die Wahrheit und nicht die Kompetenz Forschender, Daten möglichst stark zu schönen). Umso frustrierender ist es, dass Zeitschriften das Ergebnis als Kriterium zur Publikation verwenden. Unter der Vielzahl von Einreichungen werden vor allem diejenigen Artikel gewählt, die spannende Ergebnisse erzielt haben oder die ihre anfängliche Vermutung bestätigen konnten (<em>Confirmation Bias</em>). Die folgenden Ansätze lösen dieses Problem zum Beispiel dadurch, dass die Ergebnisse aus dem Begutachtungsprozess ausgeschlossen werden.</p>
<section id="results-blind-peer-review" class="level4">
<h4 class="anchored" data-anchor-id="results-blind-peer-review">Results-blind peer review</h4>
<p>Der einfachste Weg ist dabei, den Ergebnisteil einfach zu schwärzen oder wegzulassen. Verschiedene Zeitschriften bieten das als Option an. Da es sich hierbei zurzeit (2024) eher um eine Ausnahme handelt, ist den meisten Gutachtenden jedoch klar, dass vor allem diejenigen die Option zum results-blind peer review wählen, deren Ergebnisse nicht “hübsch genug” für den klassischen Weg sind.</p>
</section>
<section id="registered-report" class="level4">
<h4 class="anchored" data-anchor-id="registered-report">Registered Report</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/peerreview.jpg" class="img-fluid figure-img"></p>
<figcaption>Klassischer Forschungsprozess im Vergleich zu Registered Reports mit zusätzlicher Begutachtung vor der Studiendurchführung</figcaption>
</figure>
</div>
<p>Ein radikalerer Ansatz als die Begutachtung ohne Ergebnisteil ist die Begutachtung des Artikels, ohne dass Ergebnisse überhaupt existieren. Dieses Format heißt <em>Registered Report</em>. Dabei wird das Manuskript mit der zu prüfenden Theorie, Methodik, und dem Analyseplan bei der Zeitschrift eingereicht, ohne dass überhaupt Daten erhoben wurden. Kommt es zur Akzeptanz dieses „halbfertigen” Artikels (<em>in principle acceptance</em>), werden die Daten gesammelt, wie geplant ausgewertet, und es folgt eine weitere Begutachtungsrunde. Hierbei ist vorgeschrieben, dass die Autor*innen nichts an den bereits verfassten Teilen verändern dürfen und die Gutachter*innen im Nachhinein keine Kritik am bereits geprüften Vorgehen üben dürfen. Es geht nur noch darum, ob der Plan eingehalten wurde und ob die Schlussfolgerungen auf den geplanten Analysen fußen. Damit soll verhindert werden, dass Artikel abgelehnt werden, weil die Ergebnisse nicht spannend genug, innovativ genug, oder den Erwartungen entsprechend sind. Erste Untersuchungen können bereits nachweisen, dass sich damit die Qualität der Forschung gegenüber dem traditionellen Vorgehen verbessert <span class="citation" data-cites="Soderberg.2021">(<a href="#ref-Soderberg.2021" role="doc-biblioref">Soderberg et al. 2021</a>)</span>. Eine Übersicht über Zeitschriften, die dieses Format anbieten ist online verfügbar (<a href="https://www.cos.io/initiatives/registered-reports" class="uri">https://www.cos.io/initiatives/registered-reports</a> à Participating Journals; <span class="citation" data-cites="Chambers">(<a href="#ref-Chambers" role="doc-biblioref"><strong>Chambers?</strong></a>)</span>.; <span class="citation" data-cites="chambers2022past">Chambers and Tzavella (<a href="#ref-chambers2022past" role="doc-biblioref">2022</a>)</span>).&nbsp; Ebenfalls wird dadurch deutlich, dass Forschung einem massiven Publikationsbias unterliegt (d.h. es werden vor allem Studien veröffentlicht, die ihre Vermutungen bestätigen konnten und kaum Studien, in denen das nicht geschah): <span class="citation" data-cites="Scheel2021">(<a href="#ref-Scheel2021" role="doc-biblioref"><strong>Scheel2021?</strong></a>)</span> zeigten, dass der Anteil erwartungskonformer Ergebnisse bei Registered Reports mit 44% deutlich unter den in der Psychologie üblichen 96% liegt.</p>
</section>
<section id="pre-print-basierte-modelle" class="level4">
<h4 class="anchored" data-anchor-id="pre-print-basierte-modelle">Pre-Print basierte Modelle</h4>
<p>Durch die immer häufigere Veröffentlichung von Pre-Prints, also noch nicht begutachteten Manuskripten, eröffnen sich für die Begutachtung neue Wege. Sogenannte Overlay Journals (elife) wählen unter Pre-Prints solche aus, die sie an Gutachtende schicken um deren Meinungen einzuholen. Sofern die Autor*innen des Preprints einverstanden sind, erhalten sie dann Gutachten und ihr Artikel wird schließlich in der Zeitschrift veröffentlicht.</p>
<p>Je nach Fach haben unterschiedlich viele Zeitschriften mit PCI Initiativen Vereinbarungen, dass sie die akzeptierten Artikel ohne eigenes Peer Review veröffentlichen. Mehr und vor allem bekannte teilnehmende Zeitschriften machen PCIs für Forschende attraktiver. Zeitschriften, die Interesse an einem PCI haben, aber die Begutachtung nicht aus der Hand geben möchten, können sich als „PCI interested Journals” listen lassen (vs.&nbsp;„PCI friendly journals”). Teilnehmende Zeitschriften sparen dadurch Arbeit und bleiben relevant, indem sich Ihre Funktion dahin verschiebt, dass sie thematisch relevante Forschung sammeln und disseminieren. In einem Fall hat bereits eine Zeitschrift, die als „PCI friendly” eine Vereinbarung mit PCI-RR hatte, ein Manuskript mit einer <em>Recommendation</em> zum erneuten Peer Review versendet und wurde sofort von den PCI Partnern entfernt. Forschende, die Gutachtenprozesse für PCIs organisieren möchten – analog zu Herausgeber*innen von klassischen Zeitschriften – können <em>Recommender</em> werden und müssen dazu ein Mindestmaß an Wissen haben sowie eine Schulung absolvieren (<a href="https://rr.peercommunityin.org/about/recommenders" class="uri">https://rr.peercommunityin.org/about/recommenders</a>).</p>
<p><strong>Tabelle 2</strong></p>
<p><em>Zusammenfassung der verschiedenen Begutachtungsmodelle und der jeweiligen Art des Umgangs mit den Forschungsergebnissen</em></p>
<table class="caption-top table">
<colgroup>
<col style="width: 40%">
<col style="width: 59%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Begutachtungsprozedur</strong></td>
<td><strong>Ausblendung der Ergebnisse</strong></td>
</tr>
<tr class="even">
<td>Traditionell</td>
<td>Ergebnisse sind sichtbar und fließen in die Beurteilung ein</td>
</tr>
<tr class="odd">
<td>Results-Blind Peer Review</td>
<td>Ergebnisse liegen vor, werden den Begutachtenden jedoch vorenthalten</td>
</tr>
<tr class="even">
<td>Registered Report</td>
<td>Ergebnisse liegen noch nicht vor</td>
</tr>
<tr class="odd">
<td>Peer-Community-In Registered Report (PCI-RR)</td>
<td>Ergebnisse liegen noch nicht vor</td>
</tr>
</tbody>
</table>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Anekdoten: Meine schlimmsten Erfahrungen mit Peer Review
</div>
</div>
<div class="callout-body-container callout-body">
<p>Peer Review ist brutal. Das ist meine persönliche Erfahrung mit dem Prozess. Früh musste ich in meiner wissenschaftlichen Arbeit lernen, dass es in vielen Fällen ein Glücksspiel ist. Renommierte Wissenschaftler*innen erklärten mir, dass sie Artikel hätten, die sie über Jahre immer wieder bei Zeitschriften immer wieder eingereicht hätten, und die schließlich positiv aufgenommen worden wären, ohne, dass sie sie stark verändert hätten. Jenseits von der Akzeptanz eines Artikels zur Publikation geht es auch um die Gründe für die Ablehnung: Häufig lesen Gutachtende Artikel nicht aufmerksam und Kritiken sind nicht konstruktiv. Hierzu meine schlimmsten Erfahrungsberichte.</p>
<p><strong>Einreichung bei Collabra</strong>: Es handelte sich um einen Artikel, der zwischen den Disziplinen steht. Es geht nicht nur um Erwartungen, nicht nur um Produktbewertungen, nicht nur um die Methode, Daten direkt aus dem Internet herunterzuladen. Der “bunte-Vogel-Artikel” war bereits bei drei Zeitschriften abgelehnt worden. Bei keiner wurde er an die Reviewer weitergegeben, weil er nie zur Zeitschrift passte. Die Zeitschrift <em>Collabra</em>, bei der wir ihn schließlich einreichten, war zu dem Zeitpunkt noch wenige Jahre alt und war breit aufgestellt. Nach der Einreichung im Mai 2020 haben wir über ein halbes Jahr lang auf das Gutachten gewartet. Länger zu warten ist erstmal ein gutes Zeichen: Der Artikel wurde wohl an Reviewer rausgeschickt. In dem Fall wurden wir jedoch bitter enttäuscht: Im November 2020 erfuhren wir auf Nachfrage hin, dass 14 Gutachter*innen angefragt wurden, sodass die Herausgeberin auf Basis eines Gutachtens entschied, das Manuskript abzulehnen. Grund dafür war, dass die Methode aufgrund der inzidentellen Daten nicht geeignet für die Fragestellung war. In der Psychologie sowie den Wirtschaftswissenschaften ist das Problem mit “echten Daten” seit mehreren Jahrzehnten bekannt und wir hatten es bereits ausgiebig im Artikel diskutiert.</p>
<p><strong>Einreichung bei Journal of Experimental Social Psychology</strong>: Wir hatten eine Replikation einer dort erschienen Studie durchgeführt - der Befund ließ sich nicht replizieren. Meine Überlegung war, der Zeitschrift, die den nicht robusten Befund ursprünglich publizierte, selbst die Chance zur Selbstkorrektur zu geben. Die Reviews waren fair und positiv, es gab ein paar Punkte zu diskutieren, aber uns war klar, dass es sich hier um Verständnisprobleme und keine inhaltlichen Aspekte handelte. Nicht so der Editor: Er erklärte, dass der Befund nicht neu genug wäre und klar wäre, dass es nicht replizierbar ist. Ich erklärte ihm, dass noch niemand den Befund zu replizieren versucht hatte und wir selbst sogar vor der Analyse der Ergebnisse eine Abstimmung darüber gemacht hatten, welches Ergebnis wir erwarteten: Es war sehr ausgewogen 50-50. Darüber hinaus, wurde ein weiterer Artikel publiziert, der entgegengesetzt Ergebnisse hatte. Wir stellten klar, dass wir alle aufgezeigten Probleme einfach lösen können und gerne die Chance zur Revidierung hätten. Der Editor hätte dabei kaum Arbeit außer den Artikel anschließend nochmal an Gutachtende zu schicken. Auf unsere Mail erhielten wir nur eine kurze Antwort: <em>Hi. I know my decision is disappointing, but I’m going to stick with my decision on this one.</em> Hier befand ich mich an einem Scheideweg: Warum ist ein Forscher nicht bereit, Gründe für eine wissenschaftliche Entscheidung zu erörtern? Wir entschieden uns, einen anderen Editor direkt zu kontaktieren. Nach kurzer Zeit erhielten wir die Einladung zu einer Revision. Der Artikel wurde schließlich in der revidierten Fassung veröffentlicht.</p>
<p><strong>Einreichung bei European Journal of Personality</strong>: Die zentrale Aussage dieses Artikel war, dass verschiedene Messwerte einer angeblichen Eigenschaft nicht miteinander zusammenhängen. Der Befund stellte die Annahme infrage, dass es sich dabei überhaupt um eine Eigenschaft handelte. Die Ablehnungsgründe zweier Gutachtenden und der Herausgeberin machten deutlich: Niemand hatte den Artikel überhaupt gelesen. Ein Gutachter merkte an, dass etwas mit den Werten nicht stimme, weil sie laut einer der Tabellen nicht miteinander zusammenhängen. Genau das war ja unsere Aussage. Wir zeigten, dass es nich an unseren Daten lag, sondern sich in anderen Datensätzen so verhielt. Hätte er die Überschrift der Tabelle gelesen, den Absatz davor, oder den danach, wäre das klar geworden. Hat er aber nicht…</p>
<p>Das sind nur kurze Auszüge aus dutzenden Einreichungen und Ablehnungen. Darüber hinaus kann fast jede*r Forschende*r von substanzlosen persönliche Beleidigungen berichten. Meiner Erfahrung nach ist anonymes versus öffentliches Peer Review wie ein Vergleich von anonymen Kommentarspalten mit nicht anonymen: Bei Anonymität beherrschen persönliche Beleidigungen und Unwahrheiten den Dialog.</p>
</div>
</div>
</section>
</section>
<section id="replikationsforschung" class="level3">
<h3 class="anchored" data-anchor-id="replikationsforschung">Replikationsforschung</h3>
<p>Häufig ist die Rede von einer Replikationskrise, also einer Krise von zu geringer Replizierbarkeit. Wenig überraschend hat sich das auf die Rolle von Replikationen in den Sozialwissenschaften und darüber hinaus ausgewirkt. Zahlreiche Wege wurden eingeschlagen, die das Ansehen von Replikationsstudien und damit ihre Häufigkeit in der Forschung erhöhen. Dabei müssen die Wissenschaften nachholen, was sie zu Beginn ihrer Existenz hätten tun sollen, nämlich festzulegen, welche Ansprüche an Replizierbarkeit bestehen und wie diese geprüft werden sollen. Mit Replizierbarkeit meine ich dabei, dass eine Hypothese sich auch mit anderen Daten als denen der Originalstudie bestätigen lässt. Es geht also um ein minimales Maß an Verallgemeinerbarkeit und nicht primär um ein tieferes Verständnis von Theorien, auch, wenn letzteres dennoch manchmal kritisiert wird, obwohl niemand behauptet hat, Replikationen sollten das Theorie-Problem ebenfalls lösen <span class="citation" data-cites="feest2019replication">(<a href="#ref-feest2019replication" role="doc-biblioref">Feest 2019</a>)</span>.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Unschärfe von Replikationsstudien
</div>
</div>
<div class="callout-body-container callout-body">
<p>Ein noch ungelöstes Problem ist die Unschärfe von Original- <em>und</em> Replikationsstudien. <span class="citation" data-cites="Ting2024-af">Ting and Greenland (<a href="#ref-Ting2024-af" role="doc-biblioref">2024</a>)</span> kritisieren, dass die Ungenauigkeit von Replikationsstudien oft missachtet wird. Ihnen entgeht dabei jedoch, dass Replikationsstudien in fast allen Fällen eine weitaus höhere Schärfe im Studiendesign haben und höhere methodische Standards einhalten, als alle vorherigen Studien. Schönigung von Ergebnissen im Sinne von p-hacking <span class="citation" data-cites="Simmons.2011">(<a href="#ref-Simmons.2011" role="doc-biblioref">Simmons, Nelson, and Simonsohn 2011</a>)</span> sind prinzipiell auch bei Replikationen möglich <span class="citation" data-cites="protzko2018null">(<a href="#ref-protzko2018null" role="doc-biblioref">Protzko 2018</a>)</span>, durch die höheren Standards jedoch schwieriger. Zwar berücksichtigen Forschende Replikationsbefunde in ihren Urteilen angemessen <span class="citation" data-cites="mcdiarmid2021psychologists">(<a href="#ref-mcdiarmid2021psychologists" role="doc-biblioref">McDiarmid et al. 2021</a>)</span>, Untersuchungen dazu, wie Anfällig Replikationen für Datenfälschung im Vergleich zu Originalstudien sind, gibt es bisher noch keine.</p>
</div>
</div>
<section id="was-soll-sich-replizieren-lassen" class="level4">
<h4 class="anchored" data-anchor-id="was-soll-sich-replizieren-lassen">Was <em>soll</em> sich replizieren lassen?</h4>
<p>Vor dem Hintergrund der Robustheit wird klar, wann eine erfolgreiche Replikation zu erwarten ist und wann nicht: Wird eine Hypothese in einer Originalstudie als allgemeingültig formuliert (z.B. kurz nach der Geburt wiegen männliche Babys im Mittel mehr als weibliche Babys), sollte sie sich auch wiederholbar nachweisen lassen. Dem stehen Fälle gegenüber, wenn eine Hypothese nicht allgemeingültig formuliert ist (z.B. dass etwas auf einen spezifischen Kontext bezogen ist wie in qualitativer Forschung). Es gibt ganze Disziplinen, für die Replizierbarkeit irrelevant ist, beispielsweise wird in der Archäologie bei Ausgrabungen ein Objekt aus seinem Kontext gerissen und damit das Original “zerstört”. Dieser Prozess ist nicht wiederholbar und es hat auch niemand den Anspruch daran. Ebenfalls ist es möglich Artefakte (also Befunde, die nur durch Methoden entstanden sind) zu wiederholen, wenn deren Ursprung auf einer allgemeinen Gesetzgültigkeit basiert <span class="citation" data-cites="devezer2021case">(<a href="#ref-devezer2021case" role="doc-biblioref">Devezer et al. 2021</a>)</span>. Zum Beispiel kann es vorkommen, dass ein statistisches Modell replizierbar “anschlägt”, also Befundmuster identifiziert, auch wenn diese nicht auf Grund der eigentlichen Erklärung entstehen sondern nur, weil sie schlecht kalibriert sind oder ihre Voraussetzungen verletzt wurden. Beispielsweise schien es lange Zeit so, dass Linkshänder*innen früher sterben als Rechtshänder*innen. Dieser Befund konnte eine Zeit lang für verschiedene deutsche Stichproben nachgewiesen werden und es wurden bereits Überlegungen angestellt, woran das liegen könnte. Anhand heutiger Daten ist die Replikation nicht mehr möglich, weil es sich um ein Artefakt handelte: Bis vor einigen Jahrzehnten wurden alle Kinder dazu erzogen, mit rechts zu schreiben und zu schneiden. Schließlich stoppte die Umerziehung. Um in den darauffolgenden Jahren als linkhändrige Person in den Sterbestatistiken aufzutauchen, musste man ziemlich jung gestorben sein - denn ältere Personen, die mit links schreiben, gab es ja aufgrund der Umerziehung nicht. Das hatte zur Folge, dass linkshändrige Tote im Mittel ganze 10 Jahre jünger waren als rechtshändrige Tote. Replizierbarkeit ist also nicht hinreichend für Validität oder Wahrheit, aber um die Gültigkeit einer Hypothese zu unterstreichen oder ihren Wahrheitsanspruch zu verteidigen ist Replizierbarkeit notwendig.</p>
<p><span class="citation" data-cites="fletcher2021role">Fletcher (<a href="#ref-fletcher2021role" role="doc-biblioref">2021</a>)</span> listet die Bedingungen dafür auf, dass sich etwas replizieren lässt:</p>
<ol type="1">
<li><p>Es liegen keine Fehler in der Datenanalyse vor.</p></li>
<li><p>Der Befund ist nicht auf statistische Unschärfe zurückzuführen.</p></li>
<li><p>Der Befund hängt nicht von vernachlässigten Hintergrundfaktoren ab.</p></li>
<li><p>Es lag kein Betrug oder anderes wissenschaftliches Fehlverhalten vor.</p></li>
<li><p>Der Befund lässt sich auf eine Grundgesamtheit verallgemeinern, die größer als die Stichprobe der Originalstudie ist.</p></li>
<li><p>Die Hypothese ist auch dann noch gültig, wenn sie auf eine völlig andere Weise geprüft wird.&nbsp;</p></li>
</ol>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Notwendige und hinreichende Bedingung
</div>
</div>
<div class="callout-body-container callout-body">
<p>Replizierbarkeit ist eine notwendige aber keine hinreichende Bedingung für Allgemeingültigkeit, was ist damit gemeint? Die Begriffe “notwendig” und “hinreichend” sind vielen Personen wahrscheinlich aus der mathematischen Kurvendiskussion bekannt. Ihre genaue Bedeutung ist vor allem in der Logik relevant:</p>
<ul>
<li><p>Notwendig heißt “es geht nicht ohne”. Kakaopulver zu haben, ist notwendig dafür, dass ich einen Kakao zubereiten kann heißt, ich kann keinen Kakao zubereiten, wenn ich kein Kakaopulver habe. Gleichzeitig ist es nicht ausreichend oder hinreichend: Nur, weil ich Kakaopulver habe, heißt das nicht, dass ich Kakao zubereiten kann. Vielleicht fehlt noch Milch, Wasser, eine Tasse, oder eine Mikrowelle.</p></li>
<li><p>Hinreichend heißt: Wenn es da ist, dann reicht das schon und keine weiteren Bedingungen müssen erfüllt sein. Wenn ich ein Flugzeug am Himmel höre, dann ist das hinreichend dafür, dass am Himmel ein Flugzeug entlang fliegt. Es ist aber auch möglich, dass ein Flugzeug am Himmel entlang fliegt, ohne dass ich es höre (zum Beispiel, weil es sehr hoch fliegt, die Umgebungsgeräusche sehr laut sind, oder es ein leiser Segelflieger ist).</p></li>
</ul>
<p>Anders als in manchen Beispielen, muss die Bedingung nicht immer vor dem Ereignis auftreten. Es geht also um keinen Kausalzusammenhang, bei dem eines zum anderen <em>führt</em>. Eine Besonderheit bei Bedingungen ist, dass wenn A notwendig für B ist, dann ist B hinreichend für A. Dass ich einen Kakao zubereitet habe, ist also hinreichend dafür, dass ich Kakaopulver habe. Und, dass ein Flugzeug am Himmel entlang fliegt ist notwendig dafür, dass ich es hören kann.</p>
</div>
</div>
</section>
<section id="wer-repliziert" class="level4">
<h4 class="anchored" data-anchor-id="wer-repliziert">Wer repliziert?</h4>
<p>Trotz starker Bemühungen sind Replikationsstudien immer noch relativ selten. Schätzungen reichen von 5% bis unter 0.1% je nach Forschungsdisziplin. Ein Großteil der Befunde aus der folgenden Tabelle stammen aus einem <a href="https://x.com/giladfeldman/status/1735950123291779119">Tweet von Gilad Feldman</a>.</p>
<table class="caption-top table">
<caption>Überblick darüber, wo wieviel repliziert wird</caption>
<colgroup>
<col style="width: 27%">
<col style="width: 22%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Disziplin</th>
<th>Quelle</th>
<th>Befund</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Wirtschaftswissenschaften</td>
<td><span class="citation" data-cites="ankel2023economists">Ankel-Peters, Fiala, and Neubauer (<a href="#ref-ankel2023economists" role="doc-biblioref">2023</a>)</span></td>
<td>Je nach Zeitschrift ist der Anteil an Replikationen und Reproduktionen zwischen 0 und 11%.</td>
</tr>
<tr class="even">
<td>Wirtschaftswissenschaften</td>
<td><span class="citation" data-cites="mueller2019replication">Mueller-Langer et al. (<a href="#ref-mueller2019replication" role="doc-biblioref">2019</a>)</span></td>
<td>0,1% der Publizierten Studien sind Replikationen.</td>
</tr>
<tr class="odd">
<td>Experimentelle Linguistik</td>
<td><span class="citation" data-cites="kobrock2023assessing">Kobrock and Roettger (<a href="#ref-kobrock2023assessing" role="doc-biblioref">2023</a>)</span></td>
<td>Weniger als 0,001% der Studien beinhalten Replikationen.</td>
</tr>
<tr class="even">
<td>Psychologie (1900 - ca. 2012)</td>
<td><span class="citation" data-cites="Makel2012-bi">Makel, Plucker, and Hegarty (<a href="#ref-Makel2012-bi" role="doc-biblioref">2012</a>)</span></td>
<td>Circa 1.07% aller Artikel seit 1900 beinhalten Replikationen, der Anteil ist zuletzt gestiegen.</td>
</tr>
<tr class="odd">
<td>Psychologie (2014 - 2017)</td>
<td><span class="citation" data-cites="hardwicke2022estimating">Hardwicke et al. (<a href="#ref-hardwicke2022estimating" role="doc-biblioref">2022</a>)</span></td>
<td>Replikationen werden in 3-8% der Studien berichtet.</td>
</tr>
<tr class="even">
<td>Psychologie (2010 - 2021, High Impact Zeitschriften)</td>
<td><span class="citation" data-cites="Clarke2023-ff">Clarke et al. (<a href="#ref-Clarke2023-ff" role="doc-biblioref">2023</a>)</span></td>
<td>0,2% (169 von 84.834) Artikel beinhalteten direkte Replikationen.</td>
</tr>
<tr class="odd">
<td>Ökologie und Evolution</td>
<td><span class="citation" data-cites="kelly2019rate">Kelly (<a href="#ref-kelly2019rate" role="doc-biblioref">2019</a>)</span></td>
<td>Weniger als 1% der Studien werden als Replikationen bezeichnet.</td>
</tr>
<tr class="even">
<td>Zweitsprachenforschung</td>
<td><span class="citation" data-cites="marsden2018replication">Marsden et al. (<a href="#ref-marsden2018replication" role="doc-biblioref">2018</a>)</span></td>
<td>0,25% der Studien sind Replikationen.</td>
</tr>
<tr class="odd">
<td>Erziehungswissenschaften</td>
<td><span class="citation" data-cites="Makel2014-jc">Makel and Plucker (<a href="#ref-Makel2014-jc" role="doc-biblioref">2014</a>)</span></td>
<td>0,13% der Artikel beinhalteten Replikationen.</td>
</tr>
<tr class="even">
<td>Sonderpädagogik</td>
<td><span class="citation" data-cites="makel2016replication">Makel et al. (<a href="#ref-makel2016replication" role="doc-biblioref">2016</a>)</span></td>
<td>0,5% der Artikel beinhalteten Replikationsstudien.</td>
</tr>
<tr class="odd">
<td>Kriminologie</td>
<td><span class="citation" data-cites="McNeeley2015-bf">McNeeley and Warner (<a href="#ref-McNeeley2015-bf" role="doc-biblioref">2015</a>)</span></td>
<td>Etwas über 2% der Artikel beinhalten Replikationsstudien.</td>
</tr>
<tr class="even">
<td>Verhaltensökologie</td>
<td><span class="citation" data-cites="Kelly2006-wt">Kelly (<a href="#ref-Kelly2006-wt" role="doc-biblioref">2006</a>)</span></td>
<td>Replikationen werden selten durchgeführt.</td>
</tr>
</tbody>
</table>
</section>
<section id="ansehen-von-replikationsstudien" class="level4">
<h4 class="anchored" data-anchor-id="ansehen-von-replikationsstudien">Ansehen von Replikationsstudien</h4>
<p>Replikationen von Bem’s berüchtigter Studie zum Erfühlen der Zukunft wurden bei der Zeitschrift, bei der sie veröffentlicht wurde, ohne Begutachtungsprozess abgelehnt (“Desk Reject”). Der Editor erklärte, die Zeitschrift veröffentlicht keine Replikationsstudien, egal was dabei herauskam, da sie nicht die Zeitschrift der Bem Replikationen sein möchten <span class="citation" data-cites="Lakens.2023">(<a href="#ref-Lakens.2023" role="doc-biblioref">Daniel Lakens 2023</a>)</span>. Unter den 3185 Zeitschriften mit TOP Faktor gaben im Jahr 2024 341 Zeitschriften (10.7%) an, dass sie Replikationen akzeptieren. Sie werden als Konfrontation der aktuellen theoretischen Erwartungen mit aktuellen Daten definiert und ihre wichtige Rolle im wissenschaftlichen Prozess mehr und mehr anerkannt (REF <a href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000691" class="uri">https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000691</a>). Ein Großteil dieser Entwicklung ist von der Sozialpsychologie getragen, andere Felder verändern sich kaum oder nur langsam (REF, <a href="https://psycharchives.org/en/item/74463c10-7347-4bf2-8156-5618d42c4e93" class="uri">https://psycharchives.org/en/item/74463c10-7347-4bf2-8156-5618d42c4e93</a>), doch selbst dort sind Diskussionen von Replikationsbefunden zum Teil noch hart und die Replikationen werden (REF, <a href="#0" class="uri">https://osf.io/96pnj</a>).</p>
<p>In den Wirtschaftswissenschaften hat sich das Insitute for Replications (I4R, <a href="https://i4replication.org/reports.html" class="uri">https://i4replication.org/reports.html</a>) gebildet, welches sogenannte Replication Games organisiert, bei denen Studien reproduziert und repliziert wurden. Anknüpfend an eine Forderung <span class="citation" data-cites="Zimmermann2015-jw">(<a href="#ref-Zimmermann2015-jw" role="doc-biblioref">Zimmermann 2015</a>)</span> wurde das Journal of Comments and Replications in Economics (JCRe) gegründet. Ab 2024 konzentriert sich das I4R darauf, Replikationen zu spezifischen Zeitschriften durchzuführen. Ironischerweise tut es das nicht für Open Access Zeitschriften, sondern beispielsweise für Nature (REF <a href="https://www.nature.com/articles/s41562-023-01807-2" class="uri">https://www.nature.com/articles/s41562-023-01807-2</a>). Das Journal of Applied Econometrics veröffentlicht ebenfalls Replikationen zu Studien aus <a href="https://onlinelibrary.wiley.com/page/journal/10991255/homepage/news.html">zahlreichen ökonomischen Zeitschriften</a>.</p>
</section>
<section id="arten-von-replikationsprojekten" class="level4">
<h4 class="anchored" data-anchor-id="arten-von-replikationsprojekten">Arten von Replikationsprojekten</h4>
<p>Während ein Großteil der Replikationsstudien klassischen Studien entspricht, haben sich Spezialmodelle entwickelt. Beispielsweise können Forschende mit StudySwap Gruppen suchen, die ihre Ergebnisse vor der Veröffentlichung replizieren (REF <a href="https://osf.io/preprints/psyarxiv/dtvs7/" class="uri">https://osf.io/preprints/psyarxiv/dtvs7/</a>; p.&nbsp;11). Im Rahmen von Registered Replication Reports konzentrieren sich große Teams an mehreren Orten auf eine zuvor abgestimmte Studie und führen sie gleichzeitig überall durch. Einer der fruchtbarsten Ansätze ist die Nutzung von Abschlussarbeiten für Replikationen. Im Rahmen eines Studiums müssen alle Studierende eine Abschlussarbeit (z.B. Bachelorarbeit oder Masterarbeit) ablegen. Anhand von Replikationen können sie lernen, eine wichtige Studie nachzubilden und prüfen gleichzeitig die Robustheit der Originalbefunde. Während <span class="citation" data-cites="Quintana2021-dp">Quintana (<a href="#ref-Quintana2021-dp" role="doc-biblioref">2021</a>)</span> vorschlug, Abschlussarbeiten so zu verwenden, ist es bereits gängige Praxis in den vergleichenden Politikwissenschaften <span class="citation" data-cites="korell2023student">(<a href="#ref-korell2023student" role="doc-biblioref">Korell, Reinecke, and Lott 2023b</a>)</span>, in der Psychologie <span class="citation" data-cites="Jekel.2020 Feldman.2021 Boyce.2023 wagge2019publishing">(<a href="#ref-Jekel.2020" role="doc-biblioref">Jekel et al. 2020</a>; <a href="#ref-Feldman.2021" role="doc-biblioref">Feldman 2021</a>; <a href="#ref-Boyce.2023" role="doc-biblioref">Boyce, Mathur, and Frank 2023</a>; <a href="#ref-wagge2019publishing" role="doc-biblioref">Wagge et al. 2019</a>)</span>, und in den Wirtschaftswissenschaften (<a href="https://home.uni-leipzig.de/lerep/" class="uri">https://home.uni-leipzig.de/lerep/</a>). Am Wissenschaftszentrum Berlin für Sozialforschung (https://www.wzb.eu/de/forschung/markt-und-entscheidung/verhalten-auf-maerkten/labsquare) und beim Sports Science Replication Center (https://ssreplicationcentre.com) starteten 2024 ebenfalls Replikationsreihen.</p>
<table class="caption-top table">
<caption>Typen von Replikationen</caption>
<colgroup>
<col style="width: 20%">
<col style="width: 58%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Typ</th>
<th>Erklärung</th>
<th>Beispiel</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Registered Replication Report</td>
<td>Forschende an vielen verschiedenen Orten führen dieselbe Replikationsstudie durch <span class="citation" data-cites="Simons.2014b">(<a href="#ref-Simons.2014b" role="doc-biblioref">Simons, Holcombe, and Spellman 2014</a>)</span>.</td>
<td><span class="citation" data-cites="Cheung.2016">Cheung et al. (<a href="#ref-Cheung.2016" role="doc-biblioref">2016</a>)</span></td>
</tr>
<tr class="even">
<td>Internal Replication</td>
<td>Eine Forschungsgruppe berichtet in einem Forschungsartikel eine <em>eigene</em> Replikation einer ihrer Studien.</td>
<td><span class="citation" data-cites="ongchoco2023visual">Ongchoco, Walter-Terrill, and Scholl (<a href="#ref-ongchoco2023visual" role="doc-biblioref">2023</a>)</span></td>
</tr>
<tr class="odd">
<td>Close Replication</td>
<td>Eine Orginalstudie soll möglichst ähnlich von anderen Forschenden durchgeführt werden.</td>
<td><span class="citation" data-cites="Xiao.2021">Xiao et al. (<a href="#ref-Xiao.2021" role="doc-biblioref">2021</a>)</span></td>
</tr>
<tr class="even">
<td>Conceptual Replication</td>
<td>Andere Forschende prüfen dieselbe Hypothese erneut, verwenden dabei aber absichtlich andere Methoden.</td>
<td><span class="citation" data-cites="Sobkow.2021">Sobkow et al. (<a href="#ref-Sobkow.2021" role="doc-biblioref">2021</a>)</span></td>
</tr>
</tbody>
</table>
</section>
<section id="wer-veröffentlicht-replikationen" class="level4">
<h4 class="anchored" data-anchor-id="wer-veröffentlicht-replikationen">Wer veröffentlicht Replikationen?</h4>
<p><span class="citation" data-cites="srivastava2012pottery">Srivastava (<a href="#ref-srivastava2012pottery" role="doc-biblioref">2012</a>)</span> schlug eine “Pottery Barn” Regel für wissenschaftliche Zeitschriften vor. Unter dieser Regel versteht man das in Töpfereien übliche Regel “wer es kaputt macht, muss es kaufen”. Für Replikationen hieße das, dass eine Zeitschrift alle Replikationen zu einer Studie, die sie veröffentlicht hat, ebenfalls veröffentlichen muss. Tatsächlich tut das keine Zeitschrift - möglicherweise aus Furcht, ihren Impact Factor zu reduzieren oder der unzureichenden wissenschaftlichen Qualitätssicherung beschuldigt zu werden. Abgesehen von den Replikationsszeitschriften JCRe (<a href="https://www.jcr-econ.org" class="uri">https://www.jcr-econ.org</a>) und Rescience X (rescience.org/x) gibt es vereinzelte Zeitschriften, die Replikationsstudien veröffentlichen. In der Psychologie sind das beispielsweise Meta-Psychology und das Journal of Trial and Error.</p>
<p>Um die Auffindbarkeit von Replikationen dennoch zu erhöhen, sind Replikationen<em>datenbanken</em> entstanden. Dabei sammeln Forschende Replikationsstudien und bereiten sie nutzerfreundlich auf. Für Wirtschaftswissenschaften hat Jan Höffler mit dem Replication Wiki (<a href="https://replication.uni-goettingen.de/wiki/index.php/Special:FormEdit/New_Replication" class="uri">https://replication.uni-goettingen.de/wiki/</a>) grundlegende Arbeit geleistet <span class="citation" data-cites="hoffler2017replicationwiki">(<a href="#ref-hoffler2017replicationwiki" role="doc-biblioref">Höffler 2017</a>)</span>. In der Psychologie stellte LeBel curatescience.org vor. Das Projekt starb schnell wieder aus, die Idee wurde von FORRT mit “Replications and Reversals” (forrt.org/reversals/) aufgegriffen und 2023 mit der “Replication Database” zur “FORRT Replication Database” vereinigt. Mit meta-analytischen Funktionen und der Möglichkeit, Quellenverzeichniss auf Replikationsstudien zu prüfen ist die FORRT Replication Database aktuell das umfangreichste Projekt (forrt.org/replication-hub). Der Großteil dieser Projekte wird von großen Communities gestemmt, bei welcher die Teilnehmenden mühselig per Hand Daten beitragen. Automatisierte Methoden sind in Entwicklung, allerdings noch unausgereift <span class="citation" data-cites="de2023automatically">(<a href="#ref-de2023automatically" role="doc-biblioref">Ruiter 2023</a>)</span>.</p>
</section>
<section id="was-ist-eine-gute-replikation" class="level4">
<h4 class="anchored" data-anchor-id="was-ist-eine-gute-replikation">Was ist eine gute Replikation?</h4>
<p>Über viele Fächer hinweg werden Replikationsmethoden entwickelt. Vorangehend mit der Psychologie <span class="citation" data-cites="Brandt.2014 Huffmeier.2016">(<a href="#ref-Brandt.2014" role="doc-biblioref">Brandt et al. 2014</a>; <a href="#ref-Huffmeier.2016" role="doc-biblioref">Hüffmeier, Mazei, and Schultze 2016</a>)</span> gibt es Richtlinien für Replikationen in quantiativer Soziologie <span class="citation" data-cites="freese2017replication">(<a href="#ref-freese2017replication" role="doc-biblioref">Freese and Peterson 2017</a>)</span>, Geisteswissenschaften <span class="citation" data-cites="Schoch.2023">(<a href="#ref-Schoch.2023" role="doc-biblioref">Schöch 2023</a>)</span>, und Marketing <span class="citation" data-cites="urminsky2024taking">(<a href="#ref-urminsky2024taking" role="doc-biblioref">Urminsky and Dietvorst 2024</a>)</span>. Methoden zur Stichprobenplanung [<span class="citation" data-cites="Simonsohn.2015">Simonsohn (<a href="#ref-Simonsohn.2015" role="doc-biblioref">2015</a>)</span>; <span class="citation" data-cites="Pawel2023-vv">Pawel, Consonni, and Held (<a href="#ref-Pawel2023-vv" role="doc-biblioref">2023</a>)</span>; ht<a href="https://link.springer.com/article/10.1007/s11749-023-00916-4" class="uri">tps://link.springer.com/article/10.1007/s11749-023-00916-4</a>] und zur Auswahl [REF; <a href="https://www.sciencedirect.com/science/article/pii/S0010945223002691" class="uri">https://www.sciencedirect.com/science/article/pii/S0010945223002691</a>; <a href="https://www.researchgate.net/publication/365057816_ORMA_A_strategy_to_reduce_Psychology's_replication_problems">https://www.researchgate.net/publication/365057816_ORMA_A_strategy_to_reduce_Psychology’s_replication_problems</a>], Bewertung (https://docs.google.com/document/d/1p7GeOpwzQyTuzAWsD1w3zql2dS6mFgEhdf38Lc3uXC4/edit#heading=h.oti7bgwflneo), und Kommunikation [REF; <a href="https://doi.org/10.1017/S1049096520000943" class="uri">https://doi.org/10.1017/S1049096520000943</a>] von Replikationsstudien wurden entwickelt. Unten werden Empfehlungen in Form eines Replikationsleitfadens strukturiert.</p>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Kurzleitfaden für die Durchführung von Replikationsstudien
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><p><strong>Wahl der Studie</strong><br>
Die zu replizierende Studie sollte relevant und anzweifelbar sein. Relevanz kann sich durch viele Zitationen äußern oder dadurch, dass viel Forschung auf dem Befund aufbaut. Existieren bereits viele Replikationen und ist klar, dass Replizierbarkeit gegeben oder nicht gegeben ist, ist eine Replikationsstudie wenig informativ. Aufgrund der Replikationskrise ist die Anzweifelbarkeit meistens gegeben (z.B. durch P-Werte nah an der 5% Schwelle). Mittels meta-analytischer Auffälligkeiten <span class="citation" data-cites="Adler.2023">(<a href="#ref-Adler.2023" role="doc-biblioref">Adler, Röseler, and Schöniger 2023</a>)</span> lässt sich die Anzweifelbarkeit ebenfalls prüfen.<br>
Bei der Auswahl empfiehlt es sich zudem, bisherige Diskussionen (Kommentare in Zeitschriften oder auf Pubpeer.com) zu berücksichtigen, falls es sie gibt. Im Rahmen von Abschlussarbeiten ist außerdem die Machbarkeit zu berücksichtigen: Eine Längsschnittstudie, die 10 Jahre dauert, ist nicht gut machbar. Ebenfalls sollte es für den entsprechenden Bereich etablierte Replikationsstandards geben. Für Daten von Gehirnscannern ist das beispielsweise noch nicht der Fall, da dort hunderte bis tausende von Korrelationen verglichen werden und die Originalwerte häufig nicht verfügbar sind.</p></li>
<li><p><strong>Durchführung</strong><br>
Eine Bestandsaufnahme aller öffentlicher Materialien ist empfehlenswert. Wenn möglich, sollten Originalergebnisse reproduziert und geprüft werden. Auch ohne Daten lassen sich zum Beispiel via statcheck.io <span class="citation" data-cites="nuijten2016prevalence">(<a href="#ref-nuijten2016prevalence" role="doc-biblioref">Nuijten et al. 2016</a>)</span> Werte auf Korrektheit prüfen. Bei jüngeren Studien können die Originalautor*innen Daten und Materialien zur Verfügung stellen.<br>
Eine besondere Herausforderung ist in der Forschung die Planung des Stichprobenumfanges (statistische Power). Zwar ist das Problem für Replikationsstudien deshalb am geringsten, weil es dort schon einen Befund zur Orientierung gibt, allerdings ist der meistens zu unscharf, um den für die Berechnungen zu verwenden. Der Small Telescopes Approach <span class="citation" data-cites="Simonsohn.2015">(<a href="#ref-Simonsohn.2015" role="doc-biblioref">Simonsohn 2015</a>)</span> hilft hierbei aus und ggf. muss auf Äquivalenztests zurückgegriffen werden <span class="citation" data-cites="Lakens.2017">(<a href="#ref-Lakens.2017" role="doc-biblioref">Daniël Lakens 2017</a>)</span>.<br>
Um die Anpassung der Originalmethode kommen Replizierende nur selten: Materialien sind veraltet, müssen in eine andere Sprache übersetzt werden, oder an eine besondere Stichprobe von Personen angepasst werden. Dabei können ähnliche Studien helfen, die mittels Replikationsdatenbank aufgespürt werden können <span class="citation" data-cites="Roseler.2024">(<a href="#ref-Roseler.2024" role="doc-biblioref">Röseler et al. 2024</a>)</span>. Häufig bieten sich auch Erweiterungen (Extensions) an, die den Informationsgehalt der Studie erhöhen.</p></li>
<li><p><strong>Analyse</strong><br>
Ähnlich wie bei den Methoden ist es häufig sinnvoll, die Originalanalyse nachzubilden (konfirmatorisch) und anschließend weitere Tests durchzuführen (exploratorisch). Ein Vergleich der Ergebnisse - auch im Hinblick auf methodische Unterschiede - erlaubt dann ein umfassendes Bild.</p></li>
<li><p><strong>Diskussion</strong><br>
Unter welchen Bedingungen die Replikation als erfolgreich interpretiert wird, sollte zuvor in einer Präregistrierung festgelegt werden. Vorschläge für Kriterien machen <span class="citation" data-cites="Brandt.2014">Brandt et al. (<a href="#ref-Brandt.2014" role="doc-biblioref">2014</a>)</span>, <span class="citation" data-cites="LeBel.2019">LeBel et al. (<a href="#ref-LeBel.2019" role="doc-biblioref">2019</a>)</span>, und <span class="citation" data-cites="Anderson.2017">Anderson, Kelley, and Maxwell (<a href="#ref-Anderson.2017" role="doc-biblioref">2017</a>)</span>. Abweichungen von der Präregistrierung und der Originalstudie sollten dabei ausgiebig diskutiert werden. Ob ein Kommentar der Autor*innen der Originalstudie hilfreich ist, ist umstritten, obgleich Kommentare für die Veröffentlichung bei manchen Zeitschriften nötig ist.</p></li>
<li><p><strong>Bericht</strong><br>
Umfangreiche Berichte von Feldman und Kolleg*innen <span class="citation" data-cites="Ziano.2021">(<a href="#ref-Ziano.2021" role="doc-biblioref">Ziano, Mok, and Feldman 2021</a>)</span> bieten gute Orientierung für eigene Manuskripte. Für kurze Berichte ist ebenfalls ein <a href="https://osf.io/j2qrx">standardisiertes Formular</a> verfügbar, mittels welchem Befunde in die Replikationendatenbank eingetragen werden können. <span class="citation" data-cites="Brandt.2014">Brandt et al. (<a href="#ref-Brandt.2014" role="doc-biblioref">2014</a>)</span> empfehlen außerdem eine Registrierung der Ergebnisse, welche die Weiterverwendung ermöglicht <span class="citation" data-cites="Roseler.2022d">(<a href="#ref-Roseler.2022d" role="doc-biblioref">Röseler et al. 2022</a>)</span>. Zuletzt ist eine Veröffentlichung des Pre-Prints empfehlenswert. Für Sozialwissenschaften und Medizin befindet sich zur Zeit eine interdisziplinäre Replikationszeitschrift in der Vorbereitungsphase, bei der die Studie zur Veröffentlichung eingereicht werden kann.</p></li>
</ol>
</div>
</div>
</section>
</section>
<section id="modellierung-von-replizierbarkeit" class="level3">
<h3 class="anchored" data-anchor-id="modellierung-von-replizierbarkeit">Modellierung von Replizierbarkeit</h3>
<p>Alle Studien in einem Wissenschaftsbereich zu replizieren ist aktuell unrealistisch und würde enorme Ressourcen benötigen. Daher befinden sich verschiedene Methoden in Entwicklung, um auf Basis von Eigenschaften einer Studie vorherzusagen, welche Replikationsergebnis zu erwarten ist. Im <a href="https://www.youtube.com/watch?v=qa2_9NrEmeA">repliCATS</a> Projekt, das Teil des SCORE Projektes zur Messung wissenschaftlicher Qualität ist, werden Einschätzungen von Forschenden, Reproduktionsversuche, und Replikationsversuche kombiniert. Ähnliche Projekte verwenden komplexe statistische Modelle (z.B. Large-Language-Models) oder meta-analytische Methoden wie p-curve oder Z-curve zur Vorhersage von Replikationsraten. Solche Modelle benötigen üblicherweise sehr viele Beobachtungen und Vorhersagen sind nur auf der Ebene von hunderten Studien sinnvoll. Beispielsweise rechneten <span class="citation" data-cites="Boyce.2023">Boyce, Mathur, and Frank (<a href="#ref-Boyce.2023" role="doc-biblioref">2023</a>)</span> und Hagen Cumulative Science project <span class="citation" data-cites="Jekel.2020">(<a href="#ref-Jekel.2020" role="doc-biblioref">Jekel et al. 2020</a>)</span> Moderationsanalysen, prüften also welche Eigenschaften von Studien sich auf das Replikationsergebnis auswirken (z.B. Wechsel von Studie im Labor zu Online-Studie). Mittels umfassender Datenbanken wie der FORRT Replication Database <span class="citation" data-cites="Roseler.2024">(<a href="#ref-Roseler.2024" role="doc-biblioref">Röseler et al. 2024</a>)</span> können in Zukunft präzisere Modelle erstellt werden. Aktuelle Ergebnisse sind als vorläufig und mit Vorsicht zu interpretieren, da sie auf nicht-zufälligen Stichproben basieren, die Studieneigenschaften nicht systematisch und zufällig variiert wurden, und Replikationen solcher meta-analytischen Befunde schwierig sind.</p>
</section>
<section id="veröffentlichung-aller-ergebnisse" class="level3">
<h3 class="anchored" data-anchor-id="veröffentlichung-aller-ergebnisse">Veröffentlichung aller Ergebnisse</h3>
<p>Um das lange bekannte File-Drawer-Problem <span class="citation" data-cites="Sterling.1959 Rosenthal.1979">(<a href="#ref-Sterling.1959" role="doc-biblioref">Sterling 1959</a>; <a href="#ref-Rosenthal.1979" role="doc-biblioref">Rosenthal 1979</a>)</span> zu lösen gibt es intensive Bemühungen, statistische Modelle zu entwickeln, die die Verzerrung “herausrechnen” können. Keines der aktuellen Modelle funktioniert für alle Daten <span class="citation" data-cites="Carter.2019">(<a href="#ref-Carter.2019" role="doc-biblioref">Carter et al. 2019</a>)</span>, weshalb Forschende aktuell nicht daran vorbei kommen, alle Ergebnisse zu veröffentlichen.</p>
<p>In der Medizin ist der besondere Fall, dass Studien am Menschen öffentlich registriert werden müssen, bevor sie durchgeführt werden. Es existiert also eine öffentlich einsehbare Datenbank, mittels derer nachvollzogen werden kann, wer zu welchem Zeitpunkt eine Studie durchgeführt hat. Gleichzeitig müssen die Registrierungsnummern bei der Veröffentlichung von Artikeln angegeben werden. Werden beide Daten kombiniert, können wir sehen, wie viele Studien innerhalb eines bestimmten Zeitraums nach der Registrierung veröffentlicht werden - und das sogar aufgeteilt nach Personen und Institutionen (Quest Dashboard; <a href="https://quest-cttd.bihealth.org/#tabStart" class="uri">https://quest-cttd.bihealth.org/</a>). Im Open Trials Projekt (https://opentrials.net/about/) wird zudem daran gearbeitet, Informationen zu Registrierungen und Forschungsartikeln aus verschiedenen Datenbanken zu verknüpfen.</p>
<p>In anderen Fächern besteht keine Pflicht zur Durchführung von Studien, sodass völlig unklar ist, welche und wie viele Studien “in der Schublade landen”. Die Zeitschrift Meta-Psychology bietet ein Artikel-Format für psychologische File-Drawer-Reports (Schubladenberichte) an, in denen Forschende alle Studien zu einem bestimmten Thema veröffentlichen können und dabei auch fehlgeschlagene oder fehlerhafte Studien berichten. Das Journal of Negative Results (<a href="https://www.jnr-eeb.org/index.php/jnr/about" class="uri">https://www.jnr-eeb.org/index.php/jnr/about</a>) und das Journal of Articles in Support of the Null Hypothesis (https://www.jasnh.com) sind spezialisiert auf Ergebnisse, die die nicht den Erwartungen entsprechen. Im Rahmen des Projektes <em>PsychFileDrawer</em> existierte eine Zeit lang eine online Datenbank für psychologische Studien, die nicht veröffentlicht wurden, und “All Results Journals” veröffentlichten Ergebnisse aus den Naturwissenschaften (http://www.arjournals.com). Von letzteren ist allerdings nur noch die Biologie Zeitschrift aktiv, während Physik und Chemie seit langer Zeit nichts publiziert haben.</p>
<p>Themenspezifisch haben sich vor allem in der Psychologie Datenbanken etabliert, die alle Studien zu einem Thema zusammenfassen, mittels derer sich Studien durchsuchen und manchmal sogar statistisch zusammenfassen lassen. Solche Zusammenfassungen sind häufig Meta-Analysen (Studien über Studien bzw. Analysen von vielen Studienergebnissen) und mithilfe der Datenbanken sind sie dynamisch, es lassen sich also Studien filtern, Datenbanken wachsen über die Zeit, und Benutzer*innen können die Analysen selbst bestimmen. Durch die zentrale Rolle von statistischen Ergebnissen sind sie vielversprechend in Bezug auf kumulative Wissenschaft, das heißt, sie erleichtern es Forschenden, aufeinander aufzubauen. Neben den Themen und Funktionen unterscheiden sich die Datenbanken außerdem darin, wie sie Ergebnisse sammeln. Manche stammen von einzelnen Forschenden und andere sind durch “Crowd Sourcing” entstanden, das heißt, eine Gruppe stellt die Infrastruktur der Datenbank bereit und andere Forschende senden ihre Daten dort hin. Das hat den Vorteil, dass die Arbeit geteilt wird und die Beitragenden ihre Daten durch die Veröffentlichung in der Datenbank sichtbarer machen. In der folgenden Tabelle sind einige themenspezifische Datenbanken aufgelistet.</p>
<table class="caption-top table">
<tbody>
<tr class="odd">
<td><strong>Name</strong></td>
<td><strong>Link</strong></td>
<td><strong>Topics</strong></td>
</tr>
<tr class="even">
<td>MetaLab</td>
<td><a href="https://langcog.github.io/metalab">langcog.github.io/metalab</a></td>
<td>Sprachentwicklung, kognitive Entwicklung</td>
</tr>
<tr class="odd">
<td>metaBUS</td>
<td><a href="http://metabus.org/">metabus.org</a></td>
<td>Sozialwissenschaften</td>
</tr>
<tr class="even">
<td>SOLES</td>
<td><a href="https://camarades.shinyapps.io/AD-SOLES/">camarades.shinyapps.io/AD-SOLES/</a></td>
<td>Tiermodelle von Alzheimer</td>
</tr>
<tr class="odd">
<td>OpAQ</td>
<td><a href="https://t1p.de/openanchoring">t1p.de/openanchoring</a></td>
<td>Anker Effekte</td>
</tr>
<tr class="even">
<td>FReD</td>
<td><a href="https://t1p.de/ReD">t1p.de/ReD</a></td>
<td>Replikationsstudien</td>
</tr>
<tr class="odd">
<td>Power Posing</td>
<td><a href="https://metaanalyses.shinyapps.io/bodypositions/">metaanalyses.shinyapps.io/bodypositions</a></td>
<td>Effekte der Körperhaltung</td>
</tr>
<tr class="even">
<td>Metadataset</td>
<td><a href="https://www.metadataset.com/">metadataset.com</a></td>
<td>Landwirtschaft</td>
</tr>
<tr class="odd">
<td>METAPSY</td>
<td><a href="https://www.metapsy.org" class="uri">https://www.metapsy.org</a></td>
<td>Psychotherapie</td>
</tr>
</tbody>
</table>
<p>Inzwischen werden auch Werkzeuge entwickelt, die Forschenden helfen, solche Datenbanken zu erstellen. <em>MetaUI</em> und <em>Dynameta</em> erleichtern das erstellen einer Website, auf welche Daten interaktiv analysiert und heruntergeladen werden können (metaUI, <a href="https://github.com/lukaswallrich/metaui" class="uri">https://github.com/lukaswallrich/metaui</a>; Dynameta, https://github.com/gls21/Dynameta). Weitere Materialien erarbeitet das Project PsychOpen CAMA (https://cama.psychopen.eu).</p>
</section>
<section id="umgang-mit-fehlern" class="level3">
<h3 class="anchored" data-anchor-id="umgang-mit-fehlern">Umgang mit Fehlern</h3>
<p>Wissenschaftliche Fehler können massive Folgen haben. Beispielsweise hatte der <a href="https://de.wikipedia.org/wiki/MMR-Impfstoff#Der_Fall_Wakefield">Wakefield Skandal</a>, bei welchem Eltern bezahlt wurden, falsche Aussagen über die Entwicklung ihrer Kinder nach einer Impfung zu tätigen, eine Impfskepsis zur Folge. Das bedeutet, dass Eltern ihre Kinder aus Sorge vor den Folgen nicht impfen lassen und die Kinder dadurch erkranken und sterben können, obwohl der Ursprung der Sorge falsch war und längst und vielfach widerlegt wurde <span class="citation" data-cites="destefano2019mmr">(<a href="#ref-destefano2019mmr" role="doc-biblioref">DeStefano and Shimabukuro 2019</a>)</span>. In vielen Wissenschaften herrscht eine angespannte Fehlerkultur: Sobald jemand einen Fehler herausstellt, wird es als persönlicher Angriff verstanden und Kritiker werden beleidigt <span class="citation" data-cites="Baumeister.2016b">(<a href="#ref-Baumeister.2016b" role="doc-biblioref">Baumeister and Vohs 2016</a>)</span>. Durch die strenge Hierarchien kann es für Forschende, die noch keine Festanstellung haben, fatal sein, Professor*innen zu kritisieren, da sie ihre Artikel begutachten und über ihre Arbeitsverträge entscheiden können. Im Fall Wakefield dauert es selbst nachdem der Fehler klar war, viele Jahre, bis die Artikel öffentlich von der Zeitschrift zurückgezogen wurden <span class="citation" data-cites="eggertson2010lancet">(<a href="#ref-eggertson2010lancet" role="doc-biblioref">Eggertson 2010</a>)</span>. Und zuletzt merken Forschende gar nicht, wenn Artikel zurückgezogen werden, außer sie suchen aktiv danach.</p>
<p>Mit verschiedenen Ansätzen soll die Fehlerkultur offener gestaltet werden und diese Probleme gelöst werden. Eigentlich sollte allen klar sein, dass Fehler immer wieder passieren und alle davon profitieren, wenn die Fehler korrigiert werden. In der Wissenschaftspraxis profitieren nur leider nicht immer <em>alle</em>, sondern die Person, die den Fehler begangen hat, hat dank dieses Fehlers vielleicht einen Nobelpreis oder eine Professur bekommen. Um den Diskurs darüber anzukurbeln, haben Psycholog*innen aus der Schweiz ein Kopfgeld-Programm gestartet (https://error.reviews), bei welchem sich Personen bewerben und anschließend mit der Findung von Fehlern anderer Geld verdienen, oder in der Rolle der Begutachtenden Geld verdienen, wenn sie keine oder nur kleine Fehler begangen haben. Plattformen wie Pubpeer.com erlauben außerdem die anonyme Kommentierung von Forschung. Von besonderem Interesse ist dort Forschung von renommierten Personen, wie zum Beispiel dem Nobelpreisträger Thomas Südhof, auf Basis dessen Forschungsartikeln Diskussionen mit teilweise <a href="https://pubpeer.com/publications/F7C42C356B2E7049FDB68A434EF4F8">über 50 Kommentaren</a> geführt werden. Kommentare bei Pubper haben außerdem zu zahlreichen Retractions (also “Zurückziehungen” veröffentlichter Artikel) geführt. Retractions werden in der Retractiondatabase (retractiondatabase.org) gesammelt. Mittels eines Browser-Plugins können Forschende sich Artikel, zu denen es Pubpeer-Diskussionen gibt, hervorheben lassen. Um Retractions sichtbarer zu machen, wird aktuell (Sommer 2024) eine Studie durchgeführt, bei der Personen, die in Pre-Prints zurückgezogene Artikel zitieren, eine E-Mail-Benachrichtigung erhalten (RetractoBot, <a href="https://www.retracted.net" class="uri">https://www.retracted.net</a>).</p>
<p>In den Fällen, in denen es zu Retractions kommt, wird ein kurzer Text veröffentlicht, in dem erklärt wird, weshalb ein Artikel zurückgezogen wird. Solche Texte sind kaum standardisiert und oft intransparent. Das Committee of Publishing Ethics (https://publicationethics.org) hat Empfehlungen erarbeitet, unter welchen Bedingungen Artikel zurückgezogen werden und <span class="citation" data-cites="ivory2024tale">Ivory and Elson (<a href="#ref-ivory2024tale" role="doc-biblioref">2024</a>)</span> empfehlen standardisierte Texte, um die Gründe für die Retraction darzulegen.</p>
<p>Vereinzelt prüfen Wissenschaftler*innen große Mengen an Artikeln. Am berühmtesten ist darunter Elisabeth Bik. Sie hat zu Retractions von fast 600 Artikeln und Korrekturen von fast 500 Artikeln beigetragen (<a href="https://www.buzzfeednews.com/article/stephaniemlee/elisabeth-bik-didier-raoult-hydroxychloroquine-study" class="uri">https://www.buzzfeednews.com/article/stephaniemlee/elisabeth-bik-didier-raoult-hydroxychloroquine-study</a>). Dabei prüft sie Abbildungen in Forschungsartikeln aus der Biologie. Beispielsweise werden dabei sogenannte Western Blots beim Überführen von Artikeln in das Zeitschriftenformat, beim Erstellen von Abbildungen durch die Forschenden, oder sogar boswillig kopiert.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Erfahrungsbericht: Vom Fehler zur Korrektur
</div>
</div>
<div class="callout-body-container callout-body">
<p>Im Jahr 2021 habe ich einen Forschungsartikel zu einem Datensatz geschrieben, der durch die Zusammenarbeit von 99 Forschenden erstellt werden konnte <span class="citation" data-cites="Roseler.2021e">(<a href="#ref-Roseler.2021e" role="doc-biblioref">Röseler, Weber, and Schütz 2021</a>)</span>. 2022 wurde der Artikel beim Journal of Open Psychology Data veröffentlicht. Es war mir jedoch ein Fehler unterlaufen. Wie der erkannt und behoben wurde, beschreibe ich in der folgenden Historie:</p>
<ol type="1">
<li><p>Oktober 2022: Während der Revision (Überarbeitung) des Artikels kamen Daten von weiteren Forschenden hinzu. An dem Verfassen des Artikels waren bis dahin 64 Leute beteiligt, die Liste stieg dann auf 74 Personen. Ich sendete das überarbeitete Manuskript mit einer Tabelle der 74 Leute an die Zeitschrift. In dem System konnten Autor*innen <em>zusätzlich</em> auch in dafür vorgesehene Felder eingetragen werden. In den Feldern standen also die 64 Personen und im Artikel die 74. Der eingereichte Artikel wurde dann akzeptiert und seitens der Zeitschrift in das entsprechende Format überführt. Auch die Tabelle wurde überführt, nur löschte dabei jemand gezielt die zehn in die Tabelle (alphabetisch) einsortierten Personen unter Abgleich mit den Personen, die bei der ersten Einreichung in das System eingetragen wurden. Ich bekam den fertigen Artikel und hatte eine Woche Zeit, dazu Rückmeldung zugeben. Mir fielen die fehlenden Personen nicht auf.</p></li>
<li><p>2023 kontaktierte mich einer der fehlenden Autoren: Seine Doktorandin wollte die Quellenangabe auf ihren Lebenslauf schreiben, fand sich aber unter den Beteiligten nicht wieder. Dabei fiel auf, dass das Team aus 6 Personen komplett fehlte. Ich schrieb dem Herausgeber der Zeitschrift, entschuldigte mich für den Fehler, und fragte, ob eine Änderung noch möglich sei. Das war nicht der Fall, aber eine Korrektur war möglich.</p></li>
<li><p>Ich entschied mich für die Korrektur. Die Zeitschrift hatte in den vergangenen Monaten die Software für die Verwaltung von Einreichungen verändert und ich musste für die neue Einreichung alle 74 Personen erneut eintragen. Dies dauert inklusive Prüfungen ungefähr einen vollständigen Arbeitstag, allerdings forderte das System die Nationalitäten aller Beteiligten - und die wusste ich nicht. Ungefähr die Hälfte von ihnen waren Studierende, viele weitere hatten die Institution gewechselt, es war mir also nicht mehr möglich, die Nationalitäten aller Beteiligten in Erfahrung zu bringen. Ich wies auf das Problem hin und wartete darauf, dass bei der Korrektur eine Ausnahme gemacht werden konnte. Gleichzeitig begann meine 6-monatige Elternzeit, inklusive Umzug und Jobwechsel. Nach meiner Rückkehr kontaktierte ich einen der Herausgeber erneut. Es folgten weitere sieben Monate der Stille - mir wurde trotz mehrmaligem Nachfragen nicht geantwortet.</p></li>
<li><p>Im Januar 2024 erstellte ich einen <a href="https://pubpeer.com/publications/4C94D3988E8D66520AA044DECEE0F3">Pubpeer-Kommentar</a>. Ich verlor die Hoffnung, dass der Prozess jemals ein Ende finden würde, wollte aber auf den Fehler aufmerksam machen. Dort war die korrekte Liste der Beteiligten, die auch der Zeitschrift vorlag.</p></li>
<li><p>Im Juli 2024 schrieb ich mehreren Herausgebern erneut. Diesmal wurde mir geantwortet. Der Zeitschrift lagen plötzlich Nationalitäten der Beteiligten vor, die jemand bei der Original-Veröffentlichung händisch eingetragen haben musste. Ich konnte nun alle Autor*innen erneut und mit Nationalität eintragen. Mir fiel dabei auf, dass außer den sechs fehlenden noch vier weitere fehlten, die sich nicht bei mir gemeldet hatten. Ich berichtete allen Betroffenen über die Vorgänge und entschuldigte mich nocheinmal. Seitens der Zeitschrift wurde dann sehr schnell der formatierte Artikel vorbereitet. Wieder hatte ich eine Woche Zeit für Korrekturvorschläge. Gemeinsam mit Kollegen und Hilfskräften merkten wir circa 10 weitere Fehler bei Namen und Institutionen an und baten darum, die korrigierte Version erneut an uns zu senden, damit wir uns nicht wieder jahrelang um eine Korrektur bemühen müssen.</p></li>
<li><p>[Die Geschichte ist noch nicht abgeschlossen.]</p></li>
</ol>
</div>
</div>
</section>
<section id="offene-lehre-open-teaching-open-educational-resources" class="level3">
<h3 class="anchored" data-anchor-id="offene-lehre-open-teaching-open-educational-resources">Offene Lehre / Open Teaching / Open Educational Resources</h3>
<p>Unter dem Stichwort <em>Open Educational Resources</em> werden jegliche Materialien verstanden, die zur Lehre verwendet werden können. Das kann Bücher - so wie dieses - Forschungsartikel, Präsentationsfolien, aufgezeichnete Lehrveranstaltungen, oder Erklärvideos betreffen. Open bedeutet dabei meistens, dass sie sich gratis aus dem Internet herunterladen lassen. Diese Ressourcen zu teilen trifft den Kern von Open Science: Es soll niemand ausgeschlossen werden, nicht durch mangelnde Verfügbarkeit an einem Ort, hohe Preise, oder die Sprache. Häufig laden Open Science Verfechter*innen ihre Materialien in Portalen hoch (z.B. <a href="https://www.oerbw.de" class="uri">https://www.oerbw.de</a>, https://www.twillo.de/oer/web/, https://portal.hoou.de). Plattformen wie Zenodo (https://zenodo.org) oder das Open Science Framework (osf.io) erlauben eine kostenlose Langzeitarchivierung - also garantierte Verfügbarkeit von mindestens 20 bzw. 50 Jahren).</p>
<p>Unter den verschiedenen Akteuren im Bereich Open Educational Resources ist besonders FORRT hervorzuheben: In <em>Educational Nexus</em> werden spezifisch zu Open Science viele verschiedene Kurse und Unterlagen bereitgestellt (<a href="https://forrt.org/syllabus/" class="uri">https://forrt.org/syllabus/</a>). Es werden online Seminare durchgeführt, ein mehrsprachiges <a href="https://forrt.org/glossary/german/">Glossar</a> und eine Wissensdatenbank verwaltet <span class="citation" data-cites="Parsons.2022">(<a href="#ref-Parsons.2022" role="doc-biblioref">Parsons et al. 2022</a>)</span>. Weitere nennenswerte Wissensbanken sind die <a href="https://rosie-project.eu/knowledge-hub/#!training/health-and-life-sciences">ROSiE Knowledge Hub</a> und der <a href="https://openeconomics.zbw.eu/">Open Economics Guide</a>.</p>
<section id="weiterführende-informationen" class="level4">
<h4 class="anchored" data-anchor-id="weiterführende-informationen">Weiterführende Informationen</h4>
<ul>
<li><p><span class="citation" data-cites="Henderson2022-ci">Henderson and Chambers (<a href="#ref-Henderson2022-ci" role="doc-biblioref">2022</a>)</span> beschreibt zehn einfache Regeln zum Schreiben eines Registered Reports</p></li>
<li><p><span class="citation" data-cites="lakens2024benefits">Daniël Lakens et al. (<a href="#ref-lakens2024benefits" role="doc-biblioref">2024</a>)</span> diskutieren die Vorteile von Registered Reports und Präregistrierungen.</p></li>
<li><p>Ein Erklärvideo zu PCIs ist online verfügbar (<a href="https://www.youtube.com/watch?v=4PZhpnc8wwo" class="uri">https://www.youtube.com/watch?v=4PZhpnc8wwo</a>).</p></li>
<li><p>Berichte, wie Replikationen in verschiedenen Disziplinen aussehen, berichtet <span class="citation" data-cites="royal2018replication">Arts and Sciences (<a href="#ref-royal2018replication" role="doc-biblioref">2018</a>)</span>.</p></li>
<li><p>Mittels einem Wiki und einem Webinar können Studierende über das <a href="https://replication.uni-goettingen.de/wiki/index.php/Webinar_series:_Replicating_empirical_studies_in_economics_-_an_opportunity_for_students">ReplicationWiki</a> über Replikationen lernen.</p></li>
<li><p>Johanna Gereke und Anne-Sophie Waag haben in einem <a href="https://leibniz-psychology.org/practices-and-tools-of-open-science/open-science-in-der-lehre">Vortrag</a> Open Science in der universitären Lehre diskutiert.</p></li>
<li><p><span class="citation" data-cites="levendis2018time">Levendis (<a href="#ref-levendis2018time" role="doc-biblioref">2018</a>)</span> nutzt in seinem Lehrbuch zu Zeitreihenanalysen ausschließlich Reproduktionen von Analysen aus tatsächlichen Publikationen.</p></li>
</ul>
</section>
</section>
<section id="literatur" class="level3">
<h3 class="anchored" data-anchor-id="literatur">Literatur</h3>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-aczel2021billion" class="csl-entry" role="listitem">
Aczel, Balazs, Barnabas Szaszi, and Alex O Holcombe. 2021. <span>“A Billion-Dollar Donation: Estimating the Cost of Researchers’ Time Spent on Peer Review.”</span> <em>Research Integrity and Peer Review</em> 6: 1–8.
</div>
<div id="ref-Adler.2023" class="csl-entry" role="listitem">
Adler, Susanne Jana, Lukas Röseler, and Martina Katharina Schöniger. 2023. <span>“A Toolbox to Evaluate the Trustworthiness of Published Findings.”</span> <em>Journal of Business Research</em> 167: 114189. <a href="https://doi.org/10.1016/j.jbusres.2023.114189">https://doi.org/10.1016/j.jbusres.2023.114189</a>.
</div>
<div id="ref-Anderson.2017" class="csl-entry" role="listitem">
Anderson, Samantha F., Ken Kelley, and Scott E. Maxwell. 2017. <span>“Sample-Size Planning for More Accurate Statistical Power: A Method Adjusting Sample Effect Sizes for Publication Bias and Uncertainty.”</span> <em>Psychological Science</em> 28 (11): 1547–62. <a href="https://doi.org/10.1177/0956797617723724">https://doi.org/10.1177/0956797617723724</a>.
</div>
<div id="ref-ankel2023economists" class="csl-entry" role="listitem">
Ankel-Peters, Jörg, Nathan Fiala, and Florian Neubauer. 2023. <span>“Do Economists Replicate?”</span> <em>Journal of Economic Behavior &amp; Organization</em> 212: 219–32.
</div>
<div id="ref-royal2018replication" class="csl-entry" role="listitem">
Arts, Royal Netherlands Academy of, and Sciences. 2018. <span>“Replication Studies—Improving Reproducibility in the Empirical Sciences.”</span> In. KNAW Amsterdam.
</div>
<div id="ref-Azevedo2019-df" class="csl-entry" role="listitem">
Azevedo, Flavio, Sam Parsons, Leticia Micheli, Julia Feld Strand, Eike Mark Rinke, Samuel Guay, Mahmoud Medhat Elsherif, et al. 2019. <span>“Introducing a Framework for Open and Reproducible Research Training (<span>FORRT</span>).”</span>
</div>
<div id="ref-Baumeister.2016b" class="csl-entry" role="listitem">
Baumeister, Roy F., and Kathleen D. Vohs. 2016. <span>“Misguided Effort with Elusive Implications.”</span> <em>Perspectives on Psychological Science : A Journal of the Association for Psychological Science</em> 11 (4): 574–75. <a href="https://doi.org/10.1177/1745691616652878">https://doi.org/10.1177/1745691616652878</a>.
</div>
<div id="ref-Beall2017-hw" class="csl-entry" role="listitem">
Beall, Jeffrey. 2017. <span>“What <span>I</span> Learned from Predatory Publishers.”</span> <em>Biochem. Med. (Zagreb)</em> 27 (2): 273–78.
</div>
<div id="ref-Bilder2020-pm" class="csl-entry" role="listitem">
Bilder, Geoffrey, Jennifer Lin, and Cameron Neylon. 2020. <span>“The Principles of Open Scholarly Infrastructure.”</span> The Principles of Open Scholarly Infrastructure.
</div>
<div id="ref-Boulter2022-xu" class="csl-entry" role="listitem">
Boulter, Etienne, Julien Colombelli, Ricardo Henriques, and Chloé C Féral. 2022. <span>“The <span>LEGO</span> Brick Road to Open Science and Biotechnology.”</span> <em>Trends Biotechnol.</em> 40 (9): 1073–87.
</div>
<div id="ref-Boyce.2023" class="csl-entry" role="listitem">
Boyce, Veronica, Maya Mathur, and Michael C. Frank. 2023. <span>“Eleven Years of Student Replication Projects Provide Evidence on the Correlates of Replicability in Psychology.”</span> <em>Royal Society Open Science</em> 10 (11): 231240. <a href="https://doi.org/10.1098/rsos.231240">https://doi.org/10.1098/rsos.231240</a>.
</div>
<div id="ref-Brandt.2014" class="csl-entry" role="listitem">
Brandt, Mark J., Hans IJzerman, Ap Dijksterhuis, Frank J. Farach, Jason Geller, Roger Giner-Sorolla, James A. Grange, Marco Perugini, Jeffrey R. Spies, and Anna van ’t Veer. 2014. <span>“The Replication Recipe: What Makes for a Convincing Replication?”</span> <em>Journal of Experimental Social Psychology</em> 50: 217–24. <a href="https://doi.org/10.1016/j.jesp.2013.10.005">https://doi.org/10.1016/j.jesp.2013.10.005</a>.
</div>
<div id="ref-Brembs.2023" class="csl-entry" role="listitem">
Brembs, Björn, Philippe Huneman, Felix Schönbrodt, Gustav Nilsonne, Toma Susi, Renke Siems, Pandelis Perakakis, Varvara Trachana, Lai Ma, and Sara Rodriguez-Cuadrado. 2023. <span>“Replacing Academic Journals.”</span> <em>Royal Society Open Science</em> 10 (7). <a href="https://doi.org/10.1098/rsos.230206">https://doi.org/10.1098/rsos.230206</a>.
</div>
<div id="ref-Carriquiry2023-en" class="csl-entry" role="listitem">
Carriquiry, Alicia L, Michael J Daniels, and Nancy Reid. 2023. <span>“Editorial: Special Issue on Reproducibility and Replicability.”</span> <em>Stat. Sci.</em> 38 (4).
</div>
<div id="ref-Carter.2019" class="csl-entry" role="listitem">
Carter, Evan C., Felix D. Schönbrodt, Will M. Gervais, and Joseph Hilgard. 2019. <span>“Correcting for Bias in Psychology: A Comparison of Meta-Analytic Methods.”</span> <em>Advances in Methods and Practices in Psychological Science</em> 2 (2): 115–44. <a href="https://doi.org/10.1177/2515245919847196">https://doi.org/10.1177/2515245919847196</a>.
</div>
<div id="ref-chambers2022past" class="csl-entry" role="listitem">
Chambers, Christopher D, and Loukia Tzavella. 2022. <span>“The Past, Present and Future of Registered Reports.”</span> <em>Nature Human Behaviour</em> 6 (1): 29–42.
</div>
<div id="ref-Cheung.2016" class="csl-entry" role="listitem">
Cheung, Irene, Lorne Campbell, Etienne P. LeBel, Robert A. Ackerman, Bülent Aykutog˘lu, Štěpán Bahník, Jeffrey D. Bowen, et al. 2016. <span>“Registered Replication Report: Study 1 from Finkel, Rusbult, Kumashiro, <span>&amp;</span> Hannon (2002).”</span> <em>Perspectives on Psychological Science : A Journal of the Association for Psychological Science</em> 11 (5): 750–64. <a href="https://doi.org/10.1177/1745691616664694">https://doi.org/10.1177/1745691616664694</a>.
</div>
<div id="ref-Clarke2023-ff" class="csl-entry" role="listitem">
Clarke, Beth, Pui Yu Lee, Sarah R Schiavone, Mijke Rhemtulla, and Simine Vazire. 2023. <span>“The Prevalence of Direct Replication Articles in Top-Ranking Psychology Journals.”</span> <em>PsyArXiv</em>.
</div>
<div id="ref-destefano2019mmr" class="csl-entry" role="listitem">
DeStefano, Frank, and Tom T Shimabukuro. 2019. <span>“The MMR Vaccine and Autism.”</span> <em>Annual Review of Virology</em> 6 (1): 585–600.
</div>
<div id="ref-Deutsche_Forschungsgemeinschaft2022-qx" class="csl-entry" role="listitem">
Deutsche Forschungsgemeinschaft. 2022. <span>“Open Science Als Teil Der Wissenschaftskultur. Positionierung Der Deutschen Forschungsgemeinschaft.”</span> Zenodo.
</div>
<div id="ref-devezer2021case" class="csl-entry" role="listitem">
Devezer, Berna, Danielle J Navarro, Joachim Vandekerckhove, and Erkan Ozge Buzbas. 2021. <span>“The Case for Formal Methodology in Scientific Reform.”</span> <em>Royal Society Open Science</em> 8 (3): 200805.
</div>
<div id="ref-eggertson2010lancet" class="csl-entry" role="listitem">
Eggertson, Laura. 2010. <span>“Lancet Retracts 12-Year-Old Article Linking Autism to MMR Vaccines.”</span> <em>Canadian Medical Association Journal (CMAJ)</em> 182.
</div>
<div id="ref-Elsherif2023-by" class="csl-entry" role="listitem">
Elsherif, Mahmoud, Gilad Feldman, and Siu Kit Yeung. 2023. <span>“Quantitative Manuscript Peer Review Template.”</span> OSF.
</div>
<div id="ref-Ensinck2023-hf" class="csl-entry" role="listitem">
Ensinck, Eline Noëlle Fleur, and Daniel Lakens. 2023. <span>“An Inception Cohort Study Quantifying How Many Registered Studies Are Published.”</span> <em>PsyArXiv</em>.
</div>
<div id="ref-etzel2024inter" class="csl-entry" role="listitem">
Etzel, Franka, Anna Seyffert-Müller, Felix D Schönbrodt, Lucie Kreuzer, Anne Gärtner, Paula Knischewski, and Daniel Leising. 2024. <span>“Inter-Rater Reliability in Assessing the Methodological Quality of Research Papers in Psychology.”</span>
</div>
<div id="ref-Farrow2020-jc" class="csl-entry" role="listitem">
Farrow, Robert, Rebecca Pitt, and Martin Weller. 2020. <span>“Open Textbooks as an Innovation Route for Open Science Pedagogy.”</span> <em>Educ. Inf.</em> 36 (3): 227–45.
</div>
<div id="ref-feest2019replication" class="csl-entry" role="listitem">
Feest, Uljana. 2019. <span>“Why Replication Is Overrated.”</span> <em>Philosophy of Science</em> 86 (5): 895–905.
</div>
<div id="ref-Feldman.2021" class="csl-entry" role="listitem">
Feldman, Gilad. 2021. <span>“Replications and Extensions of Classic Findings in Judgment and Decision Making.”</span> <a href="https://doi.org/10.17605/OSF.IO/5Z4A8">https://doi.org/10.17605/OSF.IO/5Z4A8</a>.
</div>
<div id="ref-fletcher2021role" class="csl-entry" role="listitem">
Fletcher, Samuel C. 2021. <span>“The Role of Replication in Psychological Science.”</span> <em>European Journal for Philosophy of Science</em> 11 (1): 23.
</div>
<div id="ref-Frank2019-ro" class="csl-entry" role="listitem">
Frank, Michael C. 2019. <span>“N-Best Evaluation for Academic Hiring and Promotion.”</span> <em>PsyArXiv</em>.
</div>
<div id="ref-Fraser2020-fn" class="csl-entry" role="listitem">
Fraser, Nicholas, Liam Brierley, Gautam Dey, Jessica K Polka, Máté Pálfy, Federico Nanni, and Jonathon Alexis Coates. 2020. <span>“Preprinting the <span>COVID-19</span> Pandemic.”</span> <em>bioRxiv</em>. bioRxiv.
</div>
<div id="ref-freese2017replication" class="csl-entry" role="listitem">
Freese, Jeremy, and David Peterson. 2017. <span>“Replication in Social Science.”</span> <em>Annual Review of Sociology</em> 43 (1): 147–65.
</div>
<div id="ref-gartner2022responsible" class="csl-entry" role="listitem">
Gärtner, Anne, Daniel Leising, and Felix Schönbrodt. 2022a. <span>“Responsible Research Assessment II: A Specific Proposal for Hiring and Promotion in Psychology.”</span>
</div>
<div id="ref-Gartner2022-uh" class="csl-entry" role="listitem">
Gärtner, Anne, Daniel Leising, and Felix D Schönbrodt. 2022b. <span>“Responsible Research Assessment <span>II</span>: A Specific Proposal for Hiring and Promotion in Psychology.”</span> <em>PsyArXiv</em>.
</div>
<div id="ref-hardwicke2022estimating" class="csl-entry" role="listitem">
Hardwicke, Tom E, Robert T Thibault, Jessica E Kosie, Joshua D Wallach, Mallory C Kidwell, and John PA Ioannidis. 2022. <span>“Estimating the Prevalence of Transparency and Reproducibility-Related Research Practices in Psychology (2014–2017).”</span> <em>Perspectives on Psychological Science</em> 17 (1): 239–51.
</div>
<div id="ref-Hardwicke2023-fo" class="csl-entry" role="listitem">
Hardwicke, Tom E, and Simine Vazire. 2023. <span>“Transparency Is Now the Default at Psychological Science.”</span> <em>Psychol. Sci.</em>, December, 9567976231221573.
</div>
<div id="ref-Henderson2022-ci" class="csl-entry" role="listitem">
Henderson, Emma L, and Christopher D Chambers. 2022. <span>“Ten Simple Rules for Writing a Registered Report.”</span> <em>PLoS Comput. Biol.</em> 18 (10): e1010571.
</div>
<div id="ref-Himmelstein2018-ys" class="csl-entry" role="listitem">
Himmelstein, Daniel S, Ariel Rodriguez Romero, Jacob G Levernier, Thomas Anthony Munro, Stephen Reid McLaughlin, Bastian Greshake Tzovaras, and Casey S Greene. 2018. <span>“<span>Sci-Hub</span> Provides Access to Nearly All Scholarly Literature.”</span> <em>Elife</em> 7 (March).
</div>
<div id="ref-hoffler2017replicationwiki" class="csl-entry" role="listitem">
Höffler, Jan H. 2017. <span>“ReplicationWiki: Improving Transparency in Social Sciences Research.”</span> <em>D-Lib Magazine</em> 23 (3): 1.
</div>
<div id="ref-holford2024engaging" class="csl-entry" role="listitem">
Holford, Dawn, Janet McLean, Alex O Holcombe, Iratxe Puebla, and Vera Kempe. 2024. <span>“Engaging Undergraduate Students in Preprint Peer Review.”</span> <em>Active Learning in Higher Education</em>, 14697874241264495.
</div>
<div id="ref-Hostler2024-to" class="csl-entry" role="listitem">
Hostler, Tom. 2024. <span>“Research Assessment Using a Narrow Definition of <span>‘Research Quality’</span> Is an Act of Gatekeeping: A Comment on g<span>ä</span>rtner Et Al. (2022).”</span> <em>Meta-Psychology</em> 8 (March).
</div>
<div id="ref-HoyningenHuene.2013" class="csl-entry" role="listitem">
Hoyningen-Huene, Paul. 2013. <em>Systematicity: The Nature of Science</em>. Oxford Studies in Philosophy of Science. Oxford: <span>Oxford Univ. Press</span>.
</div>
<div id="ref-Huffmeier.2016" class="csl-entry" role="listitem">
Hüffmeier, Joachim, Jens Mazei, and Thomas Schultze. 2016. <span>“Reconceptualizing Replication as a Sequence of Different Studies: A Replication Typology.”</span> <em>Journal of Experimental Social Psychology</em> 66: 81–92. <a href="https://doi.org/10.1016/j.jesp.2015.09.009">https://doi.org/10.1016/j.jesp.2015.09.009</a>.
</div>
<div id="ref-ivory2024tale" class="csl-entry" role="listitem">
Ivory, James D, and Malte Elson. 2024. <span>“A Tale of Three Retractions: A Call for Standardized Categorization and Criteria in Retraction Statements.”</span> <em>Current Psychology</em> 43 (17): 16023–29.
</div>
<div id="ref-Jekel.2020" class="csl-entry" role="listitem">
Jekel, Marc, Susann Fiedler, Ramona Allstadt Torras, Dorothee Mischkowski, Angela Rachael Dorrough, and Andreas Glöckner. 2020. <span>“How to Teach Open Science Principles in the Undergraduate Curriculum—the Hagen Cumulative Science Project.”</span> <em>Psychology Learning <span>&amp;</span> Teaching</em> 19 (1): 91–106. <a href="https://doi.org/10.1177/1475725719868149">https://doi.org/10.1177/1475725719868149</a>.
</div>
<div id="ref-Kelly2006-wt" class="csl-entry" role="listitem">
Kelly, Clint D. 2006. <span>“Replicating Empirical Research in Behavioral Ecology: How and Why It Should Be Done but Rarely Ever Is.”</span> <em>Q. Rev. Biol.</em> 81 (3): 221–36.
</div>
<div id="ref-kelly2019rate" class="csl-entry" role="listitem">
———. 2019. <span>“Rate and Success of Study Replication in Ecology and Evolution.”</span> <em>PeerJ</em> 7: e7654.
</div>
<div id="ref-kletke2024bestands" class="csl-entry" role="listitem">
Kletke, Olaf, Inga Larres, Kathrin Höhner, Wibke Kleina, Julia Stapels, Bernd Zey, and Niels Kasties. 2024. <span>“Bestands-Und Bedarfserhebung Im Forschungsdatenmanagement: Ergebnisse Des Projektes FDM-TUDO.”</span> <em>O-Bib. Das Offene Bibliotheksjournal/Herausgeber VDB</em> 11 (2): 1–18.
</div>
<div id="ref-Klonsky2024-pl" class="csl-entry" role="listitem">
Klonsky, E David. 2024. <span>“Campbell’s Law Explains the Replication Crisis: Pre-Registration Badges Are History Repeating.”</span> <em>Assessment</em>, May, 10731911241253430.
</div>
<div id="ref-kobrock2023assessing" class="csl-entry" role="listitem">
Kobrock, Kristina, and Timo Roettger. 2023. <span>“Assessing the Replication Landscape in Experimental Linguistics.”</span> <em>Glossa Psycholinguistics</em> 2 (1): 1–28.
</div>
<div id="ref-Korbmacher.2023" class="csl-entry" role="listitem">
Korbmacher, Max, Flavio Azevedo, Charlotte R. Pennington, Helena Hartmann, Madeleine Pownall, Kathleen Schmidt, Mahmoud Elsherif, et al. 2023. <span>“The Replication Crisis Has Led to Positive Structural, Procedural, and Community Changes.”</span> <em>Communications Psychology</em> 1 (1). <a href="https://doi.org/10.1038/s44271-023-00003-2">https://doi.org/10.1038/s44271-023-00003-2</a>.
</div>
<div id="ref-Korell.2023" class="csl-entry" role="listitem">
Korell, Daniel, Niklas Reinecke, and Lars Lott. 2023a. <span>“Student-Led Replication Studies in Comparative Politics: New Findings by Fresh Eyes?”</span> <em>Zeitschrift f<span>ü</span>r Vergleichende Politikwissenschaft</em> 17 (3): 261–73. <a href="https://doi.org/10.1007/s12286-023-00578-4">https://doi.org/10.1007/s12286-023-00578-4</a>.
</div>
<div id="ref-korell2023student" class="csl-entry" role="listitem">
———. 2023b. <span>“Student-Led Replication Studies in Comparative Politics: New Findings by Fresh Eyes?”</span> <em>Zeitschrift f<span>ü</span>r Vergleichende Politikwissenschaft</em> 17 (3): 261–73.
</div>
<div id="ref-Lakens.2023" class="csl-entry" role="listitem">
Lakens, Daniel. 2023. <span>“Concerns about Replicability, Theorizing, Applicability, Generalizability, and Methodology Across Two Crises in Social Psychology.”</span> <a href="https://doi.org/10.31234/osf.io/dtvs7">https://doi.org/10.31234/osf.io/dtvs7</a>.
</div>
<div id="ref-Lakens.2017" class="csl-entry" role="listitem">
Lakens, Daniël. 2017. <span>“Equivalence Tests: A Practical Primer for t Tests, Correlations, and Meta-Analyses.”</span> <em>Social Psychological and Personality Science</em> 8 (4): 355–62. <a href="https://doi.org/10.1177/1948550617697177">https://doi.org/10.1177/1948550617697177</a>.
</div>
<div id="ref-lakens2024benefits" class="csl-entry" role="listitem">
Lakens, Daniël, Cristian Mesquida, Sajedeh Rasti, and Massimiliano Ditroilo. 2024. <span>“The Benefits of Preregistration and Registered Reports.”</span> <em>Evidence-Based Toxicology</em> 2 (1): 2376046.
</div>
<div id="ref-LeBel.2019" class="csl-entry" role="listitem">
LeBel, Etienne P., Wolf Vanpaemel, Irene Cheung, and Lorne Campbell. 2019. <span>“A Brief Guide to Evaluate Replications.”</span> <em>Meta-Psychology</em> 3. <a href="https://doi.org/10.15626/MP.2018.843">https://doi.org/10.15626/MP.2018.843</a>.
</div>
<div id="ref-levendis2018time" class="csl-entry" role="listitem">
Levendis, John D. 2018. <em>Time Series Econometrics</em>. Springer.
</div>
<div id="ref-Makel2014-jc" class="csl-entry" role="listitem">
Makel, Matthew C, and Jonathan A Plucker. 2014. <span>“Facts Are More Important Than Novelty.”</span> <em>Educ. Res.</em> 43 (6): 304–16.
</div>
<div id="ref-makel2016replication" class="csl-entry" role="listitem">
Makel, Matthew C, Jonathan A Plucker, Jennifer Freeman, Allison Lombardi, Brandi Simonsen, and Michael Coyne. 2016. <span>“Replication of Special Education Research: Necessary but Far Too Rare.”</span> <em>Remedial and Special Education</em> 37 (4): 205–12.
</div>
<div id="ref-Makel2012-bi" class="csl-entry" role="listitem">
Makel, Matthew C, Jonathan A Plucker, and Boyd Hegarty. 2012. <span>“Replications in Psychology Research: How Often Do They Really Occur?”</span> <em>Perspect. Psychol. Sci.</em> 7 (6): 537–42.
</div>
<div id="ref-marsden2018replication" class="csl-entry" role="listitem">
Marsden, Emma, Kara Morgan-Short, Sophie Thompson, and David Abugaber. 2018. <span>“Replication in Second Language Research: Narrative and Systematic Reviews and Recommendations for the Field.”</span> <em>Language Learning</em> 68 (2): 321–91.
</div>
<div id="ref-mcdiarmid2021psychologists" class="csl-entry" role="listitem">
McDiarmid, Alex D, Alexa M Tullett, Cassie M Whitt, Simine Vazire, Paul E Smaldino, and Jeremy E Stephens. 2021. <span>“Psychologists Update Their Beliefs about Effect Sizes After Replication Studies.”</span> <em>Nature Human Behaviour</em> 5 (12): 1663–73.
</div>
<div id="ref-McNeeley2015-bf" class="csl-entry" role="listitem">
McNeeley, Susan, and Jessica J Warner. 2015. <span>“Replication in Criminology: A Necessary Practice.”</span> <em>Eur. J. Criminol.</em> 12 (5): 581–97.
</div>
<div id="ref-merton1973sociology" class="csl-entry" role="listitem">
Merton, Robert K. 1973. <em>The Sociology of Science: Theoretical and Empirical Investigations</em>. University of Chicago press.
</div>
<div id="ref-mueller2019replication" class="csl-entry" role="listitem">
Mueller-Langer, Frank, Benedikt Fecher, Dietmar Harhoff, and Gert G Wagner. 2019. <span>“Replication Studies in Economics—How Many and Which Papers Are Chosen for Replication, and Why?”</span> <em>Research Policy</em> 48 (1): 62–83.
</div>
<div id="ref-Nelson2022-yn" class="csl-entry" role="listitem">
Nelson, Lindsay, Honghan Ye, Anna Schwenn, Shinhyo Lee, Salsabil Arabi, and B Ian Hutchins. 2022. <span>“Robustness of Evidence Reported in Preprints During Peer Review.”</span> <em>Lancet Glob. Health</em> 10 (11): e1684–87.
</div>
<div id="ref-Nosek2015-at" class="csl-entry" role="listitem">
Nosek, B A, G Alter, G C Banks, D Borsboom, S D Bowman, S J Breckler, S Buck, et al. 2015. <span>“Promoting an Open Research Culture.”</span> <em>Science</em> 348 (6242): 1422–25.
</div>
<div id="ref-nuijten2016prevalence" class="csl-entry" role="listitem">
Nuijten, Michèle B, Chris HJ Hartgerink, Marcel ALM Van Assen, Sacha Epskamp, and Jelte M Wicherts. 2016. <span>“The Prevalence of Statistical Reporting Errors in Psychology (1985–2013).”</span> <em>Behavior Research Methods</em> 48: 1205–26.
</div>
<div id="ref-ongchoco2023visual" class="csl-entry" role="listitem">
Ongchoco, Joan Danielle K, Robert Walter-Terrill, and Brian J Scholl. 2023. <span>“Visual Event Boundaries Restrict Anchoring Effects in Decision-Making.”</span> <em>Proceedings of the National Academy of Sciences</em> 120 (44): e2303883120.
</div>
<div id="ref-Openness2023-yk" class="csl-entry" role="listitem">
Openness, D H Nrw |. 2023b. <span>“<span>Open-Access-Strategie</span> Der Hochschulen Des Landes <span>NRW</span>.”</span> Zenodo.
</div>
<div id="ref-Openness2023-ga" class="csl-entry" role="listitem">
———. 2023a. <span>“<span>Open-Access-Strategie</span> Der Hochschulen Des Landes <span>NRW</span>.”</span> Zenodo.
</div>
<div id="ref-Parsons.2022" class="csl-entry" role="listitem">
Parsons, Sam, Flávio Azevedo, Mahmoud M. Elsherif, Samuel Guay, Owen N. Shahim, Gisela H. Govaart, Emma Norris, et al. 2022. <span>“A Community-Sourced Glossary of Open Scholarship Terms.”</span> <em>Nature Human Behaviour</em> 6 (3): 312–18. <a href="https://doi.org/10.1038/s41562-021-01269-4">https://doi.org/10.1038/s41562-021-01269-4</a>.
</div>
<div id="ref-Pawel2023-vv" class="csl-entry" role="listitem">
Pawel, Samuel, Guido Consonni, and Leonhard Held. 2023. <span>“Bayesian Approaches to Designing Replication Studies.”</span> <em>Psychol. Methods</em>, August.
</div>
<div id="ref-Pennington2024-mp" class="csl-entry" role="listitem">
Pennington, Charlotte Rebecca, and Madeleine Pownall. 2024. <span>“What Have We Learned from the Replication Crisis? Integrating Open Research into Social Psychology Teaching.”</span> <em>PsyArXiv</em>.
</div>
<div id="ref-Peroni2012-ko" class="csl-entry" role="listitem">
Peroni, Silvio, and David Shotton. 2012. <span>“<span>FaBiO</span> and <span>CiTO</span>: Ontologies for Describing Bibliographic Resources and Citations.”</span> <em>Web Semant.</em> 17 (December): 33–43.
</div>
<div id="ref-Priem2022-mb" class="csl-entry" role="listitem">
Priem, Jason, Heather Piwowar, and Richard Orr. 2022. <span>“<span>OpenAlex</span>: A Fully-Open Index of Scholarly Works, Authors, Venues, Institutions, and Concepts.”</span>
</div>
<div id="ref-protzko2018null" class="csl-entry" role="listitem">
Protzko, John. 2018. <span>“Null-Hacking, a Lurking Problem.”</span>
</div>
<div id="ref-Quan2021-hw" class="csl-entry" role="listitem">
Quan, Joshua. 2021. <span>“Toward Reproducibility: Academic Libraries and Open Science.”</span> Cambridge University Press.
</div>
<div id="ref-Quintana2021-dp" class="csl-entry" role="listitem">
Quintana, Daniel S. 2021. <span>“Replication Studies for Undergraduate Theses to Improve Science and Education.”</span> <em>Nat. Hum. Behav.</em> 5 (9): 1117–18.
</div>
<div id="ref-rahal2023quality" class="csl-entry" role="listitem">
Rahal, Rima-Maria, Susann Fiedler, Adeyemi Adetula, Ronnie P-A Berntsson, Ulrich Dirnagl, Gordon B Feld, Christian J Fiebach, et al. 2023. <span>“Quality Research Needs Good Working Conditions.”</span> <em>Nature Human Behaviour</em> 7 (2): 164–67.
</div>
<div id="ref-Roseler.2022d" class="csl-entry" role="listitem">
Röseler, Lukas, Taisia Gendlina, Josefine Krapp, Noemi Labusch, and Astrid Schütz. 2022. <span>“Successes and Failures of Replications: A Meta-Analysis of Independent Replication Studies Based on the OSF Registries.”</span> <a href="https://doi.org/10.31222/osf.io/8psw2">https://doi.org/10.31222/osf.io/8psw2</a>.
</div>
<div id="ref-Roseler.2024" class="csl-entry" role="listitem">
Röseler, Lukas, Leonard Kaiser, Christopher Albert Doetsch, Noah Klett, Christian Seida, Astrid Schütz, Balazs Aczel, et al. 2024. <span>“The Replication Database: Documenting the Replicability of Psychological Science.”</span> <a href="https://doi.org/10.31222/osf.io/me2ub">https://doi.org/10.31222/osf.io/me2ub</a>.
</div>
<div id="ref-Roseler.2021e" class="csl-entry" role="listitem">
Röseler, Lukas, Lucia Weber, and Astrid Schütz. 2021. <span>“OpAQ: Open Anchoring Quest.”</span> <a href="https://osf.io/ygnvb">https://osf.io/ygnvb</a>.
</div>
<div id="ref-Rosenthal.1979" class="csl-entry" role="listitem">
Rosenthal, Robert. 1979. <span>“The File Drawer Problem and Tolerance for Null Results.”</span> <em>Psychological Bulletin</em> 86 (3): 638–41. <a href="https://doi.org/10.1037/0033-2909.86.3.638">https://doi.org/10.1037/0033-2909.86.3.638</a>.
</div>
<div id="ref-de2023automatically" class="csl-entry" role="listitem">
Ruiter, Bob de. 2023. <span>“Automatically Finding and Categorizing Replication Studies.”</span> <em>arXiv e-Prints</em>, arXiv–2311.
</div>
<div id="ref-Scanff2023-sz" class="csl-entry" role="listitem">
Scanff, Alexandre, Nicolas Mauhe, Marion Taburet, Pierre-Etienne Savourat, Thomas Clément, Benjamin Bastian, Ioana Cristea, Alain Braillon, Nicolas Carayol, and Florian Naudet. 2023. <span>“The <span>‘Free Lunches’</span> Index for Assessing Academics: A Not Entirely Serious Proposal.”</span> <em>Scientometrics</em>, November.
</div>
<div id="ref-Schmidt2024-uv" class="csl-entry" role="listitem">
Schmidt, Birgit, Andrea Chiarelli, Lucia Loffreda, and Jeroen Sondervan. 2024. <span>“Emerging Roles and Responsibilities of Libraries in Support of Reproducible Research.”</span> <em>LIBER Q.</em> 33 (1): 1–21.
</div>
<div id="ref-Schoch.2023" class="csl-entry" role="listitem">
Schöch, Christof. 2023. <span>“Repetitive Research: A Conceptual Space and Terminology of Replication, Reproduction, Revision, Reanalysis, Reinvestigation and Reuse in Digital Humanities.”</span> <em>International Journal of Digital Humanities</em> 5 (2-3): 373–403. <a href="https://doi.org/10.1007/s42803-023-00073-y">https://doi.org/10.1007/s42803-023-00073-y</a>.
</div>
<div id="ref-Schönbrodt_Gärtner_Frank_Gollwitzer_Ihle_Mischkowski_Phan_Schmitt_Scheel_Schubert_Steinberg_Leising_2022" class="csl-entry" role="listitem">
Schönbrodt, Felix, Anne Gärtner, Maximilian Frank, Mario Gollwitzer, Malika Ihle, Dorothee Mischkowski, Le Vy Phan, Manfred Schmitt, Anne M. Scheel, Anna-Lena Schubert, Ulf Steinberg, et al. 2022. <span>“Responsible Research Assessment i: Implementing DORA for Hiring and Promotion in Psychology.”</span> <a href="https://doi.org/10.23668/psycharchives.8162">https://doi.org/10.23668/psycharchives.8162</a>.
</div>
<div id="ref-schonbrodt2022responsible" class="csl-entry" role="listitem">
Schönbrodt, Felix, Anne Gärtner, Maximilian Frank, Mario Gollwitzer, Malika Ihle, Dorothee Mischkowski, Le Vy Phan, Manfred Schmitt, Anne M Scheel, Anna-Lena Schubert, and others. 2022. <span>“Responsible Research Assessment i: Implementing DORA for Hiring and Promotion in Psychology.”</span>
</div>
<div id="ref-Siems2024-vv" class="csl-entry" role="listitem">
Siems, Renke. 2024. <span>“Subprime Impact Crisis. Bibliotheken, Politik Und Digitale Souver<span>ä</span>nit<span>ä</span>t.”</span> <em>BIBL. Forsch. Prax.</em> 0 (0).
</div>
<div id="ref-Silverstein2023-ek" class="csl-entry" role="listitem">
Silverstein, Priya, Colin Elman, Amanda Kay Montoya, Barbara McGillivray, Charlotte Rebecca Pennington, Chase H Harrison, Crystal Nicole Steltenpohl, et al. 2023. <span>“A Guide for Social Science Journal Editors on Easing into Open Science.”</span>
</div>
<div id="ref-Simmons.2011" class="csl-entry" role="listitem">
Simmons, Joseph P., Leif D. Nelson, and Uri Simonsohn. 2011. <span>“False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant.”</span> <em>Psychological Science</em> 22 (11): 1359–66. <a href="https://doi.org/10.1177/0956797611417632">https://doi.org/10.1177/0956797611417632</a>.
</div>
<div id="ref-Simons.2014b" class="csl-entry" role="listitem">
Simons, Daniel J., Alex O. Holcombe, and Barbara A. Spellman. 2014. <span>“An Introduction to Registered Replication Reports at Perspectives on Psychological Science.”</span> <em>Perspectives on Psychological Science : A Journal of the Association for Psychological Science</em> 9 (5): 552–55. <a href="https://doi.org/10.1177/1745691614543974">https://doi.org/10.1177/1745691614543974</a>.
</div>
<div id="ref-Simonsohn.2015" class="csl-entry" role="listitem">
Simonsohn, Uri. 2015. <span>“Small Telescopes: Detectability and the Evaluation of Replication Results.”</span> <em>Psychological Science</em> 26 (5): 559–69. <a href="https://doi.org/10.1177/0956797614567341">https://doi.org/10.1177/0956797614567341</a>.
</div>
<div id="ref-Sobkow.2021" class="csl-entry" role="listitem">
Sobkow, Agata, Marcin Surowski, Angelika Olszewska, Nina Antoniewska, Urszula Bartkiewicz, Agnieszka Brzeska, Adrianna Brzozowska, et al. 2021. <em>Conceptual Replication Study of Fifteen JDM Effects: Insights from the Polish Sample</em>. <a href="https://doi.org/10.31234/osf.io/5fc6z">https://doi.org/10.31234/osf.io/5fc6z</a>.
</div>
<div id="ref-Soderberg.2021" class="csl-entry" role="listitem">
Soderberg, Courtney K., Timothy M. Errington, Sarah R. Schiavone, Julia Bottesini, Felix Singleton Thorn, Simine Vazire, Kevin M. Esterling, and Brian A. Nosek. 2021. <span>“Initial Evidence of Research Quality of Registered Reports Compared with the Standard Publishing Model.”</span> <em>Nature Human Behaviour</em>. <a href="https://doi.org/10.1038/s41562-021-01142-4">https://doi.org/10.1038/s41562-021-01142-4</a>.
</div>
<div id="ref-srivastava2012pottery" class="csl-entry" role="listitem">
Srivastava, Sanjay. 2012. <span>“A Pottery Barn Rule for Scientific Journals.”</span> <em>The Hardest Science</em> 27.
</div>
<div id="ref-Sterling.1959" class="csl-entry" role="listitem">
Sterling, T. D. 1959. <span>“Publication Decisions and Their Possible Effects on Inferences Drawn from Tests of Significance—or Vice Versa.”</span> <em>Journal of the American Statistical Association</em> 54 (285): 30–34. <a href="http://www.jstor.com/stable/2282137">http://www.jstor.com/stable/2282137</a>.
</div>
<div id="ref-strecker2019nutzung" class="csl-entry" role="listitem">
Strecker, Dorothea. 2019. <span>“Nutzung Der Schattenbibliothek Sci-Hub in Deutschland.”</span>
</div>
<div id="ref-Ting2024-af" class="csl-entry" role="listitem">
Ting, Carol, and Sander Greenland. 2024. <span>“Forcing a Deterministic Frame on Probabilistic Phenomena: A Communication Blind Spot in Media Coverage of the <span>‘Replication Crisis’</span>.”</span> <em>Sci. Commun.</em>, April.
</div>
<div id="ref-Tiokhin2023-ne" class="csl-entry" role="listitem">
Tiokhin, Leo, Karthik Panchanathan, Paul E Smaldino, and Daniël Lakens. 2023. <span>“Shifting the Level of Selection in Science.”</span> <em>Perspect. Psychol. Sci.</em>, August, 17456916231182568.
</div>
<div id="ref-unesco2020first" class="csl-entry" role="listitem">
UNESCO. 2020. <span>“First Draft of the UNESCO Recommendation on Open Science.”</span>
</div>
<div id="ref-urminsky2024taking" class="csl-entry" role="listitem">
Urminsky, Oleg, and Berkeley J Dietvorst. 2024. <span>“Taking the Full Measure: Integrating Replication into Research Practice to Assess Generalizability.”</span> <em>Journal of Consumer Research</em> 51 (1): 157–68.
</div>
<div id="ref-wagge2019publishing" class="csl-entry" role="listitem">
Wagge, Jordan R, Mark J Brandt, Ljiljana B Lazarevic, Nicole Legate, Cody Christopherson, Brady Wiggins, and Jon E Grahe. 2019. <span>“Publishing Research with Undergraduate Students via Replication Work: The Collaborative Replications and Education Project.”</span> <em>Frontiers in Psychology</em> 10: 247.
</div>
<div id="ref-Willighagen2023-gp" class="csl-entry" role="listitem">
Willighagen, Egon. 2023. <span>“Two Years of Explicit <span>CiTO</span> Annotations.”</span> <em>J. Cheminform.</em> 15 (1): 14.
</div>
<div id="ref-Xiao.2021" class="csl-entry" role="listitem">
Xiao, Qinyu, Choi Shan Lam, Muhrajan Piara, and Gilad Feldman. 2021. <span>“Revisiting Status Quo Bias.”</span> <em>Meta-Psychology</em> 5. <a href="https://doi.org/10.15626/MP.2020.2470">https://doi.org/10.15626/MP.2020.2470</a>.
</div>
<div id="ref-Ziano.2021" class="csl-entry" role="listitem">
Ziano, Ignazio, Pui Yan Mok, and Gilad Feldman. 2021. <span>“Replication and Extension of Alicke (1985) Better-Than-Average Effect for Desirable and Controllable Traits.”</span> <em>Social Psychological and Personality Science</em> 12 (6): 1005–17. <a href="https://doi.org/10.1177/1948550620948973">https://doi.org/10.1177/1948550620948973</a>.
</div>
<div id="ref-Zimmermann2015-jw" class="csl-entry" role="listitem">
Zimmermann, Christian. 2015. <span>“On the Need for a Replication Journal.”</span> <em>Wp</em> 2015 (016).
</div>
<div id="ref-Zumstein2023-kn" class="csl-entry" role="listitem">
Zumstein, Philipp. 2023. <span>“Open Access Und Ein Blick Auf Das Wissenschaftliche Publikationswesen.”</span> PsychArchives.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("lukasroeseler\.github\.io\/opensciencebuch\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./lösungen.html" class="pagination-link" aria-label="Lösungen">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Lösungen</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./lösungen_methoden.html" class="pagination-link" aria-label="Methoden">
        <span class="nav-page-text"><span class="chapter-title">Methoden</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Röseler, L. (in preparation). Open Science: Wie sich die Wissenschaft öffnet (0.1th ed.). https://doi.org/10.17605/OSF.IO/2QXWV</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/LukasRoeseler/opensciencebuch/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Mithilfe von <a href="https://quarto.org/">Quarto</a> erstellt. Lizenz: CC-By Attribution 4.0 International.</p>
</div>
  </div>
</footer>




</body></html>